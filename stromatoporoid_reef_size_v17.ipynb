{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeong-HyunLee/stromatoporoid-reef/blob/main/stromatoporoid_reef_size_v17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiczYjViaSKp",
        "outputId": "5b77975b-6724-4492-921f-09bb8a3bed4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "STROMATOPOROID TURNOVER AND REEF MORPHOLOGY ANALYSIS\n",
            "WITH PEARSON AND SPEARMAN CORRELATIONS\n",
            "STAGE-LEVEL AND 5-MYR BIN ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "Libraries loaded successfully!\n",
            "Output directory: ./output\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "#@title CELL 1: SETUP AND IMPORTS\n",
        "# =============================================================================\n",
        "\n",
        "# Install required packages (uncomment if needed)\n",
        "# !pip install openpyxl geopandas shapely requests\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from matplotlib.lines import Line2D\n",
        "from scipy import stats\n",
        "from scipy.interpolate import interp1d\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import resample\n",
        "import statsmodels.api as sm\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up matplotlib for publication-quality vector figures\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['font.size'] = 10\n",
        "plt.rcParams['axes.labelsize'] = 11\n",
        "plt.rcParams['axes.titlesize'] = 12\n",
        "plt.rcParams['figure.dpi'] = 150\n",
        "plt.rcParams['savefig.dpi'] = 300\n",
        "plt.rcParams['pdf.fonttype'] = 42  # TrueType fonts in PDF\n",
        "plt.rcParams['ps.fonttype'] = 42\n",
        "plt.rcParams['svg.fonttype'] = 'none'  # Text as text in SVG\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"STROMATOPOROID TURNOVER AND REEF MORPHOLOGY ANALYSIS\")\n",
        "print(\"WITH PEARSON AND SPEARMAN CORRELATIONS\")\n",
        "print(\"STAGE-LEVEL AND 5-MYR BIN ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nLibraries loaded successfully!\")\n",
        "\n",
        "# Output directory\n",
        "import os\n",
        "OUTPUT_DIR = \"./output\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "print(f\"Output directory: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Vx2CXdOaivD",
        "outputId": "00164443-9c89-4dcd-8abf-4427ff91d8dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "GENERATING MACROSTRAT DATA\n",
            "======================================================================\n",
            "Generating Macrostrat data from API...\n",
            "  Fetching data for Ordovician...\n",
            "    Retrieved 2943 geological units\n",
            "  Fetching data for Silurian...\n",
            "    Retrieved 1715 geological units\n",
            "  Fetching data for Devonian...\n",
            "    Retrieved 2793 geological units\n",
            "  Combined dataset: 7451 geological units\n",
            "  ✓ Saved paleozoic_stage_data.csv\n",
            "  ✓ Saved paleozoic_5myr_data.csv\n",
            "✓ Macrostrat data ready\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "#@title CELL 2: GENERATE MACROSTRAT DATA (paleozoic_stage_data.csv, paleozoic_5myr_data.csv)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"GENERATING MACROSTRAT DATA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Check if files already exist\n",
        "macrostrat_stage_file = 'paleozoic_stage_data.csv'\n",
        "macrostrat_5myr_file = 'paleozoic_5myr_data.csv'\n",
        "\n",
        "if os.path.exists(macrostrat_stage_file) and os.path.exists(macrostrat_5myr_file):\n",
        "    print(f\"✓ {macrostrat_stage_file} already exists\")\n",
        "    print(f\"✓ {macrostrat_5myr_file} already exists\")\n",
        "    print(\"Skipping Macrostrat data generation...\")\n",
        "else:\n",
        "    print(\"Generating Macrostrat data from API...\")\n",
        "\n",
        "    import requests\n",
        "    try:\n",
        "        import geopandas as gpd\n",
        "    except ImportError:\n",
        "        print(\"Installing geopandas...\")\n",
        "        import subprocess\n",
        "        subprocess.run(['pip', 'install', 'geopandas', '-q'])\n",
        "        import geopandas as gpd\n",
        "\n",
        "    # Define Paleozoic Period Age Ranges\n",
        "    periods = {\n",
        "        \"Ordovician\": {\"start\": 485.4, \"end\": 443.8, \"color\": \"#00a9ce\"},\n",
        "        \"Silurian\": {\"start\": 443.8, \"end\": 419.2, \"color\": \"#b3e1af\"},\n",
        "        \"Devonian\": {\"start\": 419.2, \"end\": 358.9, \"color\": \"#cb8c37\"}\n",
        "    }\n",
        "\n",
        "    # Define stages\n",
        "    ordovician_stages = {\n",
        "        \"Tremadocian\": (478.6, 485.4), \"Floian\": (470.0, 478.6),\n",
        "        \"Dapingian\": (467.3, 470.0), \"Darriwilian\": (458.4, 467.3),\n",
        "        \"Sandbian\": (453.0, 458.4), \"Katian\": (445.2, 453.0),\n",
        "        \"Hirnantian\": (443.8, 445.2)\n",
        "    }\n",
        "    silurian_stages = {\n",
        "        \"Rhuddanian\": (440.8, 443.8), \"Aeronian\": (438.5, 440.8),\n",
        "        \"Telychian\": (433.4, 438.5), \"Sheinwoodian\": (430.5, 433.4),\n",
        "        \"Homerian\": (427.4, 430.5), \"Gorstian\": (425.6, 427.4),\n",
        "        \"Ludfordian\": (423.0, 425.6), \"Pridolian\": (419.2, 423.0)\n",
        "    }\n",
        "    devonian_stages = {\n",
        "        \"Lochkovian\": (410.8, 419.2), \"Pragian\": (407.6, 410.8),\n",
        "        \"Emsian\": (393.3, 407.6), \"Eifelian\": (387.7, 393.3),\n",
        "        \"Givetian\": (382.7, 387.7), \"Frasnian\": (372.2, 382.7),\n",
        "        \"Famennian\": (358.9, 372.2)\n",
        "    }\n",
        "\n",
        "    # Create stages dataframe\n",
        "    stages_data = []\n",
        "    for stage, (end_age, start_age) in ordovician_stages.items():\n",
        "        stages_data.append({\"stage\": stage, \"start_age\": start_age, \"end_age\": end_age,\n",
        "                           \"mid_age\": (start_age + end_age) / 2, \"period\": \"Ordovician\"})\n",
        "    for stage, (end_age, start_age) in silurian_stages.items():\n",
        "        stages_data.append({\"stage\": stage, \"start_age\": start_age, \"end_age\": end_age,\n",
        "                           \"mid_age\": (start_age + end_age) / 2, \"period\": \"Silurian\"})\n",
        "    for stage, (end_age, start_age) in devonian_stages.items():\n",
        "        stages_data.append({\"stage\": stage, \"start_age\": start_age, \"end_age\": end_age,\n",
        "                           \"mid_age\": (start_age + end_age) / 2, \"period\": \"Devonian\"})\n",
        "    stages_df = pd.DataFrame(stages_data)\n",
        "\n",
        "    # Retrieve Macrostrat Data\n",
        "    periods_to_fetch = [\"Ordovician\", \"Silurian\", \"Devonian\"]\n",
        "    all_units_list = []\n",
        "\n",
        "    for period in periods_to_fetch:\n",
        "        url = f\"https://macrostrat.org/api/units?interval_name={period}&format=geojson&response=long\"\n",
        "        print(f\"  Fetching data for {period}...\")\n",
        "        try:\n",
        "            response = requests.get(url, timeout=60)\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                features = data.get(\"success\", {}).get(\"data\", [])\n",
        "                if features:\n",
        "                    period_units = gpd.GeoDataFrame.from_features(features)\n",
        "                    print(f\"    Retrieved {len(period_units)} geological units\")\n",
        "                    period_units['source_period'] = period\n",
        "                    all_units_list.append(period_units)\n",
        "        except Exception as e:\n",
        "            print(f\"    Error fetching {period}: {e}\")\n",
        "\n",
        "    if all_units_list:\n",
        "        units = pd.concat(all_units_list, ignore_index=True)\n",
        "        print(f\"  Combined dataset: {len(units)} geological units\")\n",
        "\n",
        "        # Process units\n",
        "        try:\n",
        "            if units.crs is None:\n",
        "                units.set_crs(epsg=4326, inplace=True)\n",
        "            units = units.to_crs(epsg=3857)\n",
        "            if 'col_area' in units.columns:\n",
        "                units['area_km2'] = pd.to_numeric(units['col_area'], errors='coerce')\n",
        "            else:\n",
        "                units['area_km2'] = units.geometry.area / 1e6\n",
        "        except:\n",
        "            units['area_km2'] = 100  # Default\n",
        "\n",
        "        units['t_age'] = pd.to_numeric(units['t_age'], errors='coerce')\n",
        "        units['b_age'] = pd.to_numeric(units['b_age'], errors='coerce')\n",
        "        units['mid_age'] = (units['t_age'] + units['b_age']) / 2.0\n",
        "        units.dropna(subset=['mid_age'], inplace=True)\n",
        "\n",
        "        # Identify carbonates\n",
        "        def check_if_carbonate(lithologies):\n",
        "            if isinstance(lithologies, list):\n",
        "                for lith in lithologies:\n",
        "                    if isinstance(lith, dict) and 'type' in lith and 'carbonate' in str(lith['type']).lower():\n",
        "                        return True\n",
        "            elif isinstance(lithologies, str):\n",
        "                return 'carbonate' in lithologies.lower()\n",
        "            return False\n",
        "\n",
        "        units['is_carbonate'] = units['lith'].apply(check_if_carbonate)\n",
        "        carbonate_units = units[units['is_carbonate']].copy()\n",
        "\n",
        "        # Assign stages\n",
        "        all_stages = {**ordovician_stages, **silurian_stages, **devonian_stages}\n",
        "        def assign_stage(age):\n",
        "            for stage, (end, start) in all_stages.items():\n",
        "                if start >= age >= end:\n",
        "                    return stage\n",
        "            return None\n",
        "\n",
        "        units['stage'] = units['mid_age'].apply(assign_stage)\n",
        "        carbonate_units['stage'] = carbonate_units['mid_age'].apply(assign_stage)\n",
        "\n",
        "        # Aggregate by stage\n",
        "        stage_totals = units.groupby('stage')['area_km2'].sum().reset_index()\n",
        "        stage_totals.rename(columns={'area_km2': 'total_area_km2'}, inplace=True)\n",
        "        stage_carbonates = carbonate_units.groupby('stage')['area_km2'].sum().reset_index()\n",
        "        stage_carbonates.rename(columns={'area_km2': 'carbonate_area_km2'}, inplace=True)\n",
        "\n",
        "        stage_summary = pd.merge(stage_totals, stage_carbonates, on='stage', how='left')\n",
        "        stage_summary['carbonate_area_km2'] = stage_summary['carbonate_area_km2'].fillna(0)\n",
        "        stage_summary['carbonate_percentage'] = (stage_summary['carbonate_area_km2'] / stage_summary['total_area_km2']) * 100\n",
        "\n",
        "        macrostrat_data = pd.merge(stages_df, stage_summary, on='stage', how='left')\n",
        "        macrostrat_data = macrostrat_data.sort_values('start_age', ascending=False).reset_index(drop=True)\n",
        "        macrostrat_data.to_csv(macrostrat_stage_file, index=False)\n",
        "        print(f\"  ✓ Saved {macrostrat_stage_file}\")\n",
        "\n",
        "        # 5 Myr bins\n",
        "        max_age = 490\n",
        "        min_age = 355\n",
        "        manual_bins = np.arange(min_age, max_age + 5, 5)\n",
        "\n",
        "        units['time_bin'] = pd.cut(units['mid_age'], bins=manual_bins, include_lowest=True, right=False)\n",
        "        carbonate_units['time_bin'] = pd.cut(carbonate_units['mid_age'], bins=manual_bins, include_lowest=True, right=False)\n",
        "\n",
        "        macro_all_5myr = units.groupby('time_bin')['area_km2'].sum().reset_index()\n",
        "        macro_all_5myr.rename(columns={'area_km2': 'total_area_km2'}, inplace=True)\n",
        "        macro_carb_5myr = carbonate_units.groupby('time_bin')['area_km2'].sum().reset_index()\n",
        "        macro_carb_5myr.rename(columns={'area_km2': 'carbonate_area_km2'}, inplace=True)\n",
        "\n",
        "        macrostrat_5myr = pd.merge(macro_all_5myr, macro_carb_5myr, on='time_bin', how='left')\n",
        "        macrostrat_5myr['carbonate_area_km2'] = macrostrat_5myr['carbonate_area_km2'].fillna(0)\n",
        "        macrostrat_5myr['carbonate_percentage'] = (macrostrat_5myr['carbonate_area_km2'] / macrostrat_5myr['total_area_km2']) * 100\n",
        "        macrostrat_5myr['bin_mid'] = macrostrat_5myr['time_bin'].apply(lambda x: (x.left + x.right) / 2 if pd.notna(x) else np.nan)\n",
        "        macrostrat_5myr.to_csv(macrostrat_5myr_file, index=False)\n",
        "        print(f\"  ✓ Saved {macrostrat_5myr_file}\")\n",
        "    else:\n",
        "        print(\"  WARNING: Could not fetch Macrostrat data. Creating placeholder files...\")\n",
        "        # Create placeholder files\n",
        "        pd.DataFrame(columns=['stage', 'total_area_km2', 'carbonate_area_km2', 'carbonate_percentage']).to_csv(macrostrat_stage_file, index=False)\n",
        "        pd.DataFrame(columns=['bin_mid', 'total_area_km2', 'carbonate_area_km2', 'carbonate_percentage']).to_csv(macrostrat_5myr_file, index=False)\n",
        "\n",
        "print(\"✓ Macrostrat data ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "Fk40AhaealAV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "85b50d74-8400-49eb-b45e-8e7a52f2e8c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "GENERATING PARED REEF DATA\n",
            "======================================================================\n",
            "Source file 'PARED_reef_All_numerical.csv' not found.\n",
            "Please upload it now:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3e5c33b2-bd99-43da-a482-f0fdf9eb52bb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3e5c33b2-bd99-43da-a482-f0fdf9eb52bb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving PARED_reef_All_numerical.csv to PARED_reef_All_numerical.csv\n",
            "Processing PARED_reef_All_numerical.csv...\n",
            "  ✓ Generated ordovician_devonian_reef_data_stage_for_analysis.csv\n",
            "  ✓ Generated ordovician_devonian_reef_data_5myr_for_analysis.csv\n",
            "✓ PARED reef data ready\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "#@title CELL 3: GENERATE PARED REEF DATA (reef stage and 5myr files)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"GENERATING PARED REEF DATA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "reef_stage_file = 'ordovician_devonian_reef_data_stage_for_analysis.csv'\n",
        "reef_5myr_file = 'ordovician_devonian_reef_data_5myr_for_analysis.csv'\n",
        "pared_source_file = 'PARED_reef_All_numerical.csv'\n",
        "\n",
        "# Force regeneration to include new variable\n",
        "if os.path.exists(reef_stage_file) and os.path.exists(reef_5myr_file) and False:\n",
        "    print(f\"✓ {reef_stage_file} already exists\")\n",
        "    print(f\"✓ {reef_5myr_file} already exists\")\n",
        "    print(\"Skipping PARED reef data generation...\")\n",
        "else:\n",
        "    # Check if source file exists\n",
        "    if not os.path.exists(pared_source_file):\n",
        "        print(f\"Source file '{pared_source_file}' not found.\")\n",
        "        print(\"Please upload it now:\")\n",
        "        try:\n",
        "            from google.colab import files\n",
        "            uploaded_pared = files.upload()\n",
        "            uploaded_name = list(uploaded_pared.keys())[0]\n",
        "            if uploaded_name != pared_source_file:\n",
        "                os.rename(uploaded_name, pared_source_file)\n",
        "        except ImportError:\n",
        "            raise FileNotFoundError(f\"Please place '{pared_source_file}' in the current directory.\")\n",
        "\n",
        "    print(f\"Processing {pared_source_file}...\")\n",
        "\n",
        "    # Load PARED data\n",
        "    try:\n",
        "        pared_df = pd.read_csv(pared_source_file, encoding='utf-8')\n",
        "    except UnicodeDecodeError:\n",
        "        try:\n",
        "            pared_df = pd.read_csv(pared_source_file, encoding='latin-1')\n",
        "        except:\n",
        "            pared_df = pd.read_csv(pared_source_file, encoding='cp1252')\n",
        "\n",
        "    # --- NEW CODE: Calculate Paired Ratio (Log Difference) ---\n",
        "    # Ensure numeric\n",
        "    pared_df['thickness'] = pd.to_numeric(pared_df['thickness'], errors='coerce')\n",
        "    pared_df['width'] = pd.to_numeric(pared_df['width'], errors='coerce')\n",
        "\n",
        "    # Calculate difference (Log Thickness - Log Width)\n",
        "    # This automatically becomes NaN if either value is missing\n",
        "    pared_df['t_w_log_ratio'] = pared_df['thickness'] - pared_df['width']\n",
        "    # ---------------------------------------------------------\n",
        "\n",
        "    def analyze_pared_data(dataframe, bin_definitions, analysis_type_label):\n",
        "        \"\"\"Calculate statistics using OVERLAP method\"\"\"\n",
        "        results = []\n",
        "        # Added 't_w_log_ratio' to variables\n",
        "        variables = ['thickness', 'width', 'extension', 't_w_log_ratio']\n",
        "\n",
        "        for bin_def in bin_definitions:\n",
        "            s_start = bin_def['start_ma']\n",
        "            s_end = bin_def['end_ma']\n",
        "            name = bin_def['time_identifier']\n",
        "\n",
        "            # OVERLAP LOGIC\n",
        "            mask = (dataframe['min_ma'] < s_end) & (dataframe['max_ma'] > s_start)\n",
        "            subset = dataframe[mask]\n",
        "\n",
        "            row_data = {\n",
        "                'bin_center': (s_start + s_end) / 2.0,\n",
        "                'start_age': s_start,\n",
        "                'end_age': s_end,\n",
        "                'reef_count': len(subset),\n",
        "            }\n",
        "\n",
        "            for var in variables:\n",
        "                data = subset[var].dropna() if var in subset.columns else pd.Series()\n",
        "                if len(data) > 0:\n",
        "                    row_data[f'{var}_mean'] = data.mean()\n",
        "                    row_data[f'{var}_std'] = data.std()\n",
        "                    row_data[f'{var}_stderr'] = data.sem()\n",
        "                    row_data[f'{var}_median'] = data.median()\n",
        "                    row_data[f'{var}_count'] = len(data)\n",
        "                else:\n",
        "                    for suffix in ['mean', 'std', 'stderr', 'median']:\n",
        "                        row_data[f'{var}_{suffix}'] = np.nan\n",
        "                    row_data[f'{var}_count'] = 0\n",
        "\n",
        "            row_data['analysis_type'] = analysis_type_label\n",
        "            row_data['time_identifier'] = name\n",
        "            row_data['name'] = name\n",
        "            row_data['start_ma'] = s_start\n",
        "            row_data['end_ma'] = s_end\n",
        "            row_data['midpoint_ma'] = (s_start + s_end) / 2.0\n",
        "            row_data['duration_myr'] = round(s_end - s_start, 1)\n",
        "\n",
        "            results.append(row_data)\n",
        "\n",
        "        return pd.DataFrame(results)\n",
        "\n",
        "    # Stage definitions (PRESERVED FROM ORIGINAL)\n",
        "    stages_data = [\n",
        "        {'time_identifier': 'Famennian', 'start_ma': 358.9, 'end_ma': 372.2},\n",
        "        {'time_identifier': 'Frasnian', 'start_ma': 372.2, 'end_ma': 382.7},\n",
        "        {'time_identifier': 'Givetian', 'start_ma': 382.7, 'end_ma': 387.7},\n",
        "        {'time_identifier': 'Eifelian', 'start_ma': 387.7, 'end_ma': 393.3},\n",
        "        {'time_identifier': 'Emsian', 'start_ma': 393.3, 'end_ma': 407.6},\n",
        "        {'time_identifier': 'Pragian', 'start_ma': 407.6, 'end_ma': 410.8},\n",
        "        {'time_identifier': 'Lochkovian', 'start_ma': 410.8, 'end_ma': 419.2},\n",
        "        {'time_identifier': 'Pridoli', 'start_ma': 419.2, 'end_ma': 423.0},\n",
        "        {'time_identifier': 'Ludfordian', 'start_ma': 423.0, 'end_ma': 425.6},\n",
        "        {'time_identifier': 'Gorstian', 'start_ma': 425.6, 'end_ma': 427.4},\n",
        "        {'time_identifier': 'Homerian', 'start_ma': 427.4, 'end_ma': 430.5},\n",
        "        {'time_identifier': 'Sheinwoodian', 'start_ma': 430.5, 'end_ma': 433.4},\n",
        "        {'time_identifier': 'Telychian', 'start_ma': 433.4, 'end_ma': 438.5},\n",
        "        {'time_identifier': 'Aeronian', 'start_ma': 438.5, 'end_ma': 440.8},\n",
        "        {'time_identifier': 'Rhuddanian', 'start_ma': 440.8, 'end_ma': 443.8},\n",
        "        {'time_identifier': 'Hirnantian', 'start_ma': 443.8, 'end_ma': 445.2},\n",
        "        {'time_identifier': 'Katian', 'start_ma': 445.2, 'end_ma': 453.0},\n",
        "        {'time_identifier': 'Sandbian', 'start_ma': 453.0, 'end_ma': 458.4},\n",
        "        {'time_identifier': 'Darriwilian', 'start_ma': 458.4, 'end_ma': 467.3},\n",
        "        {'time_identifier': 'Dapingian', 'start_ma': 467.3, 'end_ma': 470.0},\n",
        "        {'time_identifier': 'Floian', 'start_ma': 470.0, 'end_ma': 477.7},\n",
        "        {'time_identifier': 'Tremadocian', 'start_ma': 477.7, 'end_ma': 485.4},\n",
        "    ]\n",
        "\n",
        "    # 5-Myr bins\n",
        "    bins_5myr = []\n",
        "    for age in range(355, 490, 5):\n",
        "        bins_5myr.append({\n",
        "            'time_identifier': f\"{age}-{age+5} Ma\",\n",
        "            'start_ma': float(age),\n",
        "            'end_ma': float(age + 5)\n",
        "        })\n",
        "\n",
        "    # Generate stage data\n",
        "    df_stages = analyze_pared_data(pared_df, stages_data, 'Geological_Stages')\n",
        "    df_stages.to_csv(reef_stage_file, index=False)\n",
        "    print(f\"  ✓ Generated {reef_stage_file}\")\n",
        "\n",
        "    # Generate 5myr data\n",
        "    df_5myr = analyze_pared_data(pared_df, bins_5myr, '5_myr_bins')\n",
        "    df_5myr.to_csv(reef_5myr_file, index=False)\n",
        "    print(f\"  ✓ Generated {reef_5myr_file}\")\n",
        "\n",
        "print(\"✓ PARED reef data ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "-CR5FkScbhfW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f2e1baee-28f1-4460-c89f-be898727ca7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created Generic 5-Myr bins (Aligned to 485.0):\n",
            "     bin_label  bin_top  bin_bottom\n",
            "0  485.0-480.0    485.0       480.0\n",
            "1  480.0-475.0    480.0       475.0\n",
            "2  475.0-470.0    475.0       470.0\n",
            "3  470.0-465.0    470.0       465.0\n",
            "4  465.0-460.0    465.0       460.0\n",
            "      bin_label  bin_top  bin_bottom\n",
            "21  380.0-375.0    380.0       375.0\n",
            "22  375.0-370.0    375.0       370.0\n",
            "23  370.0-365.0    370.0       365.0\n",
            "24  365.0-360.0    365.0       360.0\n",
            "25  360.0-355.0    360.0       355.0\n",
            "\n",
            "--- CHECKING FILE SYSTEM ---\n",
            "No 'pbdb_data_*.csv' files found. Please upload your RAW PBDB files now.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5c9cd23b-f34f-45af-8f0f-c68ae0e9d42e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5c9cd23b-f34f-45af-8f0f-c68ae0e9d42e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving pbdb_data_Actinostromatida.csv to pbdb_data_Actinostromatida.csv\n",
            "Saving pbdb_data_Amphiporida.csv to pbdb_data_Amphiporida.csv\n",
            "Saving pbdb_data_Clathrodictyida.csv to pbdb_data_Clathrodictyida.csv\n",
            "Saving pbdb_data_Labechiida.csv to pbdb_data_Labechiida.csv\n",
            "Saving pbdb_data_Rugosa.csv to pbdb_data_Rugosa.csv\n",
            "Saving pbdb_data_Stromatoporellida.csv to pbdb_data_Stromatoporellida.csv\n",
            "Saving pbdb_data_Stromatoporida.csv to pbdb_data_Stromatoporida.csv\n",
            "Saving pbdb_data_Syringostromatida.csv to pbdb_data_Syringostromatida.csv\n",
            "Saving pbdb_data_Tabulata.csv to pbdb_data_Tabulata.csv\n",
            "Found 9 files: ['pbdb_data_Clathrodictyida.csv', 'pbdb_data_Labechiida.csv', 'pbdb_data_Rugosa.csv', 'pbdb_data_Amphiporida.csv', 'pbdb_data_Syringostromatida.csv', 'pbdb_data_Tabulata.csv', 'pbdb_data_Actinostromatida.csv', 'pbdb_data_Stromatoporellida.csv', 'pbdb_data_Stromatoporida.csv']\n",
            "\n",
            "--- STARTING ANALYSIS (Generic 485.0 Bins) ---\n",
            "\n",
            "Analyzing Clathrodictyida...\n",
            "  -> Created: pbdb_Clathrodictyida_midpoint_stages.csv\n",
            "  -> Created: pbdb_Clathrodictyida_midpoint_5myr_bins.csv\n",
            "\n",
            "Analyzing Labechiida...\n",
            "  -> Created: pbdb_Labechiida_midpoint_stages.csv\n",
            "  -> Created: pbdb_Labechiida_midpoint_5myr_bins.csv\n",
            "\n",
            "Analyzing Rugosa...\n",
            "  -> Created: pbdb_Rugosa_midpoint_stages.csv\n",
            "  -> Created: pbdb_Rugosa_midpoint_5myr_bins.csv\n",
            "\n",
            "Analyzing Amphiporida...\n",
            "  -> Created: pbdb_Amphiporida_midpoint_stages.csv\n",
            "  -> Created: pbdb_Amphiporida_midpoint_5myr_bins.csv\n",
            "\n",
            "Analyzing Syringostromatida...\n",
            "  -> Created: pbdb_Syringostromatida_midpoint_stages.csv\n",
            "  -> Created: pbdb_Syringostromatida_midpoint_5myr_bins.csv\n",
            "\n",
            "Analyzing Tabulata...\n",
            "  -> Created: pbdb_Tabulata_midpoint_stages.csv\n",
            "  -> Created: pbdb_Tabulata_midpoint_5myr_bins.csv\n",
            "\n",
            "Analyzing Actinostromatida...\n",
            "  -> Created: pbdb_Actinostromatida_midpoint_stages.csv\n",
            "  -> Created: pbdb_Actinostromatida_midpoint_5myr_bins.csv\n",
            "\n",
            "Analyzing Stromatoporellida...\n",
            "  -> Created: pbdb_Stromatoporellida_midpoint_stages.csv\n",
            "  -> Created: pbdb_Stromatoporellida_midpoint_5myr_bins.csv\n",
            "\n",
            "Analyzing Stromatoporida...\n",
            "  -> Created: pbdb_Stromatoporida_midpoint_stages.csv\n",
            "  -> Created: pbdb_Stromatoporida_midpoint_5myr_bins.csv\n",
            "\n",
            "========================================\n",
            "DONE! New 485.0-aligned bin files created.\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# @title CELL 4: GENERATE PBDB DIVERSITY AND OCCURRENCE DATA (GENERIC 485.0 BINS)\n",
        "# =============================================================================\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "# ==========================================\n",
        "# 1. SETUP: Create Time References\n",
        "# ==========================================\n",
        "ics_data = \"\"\"stage,series,period,start_ma,end_ma\n",
        "Tremadocian,Lower Ordovician,Ordovician,485.4,477.7\n",
        "Floian,Lower Ordovician,Ordovician,477.7,470\n",
        "Dapingian,Middle Ordovician,Ordovician,470,467.3\n",
        "Darriwilian,Middle Ordovician,Ordovician,467.3,458.4\n",
        "Sandbian,Upper Ordovician,Ordovician,458.4,453\n",
        "Katian,Upper Ordovician,Ordovician,453,445.2\n",
        "Hirnantian,Upper Ordovician,Ordovician,445.2,443.8\n",
        "Rhuddanian,Llandovery,Silurian,443.8,440.8\n",
        "Aeronian,Llandovery,Silurian,440.8,438.5\n",
        "Telychian,Llandovery,Silurian,438.5,433.4\n",
        "Sheinwoodian,Wenlock,Silurian,433.4,430.5\n",
        "Homerian,Wenlock,Silurian,430.5,427.4\n",
        "Gorstian,Ludlow,Silurian,427.4,425.6\n",
        "Ludfordian,Ludlow,Silurian,425.6,423\n",
        "Pridoli,Pridoli,Silurian,423,419.2\n",
        "Lochkovian,Lower Devonian,Devonian,419.2,410.8\n",
        "Pragian,Lower Devonian,Devonian,410.8,407.6\n",
        "Emsian,Lower Devonian,Devonian,407.6,393.3\n",
        "Eifelian,Middle Devonian,Devonian,393.3,387.7\n",
        "Givetian,Middle Devonian,Devonian,387.7,382.7\n",
        "Frasnian,Upper Devonian,Devonian,382.7,372.2\n",
        "Famennian,Upper Devonian,Devonian,372.2,358.9\"\"\"\n",
        "\n",
        "with open(\"ICS_stage_boundaries.csv\", \"w\") as f:\n",
        "    f.write(ics_data)\n",
        "\n",
        "# MODIFIED: Start at 485.0 to align with generic grid\n",
        "def create_5myr_bins(start_ma=485.0, end_ma=358.9, step=5.0):\n",
        "    bins = []\n",
        "    current = start_ma\n",
        "    # Ensure we cover down to the end_ma\n",
        "    while current > end_ma - step:\n",
        "        # Logic: Stop if the bottom of the bin is way below end_ma?\n",
        "        # Typically we want the bin containing end_ma (358.9).\n",
        "        # Bin 360-355 covers 358.9. 355 is < 358.9? No.\n",
        "        # Let's keep standard logic:\n",
        "        if current < 360 and current < end_ma: break # Safety break\n",
        "\n",
        "        top = current\n",
        "        bottom = current - step\n",
        "\n",
        "        # Check if we are going too far (e.g. into Carboniferous)\n",
        "        # We want to stop after covering Famennian (ends 358.9).\n",
        "        # Bin 365-360: Covers 360+.\n",
        "        # Bin 360-355: Covers 358.9.\n",
        "        # Bin 355-350: Unnecessary.\n",
        "\n",
        "        label = f\"{top:.1f}-{bottom:.1f}\"\n",
        "        bins.append({'bin_label': label, 'bin_top': top, 'bin_bottom': bottom})\n",
        "\n",
        "        # Break if this bin covered the end of the period\n",
        "        if bottom < end_ma:\n",
        "             current = bottom\n",
        "             break\n",
        "\n",
        "        current = bottom\n",
        "    return pd.DataFrame(bins)\n",
        "\n",
        "bins_5myr_df = create_5myr_bins()\n",
        "stages_df = pd.read_csv(\"ICS_stage_boundaries.csv\")\n",
        "\n",
        "print(\"Created Generic 5-Myr bins (Aligned to 485.0):\")\n",
        "print(bins_5myr_df.head())\n",
        "print(bins_5myr_df.tail())\n",
        "\n",
        "# ==========================================\n",
        "# 2. FILE CHECK\n",
        "# ==========================================\n",
        "print(\"\\n--- CHECKING FILE SYSTEM ---\")\n",
        "found_files = []\n",
        "for f in os.listdir('.'):\n",
        "    if f.lower().startswith(\"pbdb_data_\") and f.lower().endswith(\".csv\"):\n",
        "        found_files.append(f)\n",
        "\n",
        "if not found_files:\n",
        "    print(\"No 'pbdb_data_*.csv' files found. Please upload your RAW PBDB files now.\")\n",
        "    files.upload()\n",
        "    found_files = [f for f in os.listdir('.') if f.lower().startswith(\"pbdb_data_\") and f.lower().endswith(\".csv\")]\n",
        "\n",
        "print(f\"Found {len(found_files)} files: {found_files}\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. HELPER FUNCTIONS\n",
        "# ==========================================\n",
        "\n",
        "def smart_read_pbdb(file_path):\n",
        "    header_row = None\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
        "            lines = [f.readline() for _ in range(50)]\n",
        "        for i, line in enumerate(lines):\n",
        "            if \"occurrence_no\" in line:\n",
        "                header_row = i\n",
        "                break\n",
        "        if header_row is None:\n",
        "            print(f\"    CRITICAL: Could not find 'occurrence_no' header in {file_path}\")\n",
        "            return None\n",
        "        return pd.read_csv(file_path, header=header_row)\n",
        "    except Exception as e:\n",
        "        print(f\"    Error reading {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_genus(accepted_name):\n",
        "    if pd.isna(accepted_name): return None\n",
        "    return str(accepted_name).split(' ')[0]\n",
        "\n",
        "def get_stage_from_age(age, stages_df):\n",
        "    match = stages_df[(stages_df['start_ma'] >= age) & (stages_df['end_ma'] < age)]\n",
        "    if match.empty:\n",
        "        if abs(age - stages_df['end_ma'].min()) < 0.001: return stages_df.iloc[-1]['stage']\n",
        "    if not match.empty: return match.iloc[0]['stage']\n",
        "    return None\n",
        "\n",
        "def get_bin_from_age(age, bins_df):\n",
        "    # Strict containment\n",
        "    match = bins_df[(bins_df['bin_top'] >= age) & (bins_df['bin_bottom'] < age)]\n",
        "\n",
        "    # MODIFIED: Tolerance/Snap for oldest points\n",
        "    # If age is slightly older than the top bin (e.g. 485.4 vs 485.0), snap it to the first bin\n",
        "    if match.empty:\n",
        "        max_top = bins_df['bin_top'].max()\n",
        "        if age > max_top and (age - max_top) < 1.5: # 1.5 Ma tolerance for Tremadocian start\n",
        "             return bins_df.iloc[0]['bin_label']\n",
        "\n",
        "    if not match.empty:\n",
        "        return match.iloc[0]['bin_label']\n",
        "    return None\n",
        "\n",
        "def process_midpoint(df, group_name, reference_df, ref_type=\"stage\"):\n",
        "    if 'accepted_name' not in df.columns:\n",
        "        print(f\"    Error: 'accepted_name' column missing.\")\n",
        "        return None\n",
        "\n",
        "    df['genus_name'] = df['accepted_name'].apply(extract_genus)\n",
        "    df = df.dropna(subset=['genus_name'])\n",
        "\n",
        "    # Midpoint Logic\n",
        "    df['midpoint'] = (df['max_ma'] + df['min_ma']) / 2\n",
        "\n",
        "    if ref_type == \"stage\":\n",
        "        df['assigned_interval'] = df['midpoint'].apply(lambda x: get_stage_from_age(x, reference_df))\n",
        "        merge_col = 'stage'\n",
        "    else:\n",
        "        df['assigned_interval'] = df['midpoint'].apply(lambda x: get_bin_from_age(x, reference_df))\n",
        "        merge_col = 'bin_label'\n",
        "\n",
        "    df = df.dropna(subset=['assigned_interval'])\n",
        "\n",
        "    # Aggregation\n",
        "    genus_counts = df.groupby('assigned_interval')['genus_name'].nunique()\n",
        "    genus_counts.name = f'{group_name}_genus'\n",
        "    occ_counts = df.groupby('assigned_interval')['occurrence_no'].nunique()\n",
        "    occ_counts.name = f'{group_name}_occ'\n",
        "\n",
        "    # Merging\n",
        "    final_df = reference_df.copy()\n",
        "    final_df = final_df.merge(genus_counts, left_on=merge_col, right_index=True, how='left')\n",
        "    final_df = final_df.merge(occ_counts, left_on=merge_col, right_index=True, how='left')\n",
        "\n",
        "    # Cleanup\n",
        "    cols_to_fix = [f'{group_name}_genus', f'{group_name}_occ']\n",
        "    final_df[cols_to_fix] = final_df[cols_to_fix].fillna(0).astype(int)\n",
        "\n",
        "    return final_df\n",
        "\n",
        "# ==========================================\n",
        "# 4. MAIN EXECUTION LOOP\n",
        "# ==========================================\n",
        "print(\"\\n--- STARTING ANALYSIS (Generic 485.0 Bins) ---\")\n",
        "\n",
        "for file_path in found_files:\n",
        "    filename = os.path.basename(file_path)\n",
        "    group_name = filename.replace(\"pbdb_data_\", \"\").replace(\".csv\", \"\")\n",
        "    print(f\"\\nAnalyzing {group_name}...\")\n",
        "\n",
        "    df = smart_read_pbdb(file_path)\n",
        "    if df is not None:\n",
        "        try:\n",
        "            # A. Stages\n",
        "            stage_df = process_midpoint(df.copy(), group_name, stages_df, \"stage\")\n",
        "            if stage_df is not None:\n",
        "                out_stage = f\"pbdb_{group_name}_midpoint_stages.csv\"\n",
        "                stage_df.to_csv(out_stage, index=False)\n",
        "                print(f\"  -> Created: {out_stage}\")\n",
        "\n",
        "            # B. 5-Myr Bins\n",
        "            bin_df = process_midpoint(df.copy(), group_name, bins_5myr_df, \"bin\")\n",
        "            if bin_df is not None:\n",
        "                out_bin = f\"pbdb_{group_name}_midpoint_5myr_bins.csv\"\n",
        "                bin_df.to_csv(out_bin, index=False)\n",
        "                print(f\"  -> Created: {out_bin}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  Error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"DONE! New 485.0-aligned bin files created.\")\n",
        "print(\"=\"*40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OHVXM-Zdbn9n",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "ba38a56c-7ab2-4b80-e1ed-c59af915ef77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following files are missing and need to be uploaded:\n",
            "  1. temperature.csv\n",
            "  2. DO.csv\n",
            "  3. oxygen.csv\n",
            "  4. sealevel.csv\n",
            "  5. d13C_5Myr_Cam-Dev.csv\n",
            "  6. d13C_stage_binned_Cam-Dev.csv\n",
            "\n",
            "Click 'Choose Files' and select the missing files...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1b0f15bf-3dd9-48b4-b288-5524df307d29\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1b0f15bf-3dd9-48b4-b288-5524df307d29\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving d13C_5Myr_Cam-Dev.csv to d13C_5Myr_Cam-Dev.csv\n",
            "Saving d13C_stage_binned_Cam-Dev.csv to d13C_stage_binned_Cam-Dev.csv\n",
            "Saving DO.csv to DO.csv\n",
            "Saving oxygen.csv to oxygen.csv\n",
            "Saving sealevel.csv to sealevel.csv\n",
            "Saving temperature.csv to temperature.csv\n",
            "\n",
            "✓ Uploaded 6 files:\n",
            "  - d13C_5Myr_Cam-Dev.csv\n",
            "  - d13C_stage_binned_Cam-Dev.csv\n",
            "  - DO.csv\n",
            "  - oxygen.csv\n",
            "  - sealevel.csv\n",
            "  - temperature.csv\n",
            "\n",
            "✓ 6 files ready for analysis\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "#@title CELL 5: UPLOAD ENVIRONMENT DATA FILES (Google Colab) - CONDITIONAL\n",
        "# =============================================================================\n",
        "\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# Define required files\n",
        "required_files = [\n",
        "    'temperature.csv',\n",
        "    'DO.csv',\n",
        "    'oxygen.csv',\n",
        "    'sealevel.csv',\n",
        "    'd13C_5Myr_Cam-Dev.csv',\n",
        "    'd13C_stage_binned_Cam-Dev.csv'\n",
        "]\n",
        "# Check which files are missing\n",
        "missing_files = [f for f in required_files if not os.path.exists(f)]\n",
        "\n",
        "if missing_files:\n",
        "    print(\"The following files are missing and need to be uploaded:\")\n",
        "    for i, f in enumerate(missing_files, 1):\n",
        "        print(f\"  {i}. {f}\")\n",
        "    print(\"\\nClick 'Choose Files' and select the missing files...\")\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    print(f\"\\n✓ Uploaded {len(uploaded)} files:\")\n",
        "    for fn in uploaded.keys():\n",
        "        print(f\"  - {fn}\")\n",
        "else:\n",
        "    print(\"✓ All required files already exist in the folder\")\n",
        "    uploaded = {}\n",
        "    # Load existing files into uploaded dict for compatibility\n",
        "    for f in required_files:\n",
        "        with open(f, 'rb') as file:\n",
        "            uploaded[f] = file.read()\n",
        "\n",
        "print(f\"\\n✓ {len(required_files)} files ready for analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_J9_ZRvYbrYT",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f29a038e-f647-4652-fc5e-84b377de4c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Stromatoporoid (Stage)...\n",
            "  ✓ Found: ./pbdb_Stromatoporida_midpoint_stages.csv\n",
            "  ✓ Found: ./pbdb_Labechiida_midpoint_stages.csv\n",
            "  ✓ Found: ./pbdb_Actinostromatida_midpoint_stages.csv\n",
            "  ✓ Found: ./pbdb_Clathrodictyida_midpoint_stages.csv\n",
            "  ✓ Found: ./pbdb_Syringostromatida_midpoint_stages.csv\n",
            "  ✓ Found: ./pbdb_Stromatoporellida_midpoint_stages.csv\n",
            "  ✓ Found: ./pbdb_Amphiporida_midpoint_stages.csv\n",
            "  -> Dropped 1 Stromatoporoid stage(s) with zero occurrences.\n",
            "  -> Merged Stromatoporoid Stages. Rows: 21\n",
            "\n",
            "Processing Coral (Stage)...\n",
            "  ✓ Found: ./pbdb_Tabulata_midpoint_stages.csv\n",
            "  ✓ Found: ./pbdb_Rugosa_midpoint_stages.csv\n",
            "  -> Dropped 1 Coral stage(s) with zero occurrences.\n",
            "  -> Merged Coral Stages. Rows: 21\n",
            "\n",
            "Processing Stromatoporoid (5-Myr)...\n",
            "  ✓ Found: ./pbdb_Stromatoporida_midpoint_5myr_bins.csv\n",
            "  ✓ Found: ./pbdb_Labechiida_midpoint_5myr_bins.csv\n",
            "  ✓ Found: ./pbdb_Actinostromatida_midpoint_5myr_bins.csv\n",
            "  ✓ Found: ./pbdb_Clathrodictyida_midpoint_5myr_bins.csv\n",
            "  ✓ Found: ./pbdb_Syringostromatida_midpoint_5myr_bins.csv\n",
            "  ✓ Found: ./pbdb_Stromatoporellida_midpoint_5myr_bins.csv\n",
            "  ✓ Found: ./pbdb_Amphiporida_midpoint_5myr_bins.csv\n",
            "  -> Dropped 2 Stromatoporoid 5-Myr bin(s) with zero occurrences.\n",
            "  -> Merged Stromatoporoid 5-Myr Bins. Rows: 24\n",
            "\n",
            "Processing Coral (5-Myr)...\n",
            "  ✓ Found: ./pbdb_Tabulata_midpoint_5myr_bins.csv\n",
            "  ✓ Found: ./pbdb_Rugosa_midpoint_5myr_bins.csv\n",
            "  -> Dropped 1 Coral 5-Myr bin(s) with zero occurrences.\n",
            "  -> Merged Coral 5-Myr Bins. Rows: 25\n",
            "\n",
            "Loading Contextual Data...\n",
            "\n",
            "✓ Data loading complete.\n",
            "\n",
            "Saving intermediate merged datasets...\n",
            "✓ Intermediate files saved to ./output\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# @title CELL 6: LOAD AND PROCESS DATA (FROM CONTENT FOLDER)\n",
        "# =============================================================================\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Helper: Find file path by keywords in the current directory\n",
        "def get_file_path_robust(keywords, search_dir='.'):\n",
        "    \"\"\"\n",
        "    Finds a filename in the search_dir that contains ALL keywords (case-insensitive).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        files = os.listdir(search_dir)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"  ! Error: Directory '{search_dir}' not found.\")\n",
        "        return None\n",
        "\n",
        "    for filename in files:\n",
        "        if not filename.endswith(('.csv', '.xlsx', '.xls')):\n",
        "            continue\n",
        "        # Check if ALL keywords are present in this filename\n",
        "        if all(str(k).lower() in filename.lower() for k in keywords):\n",
        "            return os.path.join(search_dir, filename)\n",
        "    return None\n",
        "\n",
        "def load_and_merge_from_disk(target_list, merge_cols, dataset_name):\n",
        "    \"\"\"\n",
        "    Iterates through a list of target filenames, finds them on disk, and merges them.\n",
        "    \"\"\"\n",
        "    merged_df = None\n",
        "    print(f\"\\nProcessing {dataset_name}...\")\n",
        "\n",
        "    for target in target_list:\n",
        "        # Extract keywords from the target filename\n",
        "        clean_name = target.replace('.csv', '').replace('.xlsx', '')\n",
        "        keywords = [k for k in clean_name.split('_') if k and k.lower() != 'pbdb']\n",
        "\n",
        "        # Search for the file\n",
        "        filepath = get_file_path_robust(keywords)\n",
        "\n",
        "        if filepath:\n",
        "            print(f\"  ✓ Found: {filepath}\")\n",
        "            try:\n",
        "                df = pd.read_csv(filepath)\n",
        "                df.columns = df.columns.str.strip()\n",
        "\n",
        "                if merged_df is None:\n",
        "                    merged_df = df\n",
        "                else:\n",
        "                    merged_df = pd.merge(merged_df, df, on=merge_cols, how='outer')\n",
        "            except Exception as e:\n",
        "                print(f\"  ! Error reading {filepath}: {e}\")\n",
        "        else:\n",
        "            # Retry with minimal keywords (Taxon + Resolution)\n",
        "            # This handles cases where the user filename might differ slightly from the instruction\n",
        "            taxon = next((k for k in keywords if k.lower() not in ['midpoint', 'stages', '5myr', 'bins']), None)\n",
        "            resolution = '5myr' if '5myr' in target.lower() else 'stages'\n",
        "\n",
        "            if taxon:\n",
        "                filepath_retry = get_file_path_robust([taxon, resolution])\n",
        "                if filepath_retry:\n",
        "                    print(f\"  ✓ Found (fallback): {filepath_retry}\")\n",
        "                    try:\n",
        "                        df = pd.read_csv(filepath_retry)\n",
        "                        df.columns = df.columns.str.strip()\n",
        "                        if merged_df is None: merged_df = df\n",
        "                        else: merged_df = pd.merge(merged_df, df, on=merge_cols, how='outer')\n",
        "                    except Exception as e:\n",
        "                        print(f\"  ! Error reading {filepath_retry}: {e}\")\n",
        "                else:\n",
        "                     print(f\"  x Could not find file for: {taxon} ({resolution})\")\n",
        "            else:\n",
        "                 print(f\"  x Could not find file matching: {keywords}\")\n",
        "\n",
        "    return merged_df\n",
        "\n",
        "# Common merge columns\n",
        "stage_merge_cols = ['stage', 'series', 'period', 'start_ma', 'end_ma']\n",
        "bin_merge_cols = ['bin_label', 'bin_top', 'bin_bottom']\n",
        "\n",
        "# =============================================================================\n",
        "# 1. Substitute Stromatoporoid Data (Stage)\n",
        "# =============================================================================\n",
        "strom_stage_targets = [\n",
        "    \"pbdb_Stromatoporida_midpoint_stages.csv\",\n",
        "    \"pbdb_Labechiida_midpoint_stages.csv\",\n",
        "    \"pbdb_Actinostromatida_midpoint_stages.csv\",\n",
        "    \"pbdb_clathrodictyida_midpoint_stages.csv\",\n",
        "    \"pbdb_Syringostromatida_midpoint_stages.csv\",\n",
        "    \"pbdb_Stromatoporellida_midpoint_stages.csv\",\n",
        "    \"pbdb_Amphiporida_midpoint_stages.csv\"\n",
        "]\n",
        "\n",
        "strom_df = load_and_merge_from_disk(strom_stage_targets, stage_merge_cols, \"Stromatoporoid (Stage)\")\n",
        "\n",
        "if strom_df is not None:\n",
        "    strom_df = strom_df.fillna(0)\n",
        "    # Calculate Totals\n",
        "    genus_cols = [c for c in strom_df.columns if c.endswith('_genus')]\n",
        "    occ_cols = [c for c in strom_df.columns if c.endswith('_occ')]\n",
        "    strom_df['Total_genus'] = strom_df[genus_cols].sum(axis=1)\n",
        "    strom_df['Total_occ'] = strom_df[occ_cols].sum(axis=1)\n",
        "\n",
        "    # === FILTER: Remove empty stages ===\n",
        "    dropped_s = len(strom_df[strom_df['Total_occ'] == 0])\n",
        "    strom_df = strom_df[strom_df['Total_occ'] > 0].copy()\n",
        "    if dropped_s > 0:\n",
        "        print(f\"  -> Dropped {dropped_s} Stromatoporoid stage(s) with zero occurrences.\")\n",
        "    # ===================================\n",
        "\n",
        "    print(f\"  -> Merged Stromatoporoid Stages. Rows: {len(strom_df)}\")\n",
        "else:\n",
        "    print(\"  ! Error: Stromatoporoid dataframe is empty.\")\n",
        "\n",
        "# =============================================================================\n",
        "# 2. Substitute Coral Data (Stage)\n",
        "# =============================================================================\n",
        "coral_stage_targets = [\n",
        "    \"pbdb_tabulata_midpoint_stages.csv\",\n",
        "    \"pbdb_Rugosa_midpoint_stages.csv\"\n",
        "]\n",
        "\n",
        "coral_df = load_and_merge_from_disk(coral_stage_targets, stage_merge_cols, \"Coral (Stage)\")\n",
        "\n",
        "if coral_df is not None:\n",
        "    coral_df = coral_df.fillna(0)\n",
        "\n",
        "    # Calculate Totals (Added for filtering)\n",
        "    c_genus_cols = [c for c in coral_df.columns if c.endswith('_genus')]\n",
        "    c_occ_cols = [c for c in coral_df.columns if c.endswith('_occ')]\n",
        "    coral_df['Total_genus'] = coral_df[c_genus_cols].sum(axis=1)\n",
        "    coral_df['Total_occ'] = coral_df[c_occ_cols].sum(axis=1)\n",
        "\n",
        "    # === FILTER: Remove empty stages ===\n",
        "    dropped_c = len(coral_df[coral_df['Total_occ'] == 0])\n",
        "    coral_df = coral_df[coral_df['Total_occ'] > 0].copy()\n",
        "    if dropped_c > 0:\n",
        "        print(f\"  -> Dropped {dropped_c} Coral stage(s) with zero occurrences.\")\n",
        "    # ===================================\n",
        "\n",
        "    print(f\"  -> Merged Coral Stages. Rows: {len(coral_df)}\")\n",
        "\n",
        "# =============================================================================\n",
        "# 3. Create New Dataset for 5-Myr Bins\n",
        "# =============================================================================\n",
        "# Stromatoporoids\n",
        "strom_bin_targets = [\n",
        "    \"pbdb_Stromatoporida_midpoint_5myr_bins.csv\",\n",
        "    \"pbdb_Labechiida_midpoint_5myr_bins.csv\",\n",
        "    \"pbdb_Actinostromatida_midpoint_5myr_bins.csv\",\n",
        "    \"pbdb_clathrodictyida_midpoint_5myr_bins.csv\",\n",
        "    \"pbdb_Syringostromatida_midpoint_5myr_bins.csv\",\n",
        "    \"pbdb_Stromatoporellida_midpoint_5myr_bins.csv\",\n",
        "    \"pbdb_Amphiporida_midpoint_5myr_bins.csv\"\n",
        "]\n",
        "\n",
        "strom_5myr_df = load_and_merge_from_disk(strom_bin_targets, bin_merge_cols, \"Stromatoporoid (5-Myr)\")\n",
        "\n",
        "if strom_5myr_df is not None:\n",
        "    strom_5myr_df = strom_5myr_df.fillna(0)\n",
        "    genus_cols = [c for c in strom_5myr_df.columns if c.endswith('_genus')]\n",
        "    occ_cols = [c for c in strom_5myr_df.columns if c.endswith('_occ')]\n",
        "    strom_5myr_df['Total_genus'] = strom_5myr_df[genus_cols].sum(axis=1)\n",
        "    strom_5myr_df['Total_occ'] = strom_5myr_df[occ_cols].sum(axis=1)\n",
        "\n",
        "    # === FILTER: Remove empty bins ===\n",
        "    dropped_s5 = len(strom_5myr_df[strom_5myr_df['Total_occ'] == 0])\n",
        "    strom_5myr_df = strom_5myr_df[strom_5myr_df['Total_occ'] > 0].copy()\n",
        "    if dropped_s5 > 0:\n",
        "        print(f\"  -> Dropped {dropped_s5} Stromatoporoid 5-Myr bin(s) with zero occurrences.\")\n",
        "    # =================================\n",
        "\n",
        "    print(f\"  -> Merged Stromatoporoid 5-Myr Bins. Rows: {len(strom_5myr_df)}\")\n",
        "\n",
        "# Corals\n",
        "coral_bin_targets = [\n",
        "    \"pbdb_tabulata_midpoint_5myr_bins.csv\",\n",
        "    \"pbdb_Rugosa_midpoint_5myr_bins.csv\"\n",
        "]\n",
        "coral_5myr_df = load_and_merge_from_disk(coral_bin_targets, bin_merge_cols, \"Coral (5-Myr)\")\n",
        "\n",
        "if coral_5myr_df is not None:\n",
        "    coral_5myr_df = coral_5myr_df.fillna(0)\n",
        "\n",
        "    # Calculate Totals (Added for filtering)\n",
        "    c5_genus_cols = [c for c in coral_5myr_df.columns if c.endswith('_genus')]\n",
        "    c5_occ_cols = [c for c in coral_5myr_df.columns if c.endswith('_occ')]\n",
        "    coral_5myr_df['Total_genus'] = coral_5myr_df[c5_genus_cols].sum(axis=1)\n",
        "    coral_5myr_df['Total_occ'] = coral_5myr_df[c5_occ_cols].sum(axis=1)\n",
        "\n",
        "    # === FILTER: Remove empty bins ===\n",
        "    dropped_c5 = len(coral_5myr_df[coral_5myr_df['Total_occ'] == 0])\n",
        "    coral_5myr_df = coral_5myr_df[coral_5myr_df['Total_occ'] > 0].copy()\n",
        "    if dropped_c5 > 0:\n",
        "        print(f\"  -> Dropped {dropped_c5} Coral 5-Myr bin(s) with zero occurrences.\")\n",
        "    # =================================\n",
        "\n",
        "    print(f\"  -> Merged Coral 5-Myr Bins. Rows: {len(coral_5myr_df)}\")\n",
        "\n",
        "# =============================================================================\n",
        "# 4. Load Remaining Contextual Data\n",
        "# =============================================================================\n",
        "print(\"\\nLoading Contextual Data...\")\n",
        "\n",
        "def quick_load(keywords):\n",
        "    path = get_file_path_robust(keywords)\n",
        "    return pd.read_csv(path) if path else pd.DataFrame()\n",
        "\n",
        "reef_df = quick_load([\"reef_data\", \"stage\"])\n",
        "reef_5myr_df = quick_load([\"reef_data\", \"5myr\"])\n",
        "\n",
        "macro_stage = quick_load([\"paleozoic_stage_data\"])\n",
        "if 'stage' in macro_stage.columns: macro_stage['stage'] = macro_stage['stage'].replace('Pridolian', 'Pridoli')\n",
        "\n",
        "macro_5myr = quick_load([\"paleozoic_5myr_data\"])\n",
        "\n",
        "# Environmental\n",
        "env_files = {\n",
        "    'temperature': 'temperature',\n",
        "    'do': 'DO',\n",
        "    'oxygen': 'oxygen',\n",
        "    'sealevel': 'sealevel',\n",
        "    # δ13C files (already binned; DO NOT re-bin/interpolate these)\n",
        "    'd13c_5myr': 'd13C_5Myr_Cam-Dev',\n",
        "    'd13c_stage': 'd13C_stage_binned_Cam-Dev'\n",
        "}\n",
        "env_dfs = {}\n",
        "for var, key in env_files.items():\n",
        "    df = quick_load([key])\n",
        "    if not df.empty: df.columns = df.columns.str.strip().str.replace('\\ufeff', '')\n",
        "    env_dfs[var] = df\n",
        "\n",
        "temp_df = env_dfs.get('temperature', pd.DataFrame())\n",
        "do_df = env_dfs.get('do', pd.DataFrame())\n",
        "oxygen_df = env_dfs.get('oxygen', pd.DataFrame())\n",
        "sealevel_df = env_dfs.get('sealevel', pd.DataFrame())\n",
        "d13c_5myr_df = env_dfs.get('d13c_5myr', pd.DataFrame())\n",
        "d13c_stage_df = env_dfs.get('d13c_stage', pd.DataFrame())\n",
        "print(\"\\n✓ Data loading complete.\")\n",
        "\n",
        "print(\"\\nSaving intermediate merged datasets...\")\n",
        "\n",
        "if 'strom_df' in locals() and strom_df is not None:\n",
        "    strom_df.to_csv(f\"{OUTPUT_DIR}/intermediate_strom_stage.csv\", index=False)\n",
        "if 'coral_df' in locals() and coral_df is not None:\n",
        "    coral_df.to_csv(f\"{OUTPUT_DIR}/intermediate_coral_stage.csv\", index=False)\n",
        "\n",
        "if 'strom_5myr_df' in locals() and strom_5myr_df is not None:\n",
        "    strom_5myr_df.to_csv(f\"{OUTPUT_DIR}/intermediate_strom_5myr.csv\", index=False)\n",
        "if 'coral_5myr_df' in locals() and coral_5myr_df is not None:\n",
        "    coral_5myr_df.to_csv(f\"{OUTPUT_DIR}/intermediate_coral_5myr.csv\", index=False)\n",
        "\n",
        "print(\"✓ Intermediate files saved to ./output\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZqhKwRrKbtoq",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e972af05-0d52-4972-e773-457e6278c740"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Constants defined and DataFrames normalized.\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# @title CELL 7: DEFINE CONSTANTS AND STAGE INFORMATION\n",
        "# =============================================================================\n",
        "\n",
        "# 1. Stage definitions (ICS 2023)\n",
        "STAGES = {\n",
        "    'Tremadocian': {'start': 485.4, 'end': 477.7, 'mid': 481.55, 'period': 'Ordovician'},\n",
        "    'Floian': {'start': 477.7, 'end': 470.0, 'mid': 473.85, 'period': 'Ordovician'},\n",
        "    'Dapingian': {'start': 470.0, 'end': 467.3, 'mid': 468.65, 'period': 'Ordovician'},\n",
        "    'Darriwilian': {'start': 467.3, 'end': 458.4, 'mid': 462.85, 'period': 'Ordovician'},\n",
        "    'Sandbian': {'start': 458.4, 'end': 453.0, 'mid': 455.7, 'period': 'Ordovician'},\n",
        "    'Katian': {'start': 453.0, 'end': 445.2, 'mid': 449.1, 'period': 'Ordovician'},\n",
        "    'Hirnantian': {'start': 445.2, 'end': 443.8, 'mid': 444.5, 'period': 'Ordovician'},\n",
        "    'Rhuddanian': {'start': 443.8, 'end': 440.8, 'mid': 442.3, 'period': 'Silurian'},\n",
        "    'Aeronian': {'start': 440.8, 'end': 438.5, 'mid': 439.65, 'period': 'Silurian'},\n",
        "    'Telychian': {'start': 438.5, 'end': 433.4, 'mid': 435.95, 'period': 'Silurian'},\n",
        "    'Sheinwoodian': {'start': 433.4, 'end': 430.5, 'mid': 431.95, 'period': 'Silurian'},\n",
        "    'Homerian': {'start': 430.5, 'end': 427.4, 'mid': 428.95, 'period': 'Silurian'},\n",
        "    'Gorstian': {'start': 427.4, 'end': 425.6, 'mid': 426.5, 'period': 'Silurian'},\n",
        "    'Ludfordian': {'start': 425.6, 'end': 423.0, 'mid': 424.3, 'period': 'Silurian'},\n",
        "    'Pridoli': {'start': 423.0, 'end': 419.2, 'mid': 421.1, 'period': 'Silurian'},\n",
        "    'Lochkovian': {'start': 419.2, 'end': 410.8, 'mid': 415.0, 'period': 'Devonian'},\n",
        "    'Pragian': {'start': 410.8, 'end': 407.6, 'mid': 409.2, 'period': 'Devonian'},\n",
        "    'Emsian': {'start': 407.6, 'end': 393.3, 'mid': 400.45, 'period': 'Devonian'},\n",
        "    'Eifelian': {'start': 393.3, 'end': 387.7, 'mid': 390.5, 'period': 'Devonian'},\n",
        "    'Givetian': {'start': 387.7, 'end': 382.7, 'mid': 385.2, 'period': 'Devonian'},\n",
        "    'Frasnian': {'start': 382.7, 'end': 372.2, 'mid': 377.45, 'period': 'Devonian'},\n",
        "    'Famennian': {'start': 372.2, 'end': 358.9, 'mid': 365.55, 'period': 'Devonian'}\n",
        "}\n",
        "STAGE_ORDER = list(STAGES.keys())\n",
        "\n",
        "# 2. Period colors (ICS standard)\n",
        "PERIOD_COLORS = {\n",
        "    'Ordovician': '#009270',\n",
        "    'Silurian': '#B3E1B6',\n",
        "    'Devonian': '#CB8C37'\n",
        "}\n",
        "\n",
        "# 3. Stromatoporoid order colors (phylogenetically informed)\n",
        "STROM_COLORS = {\n",
        "    'Labechiida': '#8B0000',       # Dark red - basal\n",
        "    'Clathrodictyida': '#CD5C5C',  # Indian red - early-diverging\n",
        "    'Actinostromatida': '#FF8C00', # Dark orange - derived\n",
        "    'Stromatoporida': '#FFD700',   # Gold - derived\n",
        "    'Stromatoporellida': '#32CD32',# Lime green - derived\n",
        "    'Syringostromatida': '#4169E1',# Royal blue - derived reef builders\n",
        "    'Amphiporida': '#9370DB'       # Medium purple - derived\n",
        "}\n",
        "STROM_ORDERS = ['Labechiida', 'Clathrodictyida', 'Actinostromatida',\n",
        "                'Stromatoporida', 'Stromatoporellida', 'Syringostromatida', 'Amphiporida']\n",
        "\n",
        "# 4. Coral colors (New definitions for Rugosa/Tabulata)\n",
        "CORAL_COLORS = {\n",
        "    'Rugosa': '#800080',    # Purple\n",
        "    'Tabulata': '#D2691E'   # Chocolate/Orange-Brown\n",
        "}\n",
        "CORAL_GROUPS = ['Rugosa', 'Tabulata']\n",
        "\n",
        "# =============================================================================\n",
        "# DATA NORMALIZATION: Ensure DataFrame columns match capitalized constants\n",
        "# =============================================================================\n",
        "# Some files were lowercase (e.g., 'clathrodictyida'), but constants are TitleCase.\n",
        "# We fix this here to prevent KeyErrors in future plotting cells.\n",
        "\n",
        "def normalize_columns(df, target_orders):\n",
        "    if df is None: return df\n",
        "\n",
        "    # Get current columns\n",
        "    cols = df.columns.tolist()\n",
        "    rename_map = {}\n",
        "\n",
        "    for order in target_orders:\n",
        "        # Check if TitleCase version exists (e.g., 'Clathrodictyida_genus')\n",
        "        title_genus = f\"{order}_genus\"\n",
        "        title_occ = f\"{order}_occ\"\n",
        "\n",
        "        # Check if LowerCase version exists (e.g., 'clathrodictyida_genus')\n",
        "        lower_genus = f\"{order.lower()}_genus\"\n",
        "        lower_occ = f\"{order.lower()}_occ\"\n",
        "\n",
        "        # If TitleCase missing but LowerCase present, map Lower -> Title\n",
        "        if title_genus not in cols and lower_genus in cols:\n",
        "            rename_map[lower_genus] = title_genus\n",
        "        if title_occ not in cols and lower_occ in cols:\n",
        "            rename_map[lower_occ] = title_occ\n",
        "\n",
        "        # Also handle \"tabulata\" (lowercase t)\n",
        "        if order == 'Tabulata' and 'tabulata_genus' in cols:\n",
        "             rename_map['tabulata_genus'] = 'Tabulata_genus'\n",
        "             rename_map['tabulata_occ'] = 'Tabulata_occ'\n",
        "\n",
        "    if rename_map:\n",
        "        print(f\"  Note: Renaming columns to match standard capitalization: {list(rename_map.keys())}\")\n",
        "        df = df.rename(columns=rename_map)\n",
        "    return df\n",
        "\n",
        "# Apply normalization to the datasets loaded in Cell 5\n",
        "if 'strom_df' in locals(): strom_df = normalize_columns(strom_df, STROM_ORDERS)\n",
        "if 'strom_5myr_df' in locals(): strom_5myr_df = normalize_columns(strom_5myr_df, STROM_ORDERS)\n",
        "if 'coral_df' in locals(): coral_df = normalize_columns(coral_df, CORAL_GROUPS)\n",
        "if 'coral_5myr_df' in locals(): coral_5myr_df = normalize_columns(coral_5myr_df, CORAL_GROUPS)\n",
        "\n",
        "print(\"✓ Constants defined and DataFrames normalized.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2mRadY5BbvJm",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fbf24fb-bea7-4bdd-c514-82dc26e4b75f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading environmental datasets...\n",
            "  ✓ Loaded temperature.csv (387 rows)\n",
            "  ✓ Loaded DO.csv (499 rows)\n",
            "  ✓ Loaded oxygen.csv (58 rows)\n",
            "  ✓ Loaded sealevel.csv (101 rows)\n",
            "\n",
            "Interpolating environmental proxies to stage midpoints...\n",
            "  -> δ13C (stage-binned) merged: 22/22 values\n",
            "\n",
            "Interpolating environmental proxies to 5-Myr bin midpoints...\n",
            "  -> δ13C (5-Myr binned) merged: 27/27 values\n",
            "✓ Environmental proxies interpolated (Stage & 5-Myr).\n",
            "✓ Interpolated environmental data saved to ./output\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# @title CELL 8: RELOAD ENV DATA & INTERPOLATE (ROBUST FIX)\n",
        "# =============================================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.interpolate import interp1d\n",
        "import os\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 1. RELOAD ENVIRONMENTAL DATA (To ensure it is not empty)\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"Reloading environmental datasets...\")\n",
        "\n",
        "def load_env_file(filenames, target_cols):\n",
        "    \"\"\"Try to load a file from a list of possible names\"\"\"\n",
        "    for fname in filenames:\n",
        "        if os.path.exists(fname):\n",
        "            try:\n",
        "                df = pd.read_csv(fname)\n",
        "                df.columns = df.columns.str.strip() # clean whitespace\n",
        "                print(f\"  ✓ Loaded {fname} ({len(df)} rows)\")\n",
        "                return df\n",
        "            except Exception as e:\n",
        "                print(f\"  ! Error loading {fname}: {e}\")\n",
        "    print(f\"  ! WARNING: Could not find any of {filenames}\")\n",
        "    return pd.DataFrame() # Return empty if not found\n",
        "\n",
        "# Load with specific fallbacks\n",
        "temp_df     = load_env_file(['temperature.csv', 'Temperature.csv'], ['Age', 'SST'])\n",
        "do_df       = load_env_file(['DO.csv', 'do.csv'], ['Age', 'DO'])\n",
        "oxygen_df   = load_env_file(['oxygen.csv', 'Oxygen.csv'], ['Age', 'O2'])\n",
        "sealevel_df = load_env_file(['sealevel.csv', 'Sealevel.csv'], ['Age', 'Eustatic'])\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 2. STANDARDIZE COLUMNS\n",
        "# -----------------------------------------------------------------------------\n",
        "def standardize_env_columns(df, name, target_age='Age', target_val=None):\n",
        "    if df.empty: return df\n",
        "\n",
        "    # Fix Age column\n",
        "    if target_age not in df.columns:\n",
        "        for candidate in ['age', 'AGE', 'Time', 'Ma', 'time']:\n",
        "            if candidate in df.columns:\n",
        "                df = df.rename(columns={candidate: target_age})\n",
        "                break\n",
        "\n",
        "    # Fix Value column\n",
        "    if target_val and target_val not in df.columns:\n",
        "        # Check case-insensitive match\n",
        "        for col in df.columns:\n",
        "            if col.lower() == target_val.lower():\n",
        "                df = df.rename(columns={col: target_val})\n",
        "                break\n",
        "\n",
        "    return df\n",
        "\n",
        "do_df = standardize_env_columns(do_df, 'Dissolved Oxygen', target_val='DO')\n",
        "temp_df = standardize_env_columns(temp_df, 'Temperature', target_val='SST')\n",
        "oxygen_df = standardize_env_columns(oxygen_df, 'Atmosphere', target_age='Age')\n",
        "sealevel_df = standardize_env_columns(sealevel_df, 'Sea Level', target_val='Eustatic Sea Level')\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 3. INTERPOLATION\n",
        "# -----------------------------------------------------------------------------\n",
        "def interpolate_to_ages(source_df, age_col, value_col, target_ages):\n",
        "    \"\"\"Interpolate values to target ages, skipping if columns missing.\"\"\"\n",
        "    # Check if empty or missing columns\n",
        "    if source_df.empty or age_col not in source_df.columns or value_col not in source_df.columns:\n",
        "        return np.full_like(target_ages, np.nan)\n",
        "\n",
        "    # Drop NaNs in source\n",
        "    source_df = source_df.dropna(subset=[age_col, value_col])\n",
        "    # Sort by Age (Crucial for interp1d)\n",
        "    source_df = source_df.sort_values(age_col)\n",
        "\n",
        "    if len(source_df) < 2:\n",
        "        return np.full_like(target_ages, np.nan)\n",
        "\n",
        "    # Interpolate\n",
        "    f = interp1d(source_df[age_col], source_df[value_col],\n",
        "                 kind='linear', fill_value='extrapolate', bounds_error=False)\n",
        "    return f(target_ages)\n",
        "\n",
        "# Get Stage Midpoints from Cell 7 constants\n",
        "stage_midpoints = np.array([STAGES[s]['mid'] for s in STAGE_ORDER])\n",
        "\n",
        "print(\"\\nInterpolating environmental proxies to stage midpoints...\")\n",
        "env_data = pd.DataFrame({'stage': STAGE_ORDER, 'midpoint_ma': stage_midpoints})\n",
        "\n",
        "env_data['temperature']     = interpolate_to_ages(temp_df, 'Age', 'SST', stage_midpoints)\n",
        "env_data['dissolved_O2']    = interpolate_to_ages(do_df, 'Age', 'DO', stage_midpoints)\n",
        "env_data['atm_O2']          = interpolate_to_ages(oxygen_df, 'Age', 'O2', stage_midpoints)\n",
        "env_data['atm_CO2']         = interpolate_to_ages(oxygen_df, 'Age', 'CO2', stage_midpoints)\n",
        "env_data['sea_level']       = interpolate_to_ages(sealevel_df, 'Age', 'Eustatic Sea Level', stage_midpoints)\n",
        "# -----------------------------------------------------------------------------\n",
        "# -----------------------------------------------------------------------------\n",
        "# MERGE δ13C (STAGE-BINNED) — prefer Stage-name join; fallback to age-nearest\n",
        "# Uses attached d13C_stage_binned_Cam-Dev.csv WITHOUT re-binning/conversion.\n",
        "# -----------------------------------------------------------------------------\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "def _norm_stage(s):\n",
        "    if pd.isna(s):\n",
        "        return np.nan\n",
        "    s = str(s).strip().lower()\n",
        "    # remove spaces/punct to survive minor naming differences\n",
        "    return re.sub(r'[^a-z0-9]+', '', s)\n",
        "\n",
        "try:\n",
        "    # Load attached stage-binned δ13C table\n",
        "    cand = [\n",
        "        Path(\"d13C_stage_binned_Cam-Dev.csv\"),\n",
        "        Path(\"/mnt/data/d13C_stage_binned_Cam-Dev.csv\")\n",
        "    ]\n",
        "    f = next((p for p in cand if p.exists()), None)\n",
        "    if f is None:\n",
        "        raise FileNotFoundError(\"d13C_stage_binned_Cam-Dev.csv not found in working dir or /mnt/data\")\n",
        "\n",
        "    d13_stage = pd.read_csv(f)\n",
        "    d13_stage.columns = d13_stage.columns.str.strip().str.replace('\\ufeff', '')\n",
        "\n",
        "    # Required columns in attached file\n",
        "    if \"Stage\" not in d13_stage.columns or \"Mid_Ma\" not in d13_stage.columns or \"d13C_mean\" not in d13_stage.columns:\n",
        "        raise ValueError(\"δ13C stage file must have columns: Stage, Mid_Ma, d13C_mean\")\n",
        "\n",
        "    # Clean numeric + stage keys\n",
        "    d13_stage[\"Mid_Ma\"] = pd.to_numeric(d13_stage[\"Mid_Ma\"], errors=\"coerce\")\n",
        "    d13_stage[\"d13C_mean\"] = pd.to_numeric(d13_stage[\"d13C_mean\"], errors=\"coerce\")\n",
        "    d13_stage[\"stage_key\"] = d13_stage[\"Stage\"].apply(_norm_stage)\n",
        "\n",
        "    env_data[\"midpoint_ma\"] = pd.to_numeric(env_data[\"midpoint_ma\"], errors=\"coerce\")\n",
        "\n",
        "    # --- 1) Stage-name merge (best) ---\n",
        "    if \"stage\" in env_data.columns:\n",
        "        env_data[\"stage_key\"] = env_data[\"stage\"].apply(_norm_stage)\n",
        "\n",
        "        _m1 = env_data.merge(\n",
        "            d13_stage[[\"stage_key\", \"d13C_mean\", \"Mid_Ma\"]],\n",
        "            on=\"stage_key\",\n",
        "            how=\"left\",\n",
        "            suffixes=(\"\", \"_d13\")\n",
        "        )\n",
        "\n",
        "        # Keep δ13C as a single downstream name\n",
        "        _m1[\"d13C\"] = _m1[\"d13C_mean\"]\n",
        "\n",
        "        # --- 2) Fallback: for unmatched stages, fill by age-nearest ---\n",
        "        missing = _m1[\"d13C\"].isna() & _m1[\"midpoint_ma\"].notna()\n",
        "        if missing.any():\n",
        "            _left = _m1.loc[missing, [\"midpoint_ma\"]].copy().sort_values(\"midpoint_ma\")\n",
        "            _right = d13_stage[[\"Mid_Ma\", \"d13C_mean\"]].dropna().sort_values(\"Mid_Ma\")\n",
        "\n",
        "            _fill = pd.merge_asof(\n",
        "                _left,\n",
        "                _right,\n",
        "                left_on=\"midpoint_ma\",\n",
        "                right_on=\"Mid_Ma\",\n",
        "                direction=\"nearest\",\n",
        "                tolerance=2.0  # stage midpoints can differ by >0.25; allow reasonable slack\n",
        "            )\n",
        "            _m1.loc[missing, \"d13C\"] = _fill[\"d13C_mean\"].values\n",
        "\n",
        "        # Cleanup\n",
        "        env_data = _m1.drop(columns=[c for c in [\"d13C_mean\", \"Mid_Ma\", \"stage_key\"] if c in _m1.columns])\n",
        "        env_data = env_data.sort_values(\"midpoint_ma\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "    else:\n",
        "        # If env_data has no stage column, do age-nearest only (more tolerant)\n",
        "        _left = env_data.dropna(subset=[\"midpoint_ma\"]).sort_values(\"midpoint_ma\")\n",
        "        _right = d13_stage[[\"Mid_Ma\", \"d13C_mean\"]].dropna().sort_values(\"Mid_Ma\")\n",
        "        _m = pd.merge_asof(_left, _right, left_on=\"midpoint_ma\", right_on=\"Mid_Ma\", direction=\"nearest\", tolerance=2.0)\n",
        "        env_data = _m.drop(columns=[\"Mid_Ma\"]).rename(columns={\"d13C_mean\": \"d13C\"})\n",
        "        env_data = env_data.sort_values(\"midpoint_ma\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "    n_valid = int(env_data[\"d13C\"].notna().sum()) if \"d13C\" in env_data.columns else 0\n",
        "    print(f\"  -> δ13C (stage-binned) merged: {n_valid}/{len(env_data)} values\")\n",
        "\n",
        "except Exception as e:\n",
        "    env_data[\"d13C\"] = np.nan\n",
        "    print(\"  ! Warning: δ13C stage merge failed:\", e)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 4. INTERPOLATE TO 5-MYR BINS\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\nInterpolating environmental proxies to 5-Myr bin midpoints...\")\n",
        "\n",
        "# Define bins (Logic from previous step)\n",
        "if 'reef_5myr_df' in locals() and not reef_5myr_df.empty:\n",
        "    bin_midpoints_5myr = reef_5myr_df['midpoint_ma'].values\n",
        "    bin_ids = reef_5myr_df['time_identifier']\n",
        "elif 'strom_5myr_df' in locals() and not strom_5myr_df.empty:\n",
        "    # Recalculate if column missing\n",
        "    if 'midpoint_ma' not in strom_5myr_df.columns:\n",
        "        strom_5myr_df['midpoint_ma'] = (strom_5myr_df['bin_top'] + strom_5myr_df['bin_bottom']) / 2\n",
        "    bin_midpoints_5myr = strom_5myr_df['midpoint_ma'].values\n",
        "    bin_ids = strom_5myr_df['bin_label']\n",
        "else:\n",
        "    # Fallback\n",
        "    bin_midpoints_5myr = np.arange(482.5, 359, -5)\n",
        "    bin_ids = [f\"{x}\" for x in bin_midpoints_5myr]\n",
        "\n",
        "env_data_5myr = pd.DataFrame({'bin_id': bin_ids, 'midpoint_ma': bin_midpoints_5myr})\n",
        "\n",
        "env_data_5myr['temperature']     = interpolate_to_ages(temp_df, 'Age', 'SST', bin_midpoints_5myr)\n",
        "env_data_5myr['dissolved_O2']    = interpolate_to_ages(do_df, 'Age', 'DO', bin_midpoints_5myr)\n",
        "env_data_5myr['atm_O2']          = interpolate_to_ages(oxygen_df, 'Age', 'O2', bin_midpoints_5myr)\n",
        "env_data_5myr['atm_CO2']         = interpolate_to_ages(oxygen_df, 'Age', 'CO2', bin_midpoints_5myr)\n",
        "env_data_5myr['sea_level']       = interpolate_to_ages(sealevel_df, 'Age', 'Eustatic Sea Level', bin_midpoints_5myr)\n",
        "# -----------------------------------------------------------------------------\n",
        "# -----------------------------------------------------------------------------\n",
        "# 4b. MERGE δ13C (5-MYR BINNED) WITHOUT INTERPOLATION / RE-BINNING\n",
        "#   Float bin midpoints often differ by tiny rounding; if exact merge yields\n",
        "#   few/zero matches, fall back to merge_asof (requires ascending sort).\n",
        "# -----------------------------------------------------------------------------\n",
        "try:\n",
        "    if 'd13c_5myr_df' in globals() and isinstance(d13c_5myr_df, pd.DataFrame) and (not d13c_5myr_df.empty):\n",
        "        _d13_5 = d13c_5myr_df.copy()\n",
        "    else:\n",
        "        cand = [\n",
        "            'd13C_5Myr_Cam-Dev.csv',\n",
        "            './output/d13C_5Myr_Cam-Dev.csv',\n",
        "            'd13C_5Myr.csv',\n",
        "            './output/d13C_5Myr.csv'\n",
        "        ]\n",
        "        _d13_5 = None\n",
        "        for p in cand:\n",
        "            if os.path.exists(p):\n",
        "                _d13_5 = pd.read_csv(p)\n",
        "                break\n",
        "        if _d13_5 is None:\n",
        "            raise FileNotFoundError(\"No 5-Myr δ13C file found (tried: \" + \", \".join(cand) + \").\")\n",
        "\n",
        "    _d13_5.columns = _d13_5.columns.str.strip().str.replace('\\ufeff', '')\n",
        "\n",
        "    # Standardize columns\n",
        "    if 'age_Ma' in _d13_5.columns and 'midpoint_ma' not in _d13_5.columns:\n",
        "        _d13_5 = _d13_5.rename(columns={'age_Ma': 'midpoint_ma'})\n",
        "    if 'Mid_Ma' in _d13_5.columns and 'midpoint_ma' not in _d13_5.columns:\n",
        "        _d13_5 = _d13_5.rename(columns={'Mid_Ma': 'midpoint_ma'})\n",
        "    if 'd13Ccarb_permille' in _d13_5.columns and 'd13C' not in _d13_5.columns:\n",
        "        _d13_5 = _d13_5.rename(columns={'d13Ccarb_permille': 'd13C'})\n",
        "    if 'd13C_mean' in _d13_5.columns and 'd13C' not in _d13_5.columns:\n",
        "        _d13_5 = _d13_5.rename(columns={'d13C_mean': 'd13C'})\n",
        "\n",
        "    _d13_5['midpoint_ma'] = pd.to_numeric(_d13_5['midpoint_ma'], errors='coerce')\n",
        "    _d13_5['d13C'] = pd.to_numeric(_d13_5['d13C'], errors='coerce')\n",
        "    _d13_5 = _d13_5.dropna(subset=['midpoint_ma', 'd13C']).copy()\n",
        "\n",
        "    # --- Attempt exact merge after rounding to reduce floating mismatch\n",
        "    env_data_5myr['midpoint_ma'] = pd.to_numeric(env_data_5myr['midpoint_ma'], errors='coerce')\n",
        "    _left = env_data_5myr.copy()\n",
        "    _left['midpoint_ma_round'] = _left['midpoint_ma'].round(3)\n",
        "    _right = _d13_5[['midpoint_ma', 'd13C']].copy()\n",
        "    _right['midpoint_ma_round'] = _right['midpoint_ma'].round(3)\n",
        "\n",
        "    env_data_5myr = _left.merge(_right[['midpoint_ma_round', 'd13C']], on='midpoint_ma_round', how='left')\n",
        "    env_data_5myr = env_data_5myr.drop(columns=['midpoint_ma_round'])\n",
        "\n",
        "    n_valid = env_data_5myr['d13C'].notna().sum()\n",
        "\n",
        "    # --- Fallback: nearest-age join if exact merge fails\n",
        "    if n_valid == 0 and len(_d13_5) > 0:\n",
        "        _left_sorted = env_data_5myr.drop(columns=['d13C'], errors='ignore').copy()\n",
        "        _left_sorted = _left_sorted.dropna(subset=['midpoint_ma']).sort_values('midpoint_ma', ascending=True).reset_index(drop=True)\n",
        "\n",
        "        _right_sorted = _d13_5[['midpoint_ma', 'd13C']].sort_values('midpoint_ma', ascending=True).reset_index(drop=True)\n",
        "\n",
        "        _m = pd.merge_asof(\n",
        "            _left_sorted,\n",
        "            _right_sorted,\n",
        "            on='midpoint_ma',\n",
        "            direction='nearest',\n",
        "            tolerance=2.6  # ~half of 5-Myr bin width\n",
        "        )\n",
        "        env_data_5myr = _m.sort_values('midpoint_ma', ascending=False).reset_index(drop=True)\n",
        "        n_valid = env_data_5myr['d13C'].notna().sum()\n",
        "\n",
        "    print(f\"  -> δ13C (5-Myr binned) merged: {n_valid}/{len(env_data_5myr)} values\")\n",
        "\n",
        "except Exception as e:\n",
        "    env_data_5myr['d13C'] = np.nan\n",
        "    print(\"  ! Warning: δ13C 5-Myr merge failed:\", e)\n",
        "\n",
        "print(\"✓ Environmental proxies interpolated (Stage & 5-Myr).\")\n",
        "\n",
        "# =============================================================================\n",
        "# [ADDED] SAVE INTERPOLATED ENV DATA\n",
        "# =============================================================================\n",
        "if 'env_data' in locals() and not env_data.empty:\n",
        "    env_data.to_csv(f\"{OUTPUT_DIR}/intermediate_env_data_stage.csv\", index=False)\n",
        "\n",
        "if 'env_data_5myr' in locals() and not env_data_5myr.empty:\n",
        "    env_data_5myr.to_csv(f\"{OUTPUT_DIR}/intermediate_env_data_5myr.csv\", index=False)\n",
        "\n",
        "print(f\"✓ Interpolated environmental data saved to {OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "t2BtkuBab2Kp",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39a943e2-f52b-4938-d60d-94f425abaf48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Master Stage Dataset...\n",
            "✓ Master dataset (STAGES) created: 22 stages, 56 variables\n",
            "\n",
            "======================================================================\n",
            "CREATING 5-MYR BIN MASTER DATASET\n",
            "======================================================================\n",
            "Using Reef Data as primary 5-Myr bin source.\n",
            "✓ Master dataset (5-MYR BINS) created: 27 bins, 39 variables\n",
            "✓ Saved: ./output/MASTER_dataset_stage.csv\n",
            "✓ Saved: ./output/MASTER_dataset_5myr.csv\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# @title CELL 9: CREATE MASTER DATASET (STAGES AND 5-MYR BINS)\n",
        "# =============================================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 1. BUILD MASTER STAGE DATASET\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"Building Master Stage Dataset...\")\n",
        "data = []\n",
        "\n",
        "for stage, info in STAGES.items():\n",
        "    row = {\n",
        "        'stage': stage,\n",
        "        'midpoint_ma': info['mid'],\n",
        "        'start_ma': info['start'],\n",
        "        'end_ma': info['end'],\n",
        "        'period': info['period']\n",
        "    }\n",
        "\n",
        "    # A. Reef data (if available)\n",
        "    if 'reef_df' in locals() and reef_df is not None and not reef_df.empty:\n",
        "        reef_row = reef_df[reef_df['name'] == stage]\n",
        "        if len(reef_row) > 0:\n",
        "            for col in [\n",
        "                'thickness_mean', 'thickness_std', 'thickness_stderr', 'thickness_median',\n",
        "                'thickness_min', 'thickness_max', 'thickness_q25', 'thickness_q75', 'thickness_count',\n",
        "                'width_mean', 'width_std', 'width_median', 'width_min', 'width_max',\n",
        "                'reef_count'\n",
        "            ]:\n",
        "                if col in reef_row.columns:\n",
        "                    row[col] = reef_row[col].values[0]\n",
        "\n",
        "    # B. Stromatoporoid data (from strom_df)\n",
        "    if 'strom_df' in locals() and strom_df is not None and not strom_df.empty:\n",
        "        # robust stage matching\n",
        "        s_stage = strom_df['stage'].astype(str).str.lower()\n",
        "        strom_row = strom_df[s_stage == str(stage).lower()]\n",
        "        if len(strom_row) > 0:\n",
        "            for order in STROM_ORDERS:\n",
        "                col_occ = f'{order}_occ'\n",
        "                col_gen = f'{order}_genus'\n",
        "                if col_occ in strom_row.columns:\n",
        "                    row[col_occ] = strom_row[col_occ].values[0]\n",
        "                if col_gen in strom_row.columns:\n",
        "                    row[col_gen] = strom_row[col_gen].values[0]\n",
        "\n",
        "            if 'Total_occ' in strom_row.columns:\n",
        "                row['strom_total_occ'] = strom_row['Total_occ'].values[0]\n",
        "            if 'Total_genus' in strom_row.columns:\n",
        "                row['strom_total_gen'] = strom_row['Total_genus'].values[0]\n",
        "\n",
        "    # C. Coral data (from coral_df)\n",
        "    if 'coral_df' in locals() and coral_df is not None and not coral_df.empty:\n",
        "        c_stage = coral_df['stage'].astype(str).str.lower()\n",
        "        coral_row = coral_df[c_stage == str(stage).lower()]\n",
        "        if len(coral_row) > 0:\n",
        "            # Rugosa\n",
        "            if 'Rugosa_genus' in coral_row.columns: row['rugose_div'] = coral_row['Rugosa_genus'].values[0]\n",
        "            if 'Rugosa_occ' in coral_row.columns:   row['rugose_occ'] = coral_row['Rugosa_occ'].values[0]\n",
        "\n",
        "            # Tabulata\n",
        "            if 'Tabulata_genus' in coral_row.columns: row['tabulate_div'] = coral_row['Tabulata_genus'].values[0]\n",
        "            if 'Tabulata_occ' in coral_row.columns:   row['tabulate_occ'] = coral_row['Tabulata_occ'].values[0]\n",
        "\n",
        "    # D. Macrostrat data\n",
        "    if 'macro_stage' in locals() and macro_stage is not None and not macro_stage.empty:\n",
        "        macro_row = macro_stage[macro_stage['stage'] == stage]\n",
        "        if len(macro_row) > 0:\n",
        "            row['total_area_km2'] = macro_row['total_area_km2'].values[0]\n",
        "            row['carbonate_area_km2'] = macro_row['carbonate_area_km2'].values[0]\n",
        "            row['carbonate_percentage'] = macro_row['carbonate_percentage'].values[0]\n",
        "\n",
        "    # E. Environmental proxies\n",
        "    if 'env_data' in locals() and env_data is not None and not env_data.empty:\n",
        "        env_row = env_data[env_data['stage'] == stage]\n",
        "        if len(env_row) > 0:\n",
        "            row['temperature'] = env_row['temperature'].values[0]\n",
        "            row['dissolved_O2'] = env_row['dissolved_O2'].values[0]\n",
        "            row['atm_O2'] = env_row['atm_O2'].values[0]\n",
        "            row['atm_CO2'] = env_row['atm_CO2'].values[0]\n",
        "            row['sea_level'] = env_row['sea_level'].values[0]\n",
        "            if 'd13C' in env_row.columns:\n",
        "                row['d13C'] = env_row['d13C'].values[0]\n",
        "\n",
        "    data.append(row)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate Stromatoporoid Proportions\n",
        "if 'strom_total_occ' in df.columns:\n",
        "    for order in STROM_ORDERS:\n",
        "        col_occ = f'{order}_occ'\n",
        "        if col_occ in df.columns:\n",
        "            df[f'{order}_prop'] = np.where(\n",
        "                df['strom_total_occ'].fillna(0) > 0,\n",
        "                df[col_occ].fillna(0) / df['strom_total_occ'].fillna(0),\n",
        "                0.0\n",
        "            )\n",
        "\n",
        "    # Derived vs Basal\n",
        "    derived_orders = ['Actinostromatida', 'Stromatoporida', 'Stromatoporellida',\n",
        "                      'Syringostromatida', 'Amphiporida']\n",
        "    basal_orders = ['Labechiida', 'Clathrodictyida']\n",
        "\n",
        "    # Occurrences\n",
        "    df['derived_strom_occ'] = sum(df[f'{o}_occ'].fillna(0) for o in derived_orders if f'{o}_occ' in df.columns)\n",
        "    df['basal_strom_occ'] = sum(df[f'{o}_occ'].fillna(0) for o in basal_orders if f'{o}_occ' in df.columns)\n",
        "\n",
        "    # Diversity\n",
        "    df['derived_strom_div'] = sum(df[f'{o}_genus'].fillna(0) for o in derived_orders if f'{o}_genus' in df.columns)\n",
        "    df['basal_strom_div'] = sum(df[f'{o}_genus'].fillna(0) for o in basal_orders if f'{o}_genus' in df.columns)\n",
        "\n",
        "    # Proportions\n",
        "    df['derived_strom_prop'] = np.where(df['strom_total_occ'].fillna(0) > 0, df['derived_strom_occ'] / df['strom_total_occ'].fillna(0), 0.0)\n",
        "    df['basal_strom_prop'] = np.where(df['strom_total_occ'].fillna(0) > 0, df['basal_strom_occ'] / df['strom_total_occ'].fillna(0), 0.0)\n",
        "\n",
        "# [ADDED] Fill all missing NUMERIC values with 0 (keep text columns untouched)\n",
        "num_cols = df.select_dtypes(include=[np.number]).columns\n",
        "df[num_cols] = df[num_cols].fillna(0)\n",
        "\n",
        "# Sort\n",
        "df = df.sort_values('midpoint_ma', ascending=False).reset_index(drop=True)\n",
        "print(f\"✓ Master dataset (STAGES) created: {len(df)} stages, {len(df.columns)} variables\")\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 2. BUILD MASTER 5-MYR DATASET\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CREATING 5-MYR BIN MASTER DATASET\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Determine the primary source for 5-Myr bins\n",
        "# We prefer reef data if available, otherwise we use the biological data\n",
        "if 'reef_5myr_df' in locals() and reef_5myr_df is not None and not reef_5myr_df.empty:\n",
        "    primary_bins = reef_5myr_df\n",
        "    print(\"Using Reef Data as primary 5-Myr bin source.\")\n",
        "elif 'strom_5myr_df' in locals() and strom_5myr_df is not None and not strom_5myr_df.empty:\n",
        "    primary_bins = strom_5myr_df\n",
        "    # Add midpoint if missing\n",
        "    if 'midpoint_ma' not in primary_bins.columns and {'bin_top', 'bin_bottom'}.issubset(primary_bins.columns):\n",
        "        primary_bins = primary_bins.copy()\n",
        "        primary_bins['midpoint_ma'] = (primary_bins['bin_top'] + primary_bins['bin_bottom']) / 2\n",
        "    print(\"Using Stromatoporoid Data as primary 5-Myr bin source.\")\n",
        "else:\n",
        "    # Fallback to env_data_5myr if bio data missing\n",
        "    primary_bins = env_data_5myr\n",
        "    print(\"Using Environmental Data as primary 5-Myr bin source.\")\n",
        "\n",
        "data_5myr = []\n",
        "\n",
        "# Iterate through the chosen primary bins\n",
        "for idx, row_ref in primary_bins.iterrows():\n",
        "    # Identify bin\n",
        "    if 'time_identifier' in row_ref:\n",
        "        bin_id = row_ref['time_identifier']\n",
        "    elif 'bin_label' in row_ref:\n",
        "        bin_id = row_ref['bin_label']\n",
        "    elif 'bin_id' in row_ref:\n",
        "        bin_id = row_ref['bin_id']\n",
        "    else:\n",
        "        bin_id = idx  # fallback\n",
        "\n",
        "    midpoint = row_ref['midpoint_ma']\n",
        "\n",
        "    row = {\n",
        "        'bin_id': bin_id,\n",
        "        'midpoint_ma': midpoint\n",
        "    }\n",
        "\n",
        "    # A. Reef Data (if available)\n",
        "    if 'reef_5myr_df' in locals() and reef_5myr_df is not None and not reef_5myr_df.empty:\n",
        "        # Find matching reef row (if not already iterating it)\n",
        "        if primary_bins is not reef_5myr_df:\n",
        "            reef_match = reef_5myr_df[abs(reef_5myr_df['midpoint_ma'] - midpoint) < 0.1]\n",
        "            row_ref_for_reef = reef_match.iloc[0] if len(reef_match) > 0 else pd.Series(dtype='float64')\n",
        "        else:\n",
        "            row_ref_for_reef = row_ref\n",
        "\n",
        "        for col in [\n",
        "            'thickness_mean', 'thickness_std', 'thickness_stderr', 'thickness_median',\n",
        "            'thickness_count', 'width_mean', 'width_std', 'reef_count'\n",
        "        ]:\n",
        "            if col in row_ref_for_reef.index:\n",
        "                row[col] = row_ref_for_reef[col]\n",
        "\n",
        "    # B. Stromatoporoid Data (5-Myr)\n",
        "    if 'strom_5myr_df' in locals() and strom_5myr_df is not None and not strom_5myr_df.empty:\n",
        "        if {'bin_top', 'bin_bottom'}.issubset(strom_5myr_df.columns):\n",
        "            strom_mid = (strom_5myr_df['bin_top'] + strom_5myr_df['bin_bottom']) / 2\n",
        "            strom_match = strom_5myr_df[abs(strom_mid - midpoint) < 0.1]\n",
        "            if len(strom_match) > 0:\n",
        "                s_row = strom_match.iloc[0]\n",
        "                for order in STROM_ORDERS:\n",
        "                    if f'{order}_occ' in s_row.index: row[f'{order}_occ'] = s_row[f'{order}_occ']\n",
        "                    if f'{order}_genus' in s_row.index: row[f'{order}_genus'] = s_row[f'{order}_genus']\n",
        "                if 'Total_occ' in s_row.index: row['strom_total_occ'] = s_row['Total_occ']\n",
        "                if 'Total_genus' in s_row.index: row['strom_total_gen'] = s_row['Total_genus']\n",
        "\n",
        "    # C. Coral Data (5-Myr)\n",
        "    if 'coral_5myr_df' in locals() and coral_5myr_df is not None and not coral_5myr_df.empty:\n",
        "        if {'bin_top', 'bin_bottom'}.issubset(coral_5myr_df.columns):\n",
        "            coral_mid = (coral_5myr_df['bin_top'] + coral_5myr_df['bin_bottom']) / 2\n",
        "            coral_match = coral_5myr_df[abs(coral_mid - midpoint) < 0.1]\n",
        "            if len(coral_match) > 0:\n",
        "                c_row = coral_match.iloc[0]\n",
        "                if 'Rugosa_occ' in c_row.index: row['rugose_occ'] = c_row['Rugosa_occ']\n",
        "                if 'Rugosa_genus' in c_row.index: row['rugose_div'] = c_row['Rugosa_genus']\n",
        "                if 'Tabulata_occ' in c_row.index: row['tabulate_occ'] = c_row['Tabulata_occ']\n",
        "                if 'Tabulata_genus' in c_row.index: row['tabulate_div'] = c_row['Tabulata_genus']\n",
        "\n",
        "    # D. Macrostrat Data\n",
        "    if 'macro_5myr' in locals() and macro_5myr is not None and not macro_5myr.empty and 'bin_mid' in macro_5myr.columns:\n",
        "        macro_match = macro_5myr[abs(macro_5myr['bin_mid'] - midpoint) < 2.5]\n",
        "        if len(macro_match) > 0:\n",
        "            row['total_area_km2'] = macro_match['total_area_km2'].values[0]\n",
        "            row['carbonate_area_km2'] = macro_match['carbonate_area_km2'].values[0]\n",
        "            row['carbonate_percentage'] = macro_match['carbonate_percentage'].values[0]\n",
        "\n",
        "    # E. Environmental Proxies\n",
        "    if 'env_data_5myr' in locals() and env_data_5myr is not None and not env_data_5myr.empty:\n",
        "        env_match = env_data_5myr[abs(env_data_5myr['midpoint_ma'] - midpoint) < 0.1]\n",
        "        if len(env_match) > 0:\n",
        "            env_val = env_match.iloc[0]\n",
        "            row['temperature'] = env_val['temperature']\n",
        "            row['dissolved_O2'] = env_val['dissolved_O2']\n",
        "            row['atm_O2'] = env_val['atm_O2']\n",
        "            row['atm_CO2'] = env_val['atm_CO2']\n",
        "            row['sea_level'] = env_val['sea_level']\n",
        "            if 'd13C' in env_val.index:\n",
        "                row['d13C'] = env_val['d13C']\n",
        "\n",
        "    data_5myr.append(row)\n",
        "\n",
        "df_5myr = pd.DataFrame(data_5myr)\n",
        "\n",
        "# [ADDED] Fill all missing NUMERIC values with 0 (keep text columns untouched)\n",
        "num_cols_5 = df_5myr.select_dtypes(include=[np.number]).columns\n",
        "df_5myr[num_cols_5] = df_5myr[num_cols_5].fillna(0)\n",
        "\n",
        "df_5myr = df_5myr.sort_values('midpoint_ma', ascending=False).reset_index(drop=True)\n",
        "print(f\"✓ Master dataset (5-MYR BINS) created: {len(df_5myr)} bins, {len(df_5myr.columns)} variables\")\n",
        "\n",
        "# =============================================================================\n",
        "# [ADDED] SAVE MASTER DATASETS\n",
        "# =============================================================================\n",
        "# Save the master datasets immediately after creation\n",
        "if 'df' in locals() and df is not None and not df.empty:\n",
        "    df.to_csv(f\"{OUTPUT_DIR}/MASTER_dataset_stage.csv\", index=False)\n",
        "    print(f\"✓ Saved: {OUTPUT_DIR}/MASTER_dataset_stage.csv\")\n",
        "\n",
        "if 'df_5myr' in locals() and df_5myr is not None and not df_5myr.empty:\n",
        "    df_5myr.to_csv(f\"{OUTPUT_DIR}/MASTER_dataset_5myr.csv\", index=False)\n",
        "    print(f\"✓ Saved: {OUTPUT_DIR}/MASTER_dataset_5myr.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "id": "jpj1BjT5d8eO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8412027-501d-4b19-a4c3-e4c6f54f5b1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==========================================================================================\n",
            "PRE-PROCESSING: CLR TRANSFORMATION\n",
            "Transforming closed compositional data (proportions) to open log-ratios\n",
            "==========================================================================================\n",
            "  Stage-Level: Created 'log_derived_basal_ratio'\n",
            "  Stage-Level: Generated 7 CLR variables.\n",
            "  5-Myr Bins: Created 'log_derived_basal_ratio'\n",
            "  5-Myr Bins: Generated 7 CLR variables.\n",
            "\n",
            "------------------------------------------------------------------------------------------\n",
            "CLR CORRELATION ANALYSIS\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "--- Stage-Level ---\n",
            "  Taxon/Group                  |   Orig ρ |    CLR ρ |    Diff |      CLR p\n",
            "  ---------------------------------------------------------------------------\n",
            "  Labechiida                   |   -0.575 |   -0.725 |  -0.150 |     0.0001 *\n",
            "  Clathrodictyida              |   +0.158 |   +0.009 |  -0.149 |     0.9681 \n",
            "  Actinostromatida             |   +0.647 |   +0.262 |  -0.385 |     0.2396 \n",
            "  Stromatoporida               |   +0.571 |   +0.173 |  -0.398 |     0.4406 \n",
            "  Stromatoporellida            |   +0.546 |   +0.191 |  -0.354 |     0.3935 \n",
            "  Syringostromatida            |   +0.844 |   +0.690 |  -0.154 |     0.0004 *\n",
            "  Amphiporida                  |   +0.664 |   +0.420 |  -0.244 |     0.0515 \n",
            "  ---------------------------------------------------------------------------\n",
            "  GROUP COMPARISONS:\n",
            "  Basal (Labech+Clathr) CLR    |      N/A |   -0.593 |     N/A |     0.0036 *\n",
            "  Derived (5 taxa) CLR         |      N/A |   +0.593 |     N/A |     0.0036 *\n",
            "  Log(Derived/Basal) Ratio     |      N/A |   +0.796 |     N/A |     0.0000 *\n",
            "\n",
            "--- 5-Myr Bins ---\n",
            "  Taxon/Group                  |   Orig ρ |    CLR ρ |    Diff |      CLR p\n",
            "  ---------------------------------------------------------------------------\n",
            "  Labechiida                   |   -0.552 |   -0.771 |  -0.219 |     0.0000 *\n",
            "  Clathrodictyida              |   +0.283 |   +0.140 |  -0.142 |     0.4847 \n",
            "  Actinostromatida             |   +0.711 |   +0.255 |  -0.456 |     0.1994 \n",
            "  Stromatoporida               |   +0.648 |   +0.345 |  -0.304 |     0.0784 \n",
            "  Stromatoporellida            |   +0.787 |   +0.610 |  -0.178 |     0.0007 *\n",
            "  Syringostromatida            |   +0.756 |   +0.613 |  -0.144 |     0.0007 *\n",
            "  Amphiporida                  |   +0.847 |   +0.651 |  -0.196 |     0.0002 *\n",
            "  ---------------------------------------------------------------------------\n",
            "  GROUP COMPARISONS:\n",
            "  Basal (Labech+Clathr) CLR    |      N/A |   -0.661 |     N/A |     0.0002 *\n",
            "  Derived (5 taxa) CLR         |      N/A |   +0.661 |     N/A |     0.0002 *\n",
            "  Log(Derived/Basal) Ratio     |      N/A |   +0.797 |     N/A |     0.0000 *\n",
            "\n",
            "Saved: ./output/results_clr.csv (40 rows)\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# @title CELL 10: CLR COMPOSITIONAL TRANSFORMATION (WITH BASAL/DERIVED GROUPS)\n",
        "# =============================================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import gmean\n",
        "import scipy.stats as stats\n",
        "print(\"\\n\" + \"=\"*90)\n",
        "print(\"PRE-PROCESSING: CLR TRANSFORMATION\")\n",
        "print(\"Transforming closed compositional data (proportions) to open log-ratios\")\n",
        "print(\"=\"*90)\n",
        "# Global list for CLR results\n",
        "global_clr_results = []\n",
        "def calculate_missing_props(input_df):\n",
        "    \"\"\"\n",
        "    Helper: If _prop columns are missing, calculate them from _occ columns.\n",
        "    \"\"\"\n",
        "    df_copy = input_df.copy()\n",
        "    orders = ['Labechiida', 'Clathrodictyida', 'Actinostromatida',\n",
        "              'Stromatoporida', 'Stromatoporellida',\n",
        "              'Syringostromatida', 'Amphiporida']\n",
        "    # Check if we have occurrence columns\n",
        "    occ_cols = [f\"{o}_occ\" for o in orders if f\"{o}_occ\" in df_copy.columns]\n",
        "    if not occ_cols:\n",
        "        return df_copy\n",
        "    # Recalculate Total\n",
        "    if 'strom_total_occ' not in df_copy.columns:\n",
        "        df_copy['strom_total_occ'] = df_copy[occ_cols].sum(axis=1)\n",
        "    # Calculate Proportions\n",
        "    for o in orders:\n",
        "        occ_col = f\"{o}_occ\"\n",
        "        prop_col = f\"{o}_prop\"\n",
        "        if occ_col in df_copy.columns:\n",
        "            total = df_copy['strom_total_occ'].replace(0, np.nan)\n",
        "            df_copy[prop_col] = df_copy[occ_col] / total\n",
        "            df_copy[prop_col] = df_copy[prop_col].fillna(0)\n",
        "    return df_copy\n",
        "def apply_clr(input_df, label):\n",
        "    \"\"\"Apply CLR transformation and calculate group-level metrics.\"\"\"\n",
        "\n",
        "    dataset = input_df.copy()\n",
        "\n",
        "    # 1. AUTO-REPAIR: Ensure Proportion Columns Exist\n",
        "    dataset = calculate_missing_props(dataset)\n",
        "    # 2. Identify Proportion Columns\n",
        "    prop_cols = ['Labechiida_prop', 'Clathrodictyida_prop', 'Actinostromatida_prop',\n",
        "                 'Stromatoporida_prop', 'Stromatoporellida_prop',\n",
        "                 'Syringostromatida_prop', 'Amphiporida_prop']\n",
        "    available_cols = [c for c in prop_cols if c in dataset.columns]\n",
        "    # Define group membership\n",
        "    basal_orders = ['Labechiida_prop', 'Clathrodictyida_prop']\n",
        "    derived_orders = ['Actinostromatida_prop', 'Stromatoporida_prop',\n",
        "                      'Stromatoporellida_prop', 'Syringostromatida_prop',\n",
        "                      'Amphiporida_prop']\n",
        "    if len(available_cols) < 2:\n",
        "        print(f\"  {label}: ! Skipped. Found only {len(available_cols)} proportion columns.\")\n",
        "        return dataset\n",
        "    # 3. Extract and Handle Zeros\n",
        "    comp_data = dataset[available_cols].replace(0, 1e-5)\n",
        "    # 4. Geometric Mean per Row\n",
        "    gmeans = gmean(comp_data, axis=1)\n",
        "    # 5. Transform: ln(x / gmean)\n",
        "    clr_data = np.log(comp_data.div(gmeans, axis=0))\n",
        "\n",
        "    # Use CLR_ prefix (avoiding duplicates)\n",
        "    new_col_names = []\n",
        "    for c in available_cols:\n",
        "        new_name = f\"CLR_{c}\"\n",
        "        # Drop existing column if present to avoid duplicates\n",
        "        if new_name in dataset.columns:\n",
        "            dataset = dataset.drop(columns=[new_name])\n",
        "        new_col_names.append(new_name)\n",
        "    clr_data.columns = new_col_names\n",
        "    # 6. Create 'Derived vs Basal' Log-Ratio\n",
        "    basal_in = [c for c in basal_orders if c in dataset.columns]\n",
        "    derived_in = [c for c in derived_orders if c in dataset.columns]\n",
        "    if basal_in and derived_in:\n",
        "        b_sum = dataset[basal_in].sum(axis=1).replace(0, 1e-5)\n",
        "        d_sum = dataset[derived_in].sum(axis=1).replace(0, 1e-5)\n",
        "        dataset['log_derived_basal_ratio'] = np.log(d_sum / b_sum)\n",
        "        print(f\"  {label}: Created 'log_derived_basal_ratio'\")\n",
        "    # 7. Merge CLR columns back to dataset\n",
        "    dataset = pd.concat([dataset.reset_index(drop=True), clr_data.reset_index(drop=True)], axis=1)\n",
        "    print(f\"  {label}: Generated {len(clr_data.columns)} CLR variables.\")\n",
        "\n",
        "    # 8. Calculate GROUP-LEVEL CLR means\n",
        "    clr_basal_cols = [f\"CLR_{c}\" for c in basal_in]\n",
        "    clr_derived_cols = [f\"CLR_{c}\" for c in derived_in]\n",
        "\n",
        "    if clr_basal_cols:\n",
        "        dataset['CLR_basal_mean'] = dataset[clr_basal_cols].mean(axis=1)\n",
        "    if clr_derived_cols:\n",
        "        dataset['CLR_derived_mean'] = dataset[clr_derived_cols].mean(axis=1)\n",
        "\n",
        "    return dataset\n",
        "# Apply to both master datasets\n",
        "df = apply_clr(df, \"Stage-Level\")\n",
        "df_5myr = apply_clr(df_5myr, \"5-Myr Bins\")\n",
        "# =============================================================================\n",
        "# CLR CORRELATION ANALYSIS (Individual Taxa + Basal/Derived Groups)\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"-\"*90)\n",
        "print(\"CLR CORRELATION ANALYSIS\")\n",
        "print(\"-\"*90)\n",
        "prop_cols = ['Labechiida_prop', 'Clathrodictyida_prop', 'Actinostromatida_prop',\n",
        "             'Stromatoporida_prop', 'Stromatoporellida_prop',\n",
        "             'Syringostromatida_prop', 'Amphiporida_prop']\n",
        "targets = ['thickness_mean', 'width_mean']\n",
        "def safe_spearman(x, y):\n",
        "    \"\"\"Calculate Spearman correlation safely, returning scalars.\"\"\"\n",
        "    try:\n",
        "        # Ensure 1D numpy arrays\n",
        "        x_arr = np.array(x).flatten()\n",
        "        y_arr = np.array(y).flatten()\n",
        "\n",
        "        # Remove NaN pairs\n",
        "        mask = ~(np.isnan(x_arr) | np.isnan(y_arr))\n",
        "        x_clean = x_arr[mask]\n",
        "        y_clean = y_arr[mask]\n",
        "\n",
        "        if len(x_clean) < 3:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        result = stats.spearmanr(x_clean, y_clean)\n",
        "        # Handle both old and new scipy return types\n",
        "        if hasattr(result, 'correlation'):\n",
        "            return float(result.correlation), float(result.pvalue)\n",
        "        else:\n",
        "            return float(result[0]), float(result[1])\n",
        "    except:\n",
        "        return np.nan, np.nan\n",
        "for label, data in [('Stage-Level', df), ('5-Myr Bins', df_5myr)]:\n",
        "    print(f\"\\n--- {label} ---\")\n",
        "    print(f\"  {'Taxon/Group':<28s} | {'Orig ρ':>8s} | {'CLR ρ':>8s} | {'Diff':>7s} | {'CLR p':>10s}\")\n",
        "    print(\"  \" + \"-\"*75)\n",
        "\n",
        "    # A. INDIVIDUAL TAXA\n",
        "    for prop in prop_cols:\n",
        "        clr_col = f\"CLR_{prop}\"\n",
        "        if prop not in data.columns or clr_col not in data.columns:\n",
        "            continue\n",
        "\n",
        "        for target in targets:\n",
        "            if target not in data.columns:\n",
        "                continue\n",
        "\n",
        "            # Get data as 1D arrays\n",
        "            x_orig = data[prop].values\n",
        "            x_clr = data[clr_col].values\n",
        "            y = data[target].values\n",
        "\n",
        "            # Calculate correlations\n",
        "            r_orig, p_orig = safe_spearman(x_orig, y)\n",
        "            r_clr, p_clr = safe_spearman(x_clr, y)\n",
        "\n",
        "            if np.isnan(r_orig) or np.isnan(r_clr):\n",
        "                continue\n",
        "\n",
        "            diff = r_clr - r_orig\n",
        "\n",
        "            # Interpretation\n",
        "            if abs(diff) < 0.1:\n",
        "                interp = \"Stable\"\n",
        "            elif diff < -0.2:\n",
        "                interp = \"SUPPRESSED\"\n",
        "            elif diff > 0.2:\n",
        "                interp = \"INFLATED\"\n",
        "            else:\n",
        "                interp = \"Moderate\"\n",
        "\n",
        "            global_clr_results.append({\n",
        "                'Dataset': label, 'Level': 'Individual',\n",
        "                'Predictor': prop.replace('_prop', ''),\n",
        "                'Target': target, 'Original_Rho': r_orig, 'CLR_Rho': r_clr,\n",
        "                'Difference': diff, 'CLR_P': p_clr, 'Interpretation': interp\n",
        "            })\n",
        "\n",
        "            if target == 'thickness_mean':\n",
        "                sig = \"*\" if p_clr < 0.05 else \"\"\n",
        "                print(f\"  {prop.replace('_prop',''):<28s} | {r_orig:>+8.3f} | {r_clr:>+8.3f} | {diff:>+7.3f} | {p_clr:>10.4f} {sig}\")\n",
        "\n",
        "    # B. BASAL vs DERIVED GROUPS\n",
        "    print(\"  \" + \"-\"*75)\n",
        "    print(\"  GROUP COMPARISONS:\")\n",
        "\n",
        "    group_vars = [\n",
        "        ('CLR_basal_mean', 'Basal (Labech+Clathr) CLR'),\n",
        "        ('CLR_derived_mean', 'Derived (5 taxa) CLR'),\n",
        "        ('log_derived_basal_ratio', 'Log(Derived/Basal) Ratio')\n",
        "    ]\n",
        "\n",
        "    for col, name in group_vars:\n",
        "        if col not in data.columns:\n",
        "            continue\n",
        "\n",
        "        for target in targets:\n",
        "            if target not in data.columns:\n",
        "                continue\n",
        "\n",
        "            x = data[col].values\n",
        "            y = data[target].values\n",
        "\n",
        "            r, p = safe_spearman(x, y)\n",
        "\n",
        "            if np.isnan(r):\n",
        "                continue\n",
        "\n",
        "            global_clr_results.append({\n",
        "                'Dataset': label, 'Level': 'Group',\n",
        "                'Predictor': name, 'Target': target,\n",
        "                'Original_Rho': np.nan, 'CLR_Rho': r,\n",
        "                'Difference': np.nan, 'CLR_P': p, 'Interpretation': 'Group-level'\n",
        "            })\n",
        "\n",
        "            if target == 'thickness_mean':\n",
        "                sig = \"*\" if p < 0.05 else \"\"\n",
        "                print(f\"  {name:<28s} |      N/A | {r:>+8.3f} |     N/A | {p:>10.4f} {sig}\")\n",
        "# =============================================================================\n",
        "# SAVE CLR RESULTS\n",
        "# =============================================================================\n",
        "pd.DataFrame(global_clr_results).to_csv(f\"{OUTPUT_DIR}/results_clr.csv\", index=False)\n",
        "print(f\"\\nSaved: {OUTPUT_DIR}/results_clr.csv ({len(global_clr_results)} rows)\")\n",
        "# Update predictor lists\n",
        "if 'all_test_vars' in locals():\n",
        "    new_vars = [\n",
        "        ('log_derived_basal_ratio', 'Log(Derived/Basal)'),\n",
        "        ('CLR_basal_mean', 'CLR Basal Mean'),\n",
        "        ('CLR_derived_mean', 'CLR Derived Mean')\n",
        "    ]\n",
        "    for var in new_vars:\n",
        "        if not any(v[0] == var[0] for v in all_test_vars):\n",
        "            all_test_vars.append(var)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "id": "OhFo2l0de0YP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "346bc160-625f-4014-d329-64359e6d87c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Correlation functions defined (Spearman and Pearson)\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# @title CELL 11: CORRELATION FUNCTIONS - SPEARMAN AND PEARSON\n",
        "# =============================================================================\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "\"\"\"\n",
        "CORRELATION ANALYSIS METHODS\n",
        "============================\n",
        "This cell defines functions for both Spearman and Pearson correlations.\n",
        "\n",
        "SPEARMAN'S RHO (ρ):\n",
        "- Non-parametric rank correlation\n",
        "- Measures monotonic relationships (not just linear)\n",
        "- Robust to outliers and non-normal distributions\n",
        "- Appropriate for ordinal data or data with outliers\n",
        "- Reference: Spearman, C. (1904). American Journal of Psychology, 15(1), 72-101.\n",
        "\n",
        "PEARSON'S r:\n",
        "- Parametric correlation coefficient\n",
        "- Measures linear relationships specifically\n",
        "- Assumes normally distributed variables\n",
        "- More powerful when assumptions are met\n",
        "- Reference: Pearson, K. (1895). Philosophical Transactions of the Royal Society A, 186, 343-414.\n",
        "\n",
        "For geological time series:\n",
        "- Spearman is often preferred due to non-normal distributions\n",
        "- Pearson provides information on linear relationships\n",
        "- Presenting both allows comparison and assessment of relationship type\n",
        "\"\"\"\n",
        "\n",
        "def calc_spearman(data, v1, v2):\n",
        "    \"\"\"\n",
        "    Calculate Spearman rank correlation with significance\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    data : DataFrame\n",
        "        Data containing the variables\n",
        "    v1, v2 : str\n",
        "        Column names to correlate\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    rho : float\n",
        "        Spearman correlation coefficient\n",
        "    p : float\n",
        "        Two-tailed p-value\n",
        "    n : int\n",
        "        Number of valid pairs\n",
        "    \"\"\"\n",
        "    # Check if columns exist\n",
        "    if v1 not in data.columns or v2 not in data.columns:\n",
        "        return np.nan, np.nan, 0\n",
        "\n",
        "    valid = data[[v1, v2]].dropna()\n",
        "\n",
        "    if len(valid) >= 5:\n",
        "        # Spearmanr returns a Result object or tuple depending on version, generic unpacking is safer\n",
        "        result = stats.spearmanr(valid[v1], valid[v2])\n",
        "        # Handle cases where result might be a struct or tuple\n",
        "        try:\n",
        "            r, p = result.correlation, result.pvalue\n",
        "        except AttributeError:\n",
        "            r, p = result[0], result[1]\n",
        "\n",
        "        return r, p, len(valid)\n",
        "\n",
        "    return np.nan, np.nan, 0\n",
        "\n",
        "def calc_pearson(data, v1, v2):\n",
        "    \"\"\"\n",
        "    Calculate Pearson correlation with significance\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    data : DataFrame\n",
        "        Data containing the variables\n",
        "    v1, v2 : str\n",
        "        Column names to correlate\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    r : float\n",
        "        Pearson correlation coefficient\n",
        "    p : float\n",
        "        Two-tailed p-value\n",
        "    n : int\n",
        "        Number of valid pairs\n",
        "    \"\"\"\n",
        "    if v1 not in data.columns or v2 not in data.columns:\n",
        "        return np.nan, np.nan, 0\n",
        "\n",
        "    valid = data[[v1, v2]].dropna()\n",
        "\n",
        "    if len(valid) >= 5:\n",
        "        r, p = stats.pearsonr(valid[v1], valid[v2])\n",
        "        return r, p, len(valid)\n",
        "\n",
        "    return np.nan, np.nan, 0\n",
        "\n",
        "def calc_both_correlations(data, v1, v2):\n",
        "    \"\"\"\n",
        "    Calculate both Spearman and Pearson correlations\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict with both correlation results\n",
        "    \"\"\"\n",
        "    spearman_r, spearman_p, n = calc_spearman(data, v1, v2)\n",
        "    pearson_r, pearson_p, _ = calc_pearson(data, v1, v2)\n",
        "\n",
        "    return {\n",
        "        'spearman_rho': spearman_r,\n",
        "        'spearman_p': spearman_p,\n",
        "        'pearson_r': pearson_r,\n",
        "        'pearson_p': pearson_p,\n",
        "        'n': n\n",
        "    }\n",
        "\n",
        "def get_significance_stars(p):\n",
        "    \"\"\"Convert p-value to significance stars\"\"\"\n",
        "    if p is None or np.isnan(p):\n",
        "        return ''\n",
        "    if p < 0.001:\n",
        "        return '***'\n",
        "    elif p < 0.01:\n",
        "        return '**'\n",
        "    elif p < 0.05:\n",
        "        return '*'\n",
        "    else:\n",
        "        return 'ns'\n",
        "\n",
        "print(\"✓ Correlation functions defined (Spearman and Pearson)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0WIsgnZGe2v-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1386a6bf-185e-447d-9a0b-932a6865a93d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================================\n",
            "COMPREHENSIVE CORRELATION ANALYSIS\n",
            "Metrics: Thickness, Width\n",
            "Scopes:  Stage-Level AND 5-Myr Bins\n",
            "Notes:   NO T/W ratio; pairwise-complete; NO group-level presence filters\n",
            "==========================================================================================\n",
            "Pre-processing data...\n",
            "  [OK] [Stage] Calculated strom proportions and groupings\n",
            "  [OK] [5-Myr] Calculated strom proportions and groupings\n",
            "  [OK] [Stage] atmospheric_O2 <- atm_O2\n",
            "  [OK] [Stage] atmospheric_CO2 <- atm_CO2\n",
            "  [OK] [5-Myr] atmospheric_O2 <- atm_O2\n",
            "  [OK] [5-Myr] atmospheric_CO2 <- atm_CO2\n",
            "\n",
            "------------------------------------------------------------------------------------------\n",
            "Stage | TARGET: THICKNESS (LOG)\n",
            "------------------------------------------------------------------------------------------\n",
            "Group        Variable                                 rho     p(rho)        r       p(r)     n\n",
            "Strom Props  Derived Proportion                      0.87***    2.5e-07     0.85***   8.77e-07    21\n",
            "Strom Props  Basal Proportion                       -0.87***    2.5e-07    -0.85***   8.77e-07    21\n",
            "Strom Props  Labechiida Prop                        -0.78***   3.21e-05    -0.73***   0.000153    21\n",
            "Strom Props  Clathrodictyida Prop                    0.05         0.838    -0.15         0.513    21\n",
            "Strom Props  Actinostromatida Prop                   0.61**      0.0031     0.60**     0.00438    21\n",
            "Strom Props  Stromatoporida Prop                     0.53*       0.0139     0.49*       0.0257    21\n",
            "Strom Props  Stromatoporellida Prop                  0.52*       0.0162     0.51*       0.0173    21\n",
            "Strom Props  Syringostromatida Prop                  0.84***   2.06e-06     0.57**     0.00702    21\n",
            "Strom Props  Amphiporida Prop                        0.65**     0.00135     0.61**     0.00322    21\n",
            "Strom Occ    Total Occurrence                        0.44*       0.0419     0.47*       0.0283    22\n",
            "Strom Occ    Derived Occurrence                      0.73***   0.000121     0.52*       0.0125    22\n",
            "Strom Occ    Basal Occurrence                       -0.02         0.936    -0.10         0.656    22\n",
            "Strom Occ    Labechiida Occ                         -0.31         0.156    -0.26         0.241    22\n",
            "Strom Occ    Clathrodictyida Occ                     0.30         0.168     0.15         0.492    22\n",
            "Strom Occ    Actinostromatida Occ                    0.65**     0.00102     0.57**     0.00582    22\n",
            "Strom Occ    Stromatoporida Occ                      0.62**     0.00188     0.52*       0.0132    22\n",
            "Strom Occ    Stromatoporellida Occ                   0.54*       0.0103     0.47*       0.0267    22\n",
            "Strom Occ    Syringostromatida Occ                   0.78***   1.71e-05     0.47*       0.0262    22\n",
            "Strom Occ    Amphiporida Occ                         0.65***    0.00098     0.53*       0.0106    22\n",
            "Strom Div    Total Diversity                         0.57**     0.00567     0.50*       0.0178    22\n",
            "Strom Div    Derived Diversity                       0.71***   0.000206     0.60**     0.00335    22\n",
            "Strom Div    Basal Diversity                         0.02         0.918    -0.01         0.955    22\n",
            "Strom Div    Labechiida Div                         -0.40        0.0652    -0.33         0.133    22\n",
            "Strom Div    Clathrodictyida Div                     0.42        0.0541     0.35         0.109    22\n",
            "Strom Div    Actinostromatida Div                    0.52*       0.0129     0.33          0.13    22\n",
            "Strom Div    Stromatoporida Div                      0.61**     0.00232     0.54*       0.0102    22\n",
            "Strom Div    Stromatoporellida Div                   0.53*       0.0114     0.52*       0.0141    22\n",
            "Strom Div    Syringostromatida Div                   0.74***   8.86e-05     0.54**     0.00885    22\n",
            "Strom Div    Amphiporida Div                         0.65**      0.0011     0.64**     0.00134    22\n",
            "Coral Div    Rugose Diversity                        0.54**     0.00905     0.47*       0.0289    22\n",
            "Coral Div    Tabulate Diversity                      0.44*       0.0404     0.41        0.0554    22\n",
            "Coral Occ    Rugose Occurrence                       0.47*       0.0259     0.41        0.0604    22\n",
            "Coral Occ    Tabulate Occurrence                     0.44*       0.0388     0.30         0.174    22\n",
            "Macrostrat   Total Area                              0.25         0.259     0.23         0.313    22\n",
            "Macrostrat   Carb Area                               0.13         0.559     0.08         0.733    22\n",
            "Macrostrat   Carb %                                 -0.36         0.104    -0.37        0.0865    22\n",
            "Proxies      SST                                    -0.25         0.266    -0.37        0.0936    22\n",
            "Proxies      Sea Level                              -0.38         0.084    -0.40        0.0636    22\n",
            "Proxies      Atm O2                                  0.46*       0.0331     0.46*        0.032    22\n",
            "Proxies      Atm CO2                                -0.44*       0.0383    -0.43*        0.044    22\n",
            "Proxies      Dissolved O2                            0.54**     0.00978     0.50*       0.0169    22\n",
            "Proxies      δ¹³C                                    0.33         0.139     0.36         0.101    22\n",
            "\n",
            "------------------------------------------------------------------------------------------\n",
            "Stage | TARGET: WIDTH (LOG)\n",
            "------------------------------------------------------------------------------------------\n",
            "Group        Variable                                 rho     p(rho)        r       p(r)     n\n",
            "Strom Props  Derived Proportion                      0.54*       0.0119     0.51*       0.0177    21\n",
            "Strom Props  Basal Proportion                       -0.54*       0.0119    -0.51*       0.0177    21\n",
            "Strom Props  Labechiida Prop                        -0.36         0.107    -0.15         0.518    21\n",
            "Strom Props  Clathrodictyida Prop                   -0.48*       0.0279    -0.50*       0.0206    21\n",
            "Strom Props  Actinostromatida Prop                   0.17          0.46     0.17         0.473    21\n",
            "Strom Props  Stromatoporida Prop                     0.09         0.691     0.06         0.813    21\n",
            "Strom Props  Stromatoporellida Prop                  0.13         0.583     0.29         0.195    21\n",
            "Strom Props  Syringostromatida Prop                  0.55**     0.00969     0.50*       0.0207    21\n",
            "Strom Props  Amphiporida Prop                        0.28         0.213     0.36         0.107    21\n",
            "Strom Occ    Total Occurrence                        0.19         0.394     0.36        0.0968    22\n",
            "Strom Occ    Derived Occurrence                      0.33         0.135     0.41        0.0559    22\n",
            "Strom Occ    Basal Occurrence                       -0.16         0.477    -0.10         0.658    22\n",
            "Strom Occ    Labechiida Occ                         -0.30         0.172     0.04         0.854    22\n",
            "Strom Occ    Clathrodictyida Occ                    -0.16         0.475    -0.21         0.339    22\n",
            "Strom Occ    Actinostromatida Occ                    0.30         0.172     0.36         0.104    22\n",
            "Strom Occ    Stromatoporida Occ                      0.26         0.243     0.33         0.131    22\n",
            "Strom Occ    Stromatoporellida Occ                   0.17         0.437     0.40        0.0678    22\n",
            "Strom Occ    Syringostromatida Occ                   0.43*       0.0456     0.46*       0.0316    22\n",
            "Strom Occ    Amphiporida Occ                         0.32         0.141     0.42        0.0521    22\n",
            "Strom Div    Total Diversity                         0.23           0.3     0.21         0.347    22\n",
            "Strom Div    Derived Diversity                       0.34         0.118     0.30         0.177    22\n",
            "Strom Div    Basal Diversity                        -0.11         0.619    -0.10         0.647    22\n",
            "Strom Div    Labechiida Div                         -0.33         0.137    -0.08         0.736    22\n",
            "Strom Div    Clathrodictyida Div                    -0.11         0.619    -0.06         0.783    22\n",
            "Strom Div    Actinostromatida Div                    0.10         0.657    -0.06         0.798    22\n",
            "Strom Div    Stromatoporida Div                      0.27         0.218     0.35         0.106    22\n",
            "Strom Div    Stromatoporellida Div                   0.17         0.463     0.34         0.118    22\n",
            "Strom Div    Syringostromatida Div                   0.36         0.103     0.30         0.174    22\n",
            "Strom Div    Amphiporida Div                         0.27         0.228     0.31         0.162    22\n",
            "Coral Div    Rugose Diversity                        0.12         0.598     0.13         0.554    22\n",
            "Coral Div    Tabulate Diversity                      0.18         0.434     0.17         0.448    22\n",
            "Coral Occ    Rugose Occurrence                       0.24         0.281     0.33          0.14    22\n",
            "Coral Occ    Tabulate Occurrence                     0.16         0.468     0.15         0.514    22\n",
            "Macrostrat   Total Area                              0.39        0.0744     0.39         0.073    22\n",
            "Macrostrat   Carb Area                               0.41        0.0554     0.33          0.13    22\n",
            "Macrostrat   Carb %                                 -0.21         0.344    -0.25         0.263    22\n",
            "Proxies      SST                                    -0.05         0.818     0.00          0.99    22\n",
            "Proxies      Sea Level                              -0.08         0.715    -0.03         0.905    22\n",
            "Proxies      Atm O2                                  0.22         0.336     0.18         0.419    22\n",
            "Proxies      Atm CO2                                -0.14         0.524    -0.11         0.635    22\n",
            "Proxies      Dissolved O2                            0.15         0.518     0.15         0.499    22\n",
            "Proxies      δ¹³C                                   -0.03         0.895    -0.01          0.95    22\n",
            "\n",
            "------------------------------------------------------------------------------------------\n",
            "5-Myr | TARGET: THICKNESS (LOG)\n",
            "------------------------------------------------------------------------------------------\n",
            "Group        Variable                                 rho     p(rho)        r       p(r)     n\n",
            "Strom Props  Derived Proportion                      0.88***   1.67e-08     0.93***   7.06e-11    24\n",
            "Strom Props  Basal Proportion                       -0.88***   1.67e-08    -0.93***   7.06e-11    24\n",
            "Strom Props  Labechiida Prop                        -0.83***    5.6e-07    -0.83***   6.98e-07    24\n",
            "Strom Props  Clathrodictyida Prop                    0.14           0.5    -0.07          0.75    24\n",
            "Strom Props  Actinostromatida Prop                   0.71***   0.000105     0.67***   0.000373    24\n",
            "Strom Props  Stromatoporida Prop                     0.64***   0.000777     0.58**     0.00307    24\n",
            "Strom Props  Stromatoporellida Prop                  0.82***   9.88e-07     0.82***   8.75e-07    24\n",
            "Strom Props  Syringostromatida Prop                  0.77***   1.16e-05     0.60**     0.00177    24\n",
            "Strom Props  Amphiporida Prop                        0.89***   9.28e-09     0.79***   4.02e-06    24\n",
            "Strom Occ    Total Occurrence                        0.47*       0.0143     0.44*       0.0206    27\n",
            "Strom Occ    Derived Occurrence                      0.78***   1.72e-06     0.56**     0.00241    27\n",
            "Strom Occ    Basal Occurrence                        0.13          0.51    -0.16         0.425    27\n",
            "Strom Occ    Labechiida Occ                         -0.27         0.172    -0.30         0.127    27\n",
            "Strom Occ    Clathrodictyida Occ                     0.40*         0.04     0.02          0.94    27\n",
            "Strom Occ    Actinostromatida Occ                    0.70***   4.72e-05     0.59**     0.00135    27\n",
            "Strom Occ    Stromatoporida Occ                      0.71***      3e-05     0.52**      0.0056    27\n",
            "Strom Occ    Stromatoporellida Occ                   0.81***   2.52e-07     0.49**     0.00967    27\n",
            "Strom Occ    Syringostromatida Occ                   0.74***   9.96e-06     0.57**     0.00196    27\n",
            "Strom Occ    Amphiporida Occ                         0.80***   4.54e-07     0.54**     0.00345    27\n",
            "Strom Div    Total Diversity                         0.61***   0.000681     0.64***   0.000351    27\n",
            "Strom Div    Derived Diversity                       0.76***    4.3e-06     0.76***   3.81e-06    27\n",
            "Strom Div    Basal Diversity                         0.13          0.52     0.05         0.799    27\n",
            "Strom Div    Labechiida Div                         -0.34         0.086    -0.38        0.0531    27\n",
            "Strom Div    Clathrodictyida Div                     0.52**     0.00528     0.54**      0.0038    27\n",
            "Strom Div    Actinostromatida Div                    0.48*        0.012     0.26         0.192    27\n",
            "Strom Div    Stromatoporida Div                      0.75***   6.76e-06     0.69***   6.52e-05    27\n",
            "Strom Div    Stromatoporellida Div                   0.81***   2.69e-07     0.79***   1.12e-06    27\n",
            "Strom Div    Syringostromatida Div                   0.75***   7.12e-06     0.75***   8.01e-06    27\n",
            "Strom Div    Amphiporida Div                         0.72***   2.46e-05     0.70***   4.16e-05    27\n",
            "Coral Div    Rugose Diversity                        0.55**     0.00323     0.58**     0.00148    27\n",
            "Coral Div    Tabulate Diversity                      0.41*       0.0338     0.45*        0.018    27\n",
            "Coral Occ    Rugose Occurrence                       0.46*       0.0148     0.34        0.0834    27\n",
            "Coral Occ    Tabulate Occurrence                     0.35        0.0758     0.22         0.269    27\n",
            "Macrostrat   Total Area                              0.18         0.363     0.05         0.809    27\n",
            "Macrostrat   Carb Area                              -0.06         0.777    -0.15         0.466    27\n",
            "Macrostrat   Carb %                                 -0.62***    0.00052    -0.57**     0.00208    27\n",
            "Proxies      SST                                    -0.51**     0.00625    -0.53**     0.00444    27\n",
            "Proxies      Sea Level                              -0.57**     0.00191    -0.57**     0.00181    27\n",
            "Proxies      Atm O2                                  0.29         0.147     0.29         0.145    27\n",
            "Proxies      Atm CO2                                -0.52**     0.00509    -0.55**     0.00267    27\n",
            "Proxies      Dissolved O2                            0.44*       0.0223     0.41*       0.0326    27\n",
            "Proxies      δ¹³C                                    0.27         0.165     0.27         0.178    27\n",
            "\n",
            "------------------------------------------------------------------------------------------\n",
            "5-Myr | TARGET: WIDTH (LOG)\n",
            "------------------------------------------------------------------------------------------\n",
            "Group        Variable                                 rho     p(rho)        r       p(r)     n\n",
            "Strom Props  Derived Proportion                      0.57**     0.00369     0.59**     0.00225    24\n",
            "Strom Props  Basal Proportion                       -0.57**     0.00369    -0.59**     0.00225    24\n",
            "Strom Props  Labechiida Prop                        -0.45*       0.0286    -0.29         0.171    24\n",
            "Strom Props  Clathrodictyida Prop                   -0.37         0.079    -0.49*       0.0155    24\n",
            "Strom Props  Actinostromatida Prop                   0.28         0.183     0.27         0.204    24\n",
            "Strom Props  Stromatoporida Prop                     0.21         0.334     0.12         0.588    24\n",
            "Strom Props  Stromatoporellida Prop                  0.39        0.0579     0.45*       0.0286    24\n",
            "Strom Props  Syringostromatida Prop                  0.68***   0.000264     0.71***   0.000112    24\n",
            "Strom Props  Amphiporida Prop                        0.59**     0.00226     0.57**      0.0034    24\n",
            "Strom Occ    Total Occurrence                        0.38        0.0528     0.45*       0.0199    27\n",
            "Strom Occ    Derived Occurrence                      0.56**     0.00219     0.56**     0.00255    27\n",
            "Strom Occ    Basal Occurrence                        0.05         0.793    -0.15         0.457    27\n",
            "Strom Occ    Labechiida Occ                         -0.21         0.303    -0.05          0.82    27\n",
            "Strom Occ    Clathrodictyida Occ                     0.16         0.412    -0.17         0.388    27\n",
            "Strom Occ    Actinostromatida Occ                    0.49*       0.0103     0.47*       0.0128    27\n",
            "Strom Occ    Stromatoporida Occ                      0.47*       0.0139     0.43*       0.0244    27\n",
            "Strom Occ    Stromatoporellida Occ                   0.54**     0.00379     0.50**     0.00762    27\n",
            "Strom Occ    Syringostromatida Occ                   0.65***   0.000219     0.68***   9.43e-05    27\n",
            "Strom Occ    Amphiporida Occ                         0.61***   0.000668     0.55**     0.00324    27\n",
            "Strom Div    Total Diversity                         0.51**     0.00695     0.49**     0.00984    27\n",
            "Strom Div    Derived Diversity                       0.54**     0.00396     0.57**      0.0019    27\n",
            "Strom Div    Basal Diversity                         0.13         0.514     0.06         0.753    27\n",
            "Strom Div    Labechiida Div                         -0.26         0.196    -0.16         0.431    27\n",
            "Strom Div    Clathrodictyida Div                     0.26         0.199     0.29         0.138    27\n",
            "Strom Div    Actinostromatida Div                    0.20         0.308    -0.01          0.95    27\n",
            "Strom Div    Stromatoporida Div                      0.54**      0.0036     0.55**     0.00306    27\n",
            "Strom Div    Stromatoporellida Div                   0.56**     0.00251     0.68***   9.22e-05    27\n",
            "Strom Div    Syringostromatida Div                   0.64***   0.000292     0.67***   0.000123    27\n",
            "Strom Div    Amphiporida Div                         0.46*       0.0154     0.44*       0.0205    27\n",
            "Coral Div    Rugose Diversity                        0.27         0.168     0.35        0.0774    27\n",
            "Coral Div    Tabulate Diversity                      0.26         0.193     0.33        0.0943    27\n",
            "Coral Occ    Rugose Occurrence                       0.33        0.0947     0.35        0.0752    27\n",
            "Coral Occ    Tabulate Occurrence                     0.20         0.323     0.16         0.434    27\n",
            "Macrostrat   Total Area                              0.26         0.182     0.21         0.285    27\n",
            "Macrostrat   Carb Area                               0.16         0.436     0.07         0.724    27\n",
            "Macrostrat   Carb %                                 -0.28         0.155    -0.21         0.285    27\n",
            "Proxies      SST                                    -0.23         0.257    -0.19         0.349    27\n",
            "Proxies      Sea Level                              -0.17         0.403    -0.11         0.592    27\n",
            "Proxies      Atm O2                                  0.14           0.5     0.18         0.376    27\n",
            "Proxies      Atm CO2                                -0.12         0.565    -0.13          0.51    27\n",
            "Proxies      Dissolved O2                            0.18         0.373     0.19         0.342    27\n",
            "Proxies      δ¹³C                                   -0.13         0.525    -0.15         0.453    27\n",
            "\n",
            "Saved: ./output/results_correlations_stage.csv\n",
            "Saved: ./output/results_correlations_5myr.csv\n",
            "Saved: ./output/results_correlations_stage_FULL_with_status.csv\n",
            "Saved: ./output/results_correlations_5myr_FULL_with_status.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Scope          Target              Predictor                  Label  \\\n",
              "0   Stage  thickness_mean     derived_strom_prop     Derived Proportion   \n",
              "1   Stage  thickness_mean       basal_strom_prop       Basal Proportion   \n",
              "2   Stage  thickness_mean        Labechiida_prop        Labechiida Prop   \n",
              "3   Stage  thickness_mean   Clathrodictyida_prop   Clathrodictyida Prop   \n",
              "4   Stage  thickness_mean  Actinostromatida_prop  Actinostromatida Prop   \n",
              "..    ...             ...                    ...                    ...   \n",
              "79  Stage      width_mean              sea_level              Sea Level   \n",
              "80  Stage      width_mean         atmospheric_O2                 Atm O2   \n",
              "81  Stage      width_mean        atmospheric_CO2                Atm CO2   \n",
              "82  Stage      width_mean           dissolved_O2           Dissolved O2   \n",
              "83  Stage      width_mean                   d13C                   δ¹³C   \n",
              "\n",
              "          Group  Spearman_Rho    Spearman_P  Pearson_R     Pearson_P   N  \\\n",
              "0   Strom Props      0.872563  2.501763e-07   0.853369  8.771189e-07  21   \n",
              "1   Strom Props     -0.872563  2.501763e-07  -0.853369  8.771189e-07  21   \n",
              "2   Strom Props     -0.778648  3.214033e-05  -0.733873  1.527280e-04  21   \n",
              "3   Strom Props      0.047557  8.378025e-01  -0.151025  5.134546e-01  21   \n",
              "4   Strom Props      0.613505  3.098310e-03   0.595730  4.377395e-03  21   \n",
              "..          ...           ...           ...        ...           ...  ..   \n",
              "79      Proxies     -0.082463  7.152392e-01  -0.027155  9.045200e-01  22   \n",
              "80      Proxies      0.215193  3.361696e-01   0.181302  4.193975e-01  22   \n",
              "81      Proxies     -0.143462  5.241721e-01  -0.107114  6.351780e-01  22   \n",
              "82      Proxies      0.145722  5.175893e-01   0.152138  4.991127e-01  22   \n",
              "83      Proxies     -0.029935  8.947936e-01  -0.014157  9.501429e-01  22   \n",
              "\n",
              "   Status  \n",
              "0      ok  \n",
              "1      ok  \n",
              "2      ok  \n",
              "3      ok  \n",
              "4      ok  \n",
              "..    ...  \n",
              "79     ok  \n",
              "80     ok  \n",
              "81     ok  \n",
              "82     ok  \n",
              "83     ok  \n",
              "\n",
              "[84 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c47a337d-e4ff-4dd4-b019-fc20ecfd205e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Scope</th>\n",
              "      <th>Target</th>\n",
              "      <th>Predictor</th>\n",
              "      <th>Label</th>\n",
              "      <th>Group</th>\n",
              "      <th>Spearman_Rho</th>\n",
              "      <th>Spearman_P</th>\n",
              "      <th>Pearson_R</th>\n",
              "      <th>Pearson_P</th>\n",
              "      <th>N</th>\n",
              "      <th>Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stage</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>Derived Proportion</td>\n",
              "      <td>Strom Props</td>\n",
              "      <td>0.872563</td>\n",
              "      <td>2.501763e-07</td>\n",
              "      <td>0.853369</td>\n",
              "      <td>8.771189e-07</td>\n",
              "      <td>21</td>\n",
              "      <td>ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Stage</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>Basal Proportion</td>\n",
              "      <td>Strom Props</td>\n",
              "      <td>-0.872563</td>\n",
              "      <td>2.501763e-07</td>\n",
              "      <td>-0.853369</td>\n",
              "      <td>8.771189e-07</td>\n",
              "      <td>21</td>\n",
              "      <td>ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Stage</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>Labechiida_prop</td>\n",
              "      <td>Labechiida Prop</td>\n",
              "      <td>Strom Props</td>\n",
              "      <td>-0.778648</td>\n",
              "      <td>3.214033e-05</td>\n",
              "      <td>-0.733873</td>\n",
              "      <td>1.527280e-04</td>\n",
              "      <td>21</td>\n",
              "      <td>ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stage</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>Clathrodictyida_prop</td>\n",
              "      <td>Clathrodictyida Prop</td>\n",
              "      <td>Strom Props</td>\n",
              "      <td>0.047557</td>\n",
              "      <td>8.378025e-01</td>\n",
              "      <td>-0.151025</td>\n",
              "      <td>5.134546e-01</td>\n",
              "      <td>21</td>\n",
              "      <td>ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stage</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>Actinostromatida_prop</td>\n",
              "      <td>Actinostromatida Prop</td>\n",
              "      <td>Strom Props</td>\n",
              "      <td>0.613505</td>\n",
              "      <td>3.098310e-03</td>\n",
              "      <td>0.595730</td>\n",
              "      <td>4.377395e-03</td>\n",
              "      <td>21</td>\n",
              "      <td>ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>Stage</td>\n",
              "      <td>width_mean</td>\n",
              "      <td>sea_level</td>\n",
              "      <td>Sea Level</td>\n",
              "      <td>Proxies</td>\n",
              "      <td>-0.082463</td>\n",
              "      <td>7.152392e-01</td>\n",
              "      <td>-0.027155</td>\n",
              "      <td>9.045200e-01</td>\n",
              "      <td>22</td>\n",
              "      <td>ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>Stage</td>\n",
              "      <td>width_mean</td>\n",
              "      <td>atmospheric_O2</td>\n",
              "      <td>Atm O2</td>\n",
              "      <td>Proxies</td>\n",
              "      <td>0.215193</td>\n",
              "      <td>3.361696e-01</td>\n",
              "      <td>0.181302</td>\n",
              "      <td>4.193975e-01</td>\n",
              "      <td>22</td>\n",
              "      <td>ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>Stage</td>\n",
              "      <td>width_mean</td>\n",
              "      <td>atmospheric_CO2</td>\n",
              "      <td>Atm CO2</td>\n",
              "      <td>Proxies</td>\n",
              "      <td>-0.143462</td>\n",
              "      <td>5.241721e-01</td>\n",
              "      <td>-0.107114</td>\n",
              "      <td>6.351780e-01</td>\n",
              "      <td>22</td>\n",
              "      <td>ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>Stage</td>\n",
              "      <td>width_mean</td>\n",
              "      <td>dissolved_O2</td>\n",
              "      <td>Dissolved O2</td>\n",
              "      <td>Proxies</td>\n",
              "      <td>0.145722</td>\n",
              "      <td>5.175893e-01</td>\n",
              "      <td>0.152138</td>\n",
              "      <td>4.991127e-01</td>\n",
              "      <td>22</td>\n",
              "      <td>ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>Stage</td>\n",
              "      <td>width_mean</td>\n",
              "      <td>d13C</td>\n",
              "      <td>δ¹³C</td>\n",
              "      <td>Proxies</td>\n",
              "      <td>-0.029935</td>\n",
              "      <td>8.947936e-01</td>\n",
              "      <td>-0.014157</td>\n",
              "      <td>9.501429e-01</td>\n",
              "      <td>22</td>\n",
              "      <td>ok</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>84 rows × 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c47a337d-e4ff-4dd4-b019-fc20ecfd205e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c47a337d-e4ff-4dd4-b019-fc20ecfd205e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c47a337d-e4ff-4dd4-b019-fc20ecfd205e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_becdc246-a2a0-4eee-8cf4-c2c4340e558e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('stage_ok')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_becdc246-a2a0-4eee-8cf4-c2c4340e558e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('stage_ok');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "stage_ok",
              "summary": "{\n  \"name\": \"stage_ok\",\n  \"rows\": 84,\n  \"fields\": [\n    {\n      \"column\": \"Scope\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Stage\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"width_mean\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predictor\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 42,\n        \"samples\": [\n          \"Stromatoporida_genus\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 42,\n        \"samples\": [\n          \"Stromatoporida Div\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Group\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Strom Props\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spearman_Rho\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3811512791776621,\n        \"min\": -0.8725625062887773,\n        \"max\": 0.8725625062887773,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          0.24039548022598872\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spearman_P\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2663832458504643,\n        \"min\": 2.5017628461079054e-07,\n        \"max\": 0.9363706903499582,\n        \"num_unique_values\": 82,\n        \"samples\": [\n          0.025885612054582896\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pearson_R\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.34511825740161867,\n        \"min\": -0.8533693231861407,\n        \"max\": 0.8533693231861407,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          0.32502469123820915\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pearson_P\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2922452386845082,\n        \"min\": 8.77118909244623e-07,\n        \"max\": 0.9899844649001842,\n        \"num_unique_values\": 82,\n        \"samples\": [\n          0.060355370444545\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 21,\n        \"max\": 22,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ok\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Scope          Target              Predictor                  Label  \\\n",
              "0   5-Myr  thickness_mean     derived_strom_prop     Derived Proportion   \n",
              "1   5-Myr  thickness_mean       basal_strom_prop       Basal Proportion   \n",
              "2   5-Myr  thickness_mean        Labechiida_prop        Labechiida Prop   \n",
              "3   5-Myr  thickness_mean   Clathrodictyida_prop   Clathrodictyida Prop   \n",
              "4   5-Myr  thickness_mean  Actinostromatida_prop  Actinostromatida Prop   \n",
              "..    ...             ...                    ...                    ...   \n",
              "79  5-Myr      width_mean              sea_level              Sea Level   \n",
              "80  5-Myr      width_mean         atmospheric_O2                 Atm O2   \n",
              "81  5-Myr      width_mean        atmospheric_CO2                Atm CO2   \n",
              "82  5-Myr      width_mean           dissolved_O2           Dissolved O2   \n",
              "83  5-Myr      width_mean                   d13C                   δ¹³C   \n",
              "\n",
              "          Group  Spearman_Rho    Spearman_P  Pearson_R     Pearson_P   N  \\\n",
              "0   Strom Props      0.878380  1.673329e-08   0.927584  7.061008e-11  24   \n",
              "1   Strom Props     -0.878380  1.673329e-08  -0.927584  7.061008e-11  24   \n",
              "2   Strom Props     -0.828941  5.599693e-07  -0.825183  6.980943e-07  24   \n",
              "3   Strom Props      0.144726  4.998510e-01  -0.068724  7.496635e-01  24   \n",
              "4   Strom Props      0.708982  1.051787e-04   0.666808  3.730702e-04  24   \n",
              "..          ...           ...           ...        ...           ...  ..   \n",
              "79      Proxies     -0.167762  4.029193e-01  -0.107911  5.921266e-01  27   \n",
              "80      Proxies      0.135676  4.998249e-01   0.177231  3.764953e-01  27   \n",
              "81      Proxies     -0.115814  5.651215e-01  -0.132356  5.104707e-01  27   \n",
              "82      Proxies      0.178457  3.731488e-01   0.190122  3.421826e-01  27   \n",
              "83      Proxies     -0.127943  5.247939e-01  -0.150674  4.531474e-01  27   \n",
              "\n",
              "   Status  \n",
              "0      ok  \n",
              "1      ok  \n",
              "2      ok  \n",
              "3      ok  \n",
              "4      ok  \n",
              "..    ...  \n",
              "79     ok  \n",
              "80     ok  \n",
              "81     ok  \n",
              "82     ok  \n",
              "83     ok  \n",
              "\n",
              "[84 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9145ceff-ecb0-4798-ad33-f39389d6f3f8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Scope</th>\n",
              "      <th>Target</th>\n",
              "      <th>Predictor</th>\n",
              "      <th>Label</th>\n",
              "      <th>Group</th>\n",
              "      <th>Spearman_Rho</th>\n",
              "      <th>Spearman_P</th>\n",
              "      <th>Pearson_R</th>\n",
              "      <th>Pearson_P</th>\n",
              "      <th>N</th>\n",
              "      <th>Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5-Myr</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>Derived Proportion</td>\n",
              "      <td>Strom Props</td>\n",
              "      <td>0.878380</td>\n",
              "      <td>1.673329e-08</td>\n",
              "      <td>0.927584</td>\n",
              "      <td>7.061008e-11</td>\n",
              "      <td>24</td>\n",
              "      <td>ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5-Myr</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>Basal Proportion</td>\n",
              "      <td>Strom Props</td>\n",
              "      <td>-0.878380</td>\n",
              "      <td>1.673329e-08</td>\n",
              "      <td>-0.927584</td>\n",
              "      <td>7.061008e-11</td>\n",
              "      <td>24</td>\n",
              "      <td>ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5-Myr</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>Labechiida_prop</td>\n",
              "      <td>Labechiida Prop</td>\n",
              "      <td>Strom Props</td>\n",
              "      <td>-0.828941</td>\n",
              "      <td>5.599693e-07</td>\n",
              "      <td>-0.825183</td>\n",
              "      <td>6.980943e-07</td>\n",
              "      <td>24</td>\n",
              "      <td>ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5-Myr</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>Clathrodictyida_prop</td>\n",
              "      <td>Clathrodictyida Prop</td>\n",
              "      <td>Strom Props</td>\n",
              "      <td>0.144726</td>\n",
              "      <td>4.998510e-01</td>\n",
              "      <td>-0.068724</td>\n",
              "      <td>7.496635e-01</td>\n",
              "      <td>24</td>\n",
              "      <td>ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5-Myr</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>Actinostromatida_prop</td>\n",
              "      <td>Actinostromatida Prop</td>\n",
              "      <td>Strom Props</td>\n",
              "      <td>0.708982</td>\n",
              "      <td>1.051787e-04</td>\n",
              "      <td>0.666808</td>\n",
              "      <td>3.730702e-04</td>\n",
              "      <td>24</td>\n",
              "      <td>ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>5-Myr</td>\n",
              "      <td>width_mean</td>\n",
              "      <td>sea_level</td>\n",
              "      <td>Sea Level</td>\n",
              "      <td>Proxies</td>\n",
              "      <td>-0.167762</td>\n",
              "      <td>4.029193e-01</td>\n",
              "      <td>-0.107911</td>\n",
              "      <td>5.921266e-01</td>\n",
              "      <td>27</td>\n",
              "      <td>ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>5-Myr</td>\n",
              "      <td>width_mean</td>\n",
              "      <td>atmospheric_O2</td>\n",
              "      <td>Atm O2</td>\n",
              "      <td>Proxies</td>\n",
              "      <td>0.135676</td>\n",
              "      <td>4.998249e-01</td>\n",
              "      <td>0.177231</td>\n",
              "      <td>3.764953e-01</td>\n",
              "      <td>27</td>\n",
              "      <td>ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>5-Myr</td>\n",
              "      <td>width_mean</td>\n",
              "      <td>atmospheric_CO2</td>\n",
              "      <td>Atm CO2</td>\n",
              "      <td>Proxies</td>\n",
              "      <td>-0.115814</td>\n",
              "      <td>5.651215e-01</td>\n",
              "      <td>-0.132356</td>\n",
              "      <td>5.104707e-01</td>\n",
              "      <td>27</td>\n",
              "      <td>ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>5-Myr</td>\n",
              "      <td>width_mean</td>\n",
              "      <td>dissolved_O2</td>\n",
              "      <td>Dissolved O2</td>\n",
              "      <td>Proxies</td>\n",
              "      <td>0.178457</td>\n",
              "      <td>3.731488e-01</td>\n",
              "      <td>0.190122</td>\n",
              "      <td>3.421826e-01</td>\n",
              "      <td>27</td>\n",
              "      <td>ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>5-Myr</td>\n",
              "      <td>width_mean</td>\n",
              "      <td>d13C</td>\n",
              "      <td>δ¹³C</td>\n",
              "      <td>Proxies</td>\n",
              "      <td>-0.127943</td>\n",
              "      <td>5.247939e-01</td>\n",
              "      <td>-0.150674</td>\n",
              "      <td>4.531474e-01</td>\n",
              "      <td>27</td>\n",
              "      <td>ok</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>84 rows × 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9145ceff-ecb0-4798-ad33-f39389d6f3f8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9145ceff-ecb0-4798-ad33-f39389d6f3f8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9145ceff-ecb0-4798-ad33-f39389d6f3f8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_0bebeef8-9461-4862-a904-6b453b6328c9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('myr_ok')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0bebeef8-9461-4862-a904-6b453b6328c9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('myr_ok');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "myr_ok",
              "summary": "{\n  \"name\": \"myr_ok\",\n  \"rows\": 84,\n  \"fields\": [\n    {\n      \"column\": \"Scope\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"5-Myr\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"width_mean\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predictor\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 42,\n        \"samples\": [\n          \"Stromatoporida_genus\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 42,\n        \"samples\": [\n          \"Stromatoporida Div\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Group\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Strom Props\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spearman_Rho\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.43157243037985377,\n        \"min\": -0.8783797136997108,\n        \"max\": 0.8850632123965714,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          0.3281345719184964\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spearman_P\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.197764719704609,\n        \"min\": 9.28059032977321e-09,\n        \"max\": 0.7926759770024908,\n        \"num_unique_values\": 82,\n        \"samples\": [\n          0.01480289574700302\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pearson_R\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4237732578641066,\n        \"min\": -0.9275841519122263,\n        \"max\": 0.9275841519122263,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          0.34805671670861804\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pearson_P\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.26574708067335173,\n        \"min\": 7.061007671886164e-11,\n        \"max\": 0.9500486812462953,\n        \"num_unique_values\": 82,\n        \"samples\": [\n          0.08336721170167355\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 24,\n        \"max\": 27,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ok\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# @title CELL 12: COMPREHENSIVE CORRELATION ANALYSIS (MULTI-METRIC & 5-MYR BIOLOGY)\n",
        "#   - NO T/W ratio computed or compared\n",
        "#   - FIXES:\n",
        "#       (1) Pairwise-complete correlations per predictor (NaNs in other columns won't block)\n",
        "#       (2) UPDATED: NO group-level presence filters (Option 1 policy)\n",
        "#           * All groups use the full dataset; missingness handled per-pair only\n",
        "#       (3) Optional: treat coral zeros as missing (ONLY if zeros encode \"no data\", not true absence)\n",
        "#   - Includes δ13C (expects column name 'd13C')\n",
        "#   - Standardizes atmospheric O2/CO2 column names:\n",
        "#       atmospheric_O2, atmospheric_CO2\n",
        "# =============================================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "import re\n",
        "\n",
        "print(\"=\"*90)\n",
        "print(\"COMPREHENSIVE CORRELATION ANALYSIS\")\n",
        "print(\"Metrics: Thickness, Width\")\n",
        "print(\"Scopes:  Stage-Level AND 5-Myr Bins\")\n",
        "print(\"Notes:   NO T/W ratio; pairwise-complete; NO group-level presence filters\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "# -----------------------------------------------------------------------------#\n",
        "# SETTINGS\n",
        "# -----------------------------------------------------------------------------#\n",
        "MIN_N = 5\n",
        "VERBOSE_SKIPS = False            # show reasons for non-results\n",
        "TREAT_CORAL_ZEROS_AS_MISSING = False  # set True ONLY if 0 means \"no measurement\" (not true absence)\n",
        "\n",
        "# -----------------------------------------------------------------------------#\n",
        "# 0. SAFETY: define STROM_ORDERS if missing\n",
        "# -----------------------------------------------------------------------------#\n",
        "if 'STROM_ORDERS' not in globals():\n",
        "    STROM_ORDERS = [\n",
        "        'Labechiida', 'Clathrodictyida', 'Actinostromatida',\n",
        "        'Stromatoporida', 'Stromatoporellida', 'Syringostromatida', 'Amphiporida'\n",
        "    ]\n",
        "    print(\"[WARN] STROM_ORDERS not found in globals(); using default list.\")\n",
        "\n",
        "# -----------------------------------------------------------------------------#\n",
        "# 1. PRE-PROCESSING: CALCULATE DERIVED VARIABLES (NO T/W)\n",
        "# -----------------------------------------------------------------------------#\n",
        "print(\"Pre-processing data...\")\n",
        "\n",
        "def calculate_derived_metrics(dataset, label):\n",
        "    if dataset is None or dataset.empty:\n",
        "        print(f\"  - [{label}] Empty dataset; skip derived metrics.\")\n",
        "        return dataset\n",
        "\n",
        "    dataset = dataset.copy()\n",
        "\n",
        "    # Remove T/W ratio if it exists from older runs (do NOT compute it)\n",
        "    if 'thickness_width_ratio' in dataset.columns:\n",
        "        dataset = dataset.drop(columns=['thickness_width_ratio'])\n",
        "\n",
        "    # Stromatoporoid Proportions & Groups\n",
        "    strom_cols = [c for c in dataset.columns if c.endswith('_occ') and c != 'strom_total_occ']\n",
        "    if strom_cols:\n",
        "        if 'strom_total_occ' not in dataset.columns:\n",
        "            dataset['strom_total_occ'] = dataset[strom_cols].sum(axis=1)\n",
        "\n",
        "        dataset['strom_total_occ'] = pd.to_numeric(dataset['strom_total_occ'], errors='coerce')\n",
        "\n",
        "        for order in STROM_ORDERS:\n",
        "            col_occ = f'{order}_occ'\n",
        "            if col_occ in dataset.columns:\n",
        "                dataset[col_occ] = pd.to_numeric(dataset[col_occ], errors='coerce')  # keep NaN\n",
        "                dataset[f'{order}_prop'] = np.where(\n",
        "                    dataset['strom_total_occ'] > 0,\n",
        "                    dataset[col_occ] / dataset['strom_total_occ'],\n",
        "                    np.nan\n",
        "                )\n",
        "\n",
        "        derived_orders = ['Actinostromatida', 'Stromatoporida', 'Stromatoporellida',\n",
        "                          'Syringostromatida', 'Amphiporida']\n",
        "        basal_orders   = ['Labechiida', 'Clathrodictyida']\n",
        "\n",
        "        # occurrences: sum with min_count=1 so all-NaN stays NaN\n",
        "        derived_occ_cols = [f'{o}_occ' for o in derived_orders if f'{o}_occ' in dataset.columns]\n",
        "        basal_occ_cols   = [f'{o}_occ' for o in basal_orders   if f'{o}_occ' in dataset.columns]\n",
        "\n",
        "        dataset['derived_strom_occ'] = (\n",
        "            dataset[derived_occ_cols].apply(pd.to_numeric, errors='coerce').sum(axis=1, min_count=1)\n",
        "            if derived_occ_cols else np.nan\n",
        "        )\n",
        "        dataset['basal_strom_occ'] = (\n",
        "            dataset[basal_occ_cols].apply(pd.to_numeric, errors='coerce').sum(axis=1, min_count=1)\n",
        "            if basal_occ_cols else np.nan\n",
        "        )\n",
        "\n",
        "        # diversity: sum with min_count=1 so all-NaN stays NaN\n",
        "        derived_div_cols = [f'{o}_genus' for o in derived_orders if f'{o}_genus' in dataset.columns]\n",
        "        basal_div_cols   = [f'{o}_genus' for o in basal_orders   if f'{o}_genus' in dataset.columns]\n",
        "\n",
        "        dataset['derived_strom_div'] = (\n",
        "            dataset[derived_div_cols].apply(pd.to_numeric, errors='coerce').sum(axis=1, min_count=1)\n",
        "            if derived_div_cols else np.nan\n",
        "        )\n",
        "        dataset['basal_strom_div'] = (\n",
        "            dataset[basal_div_cols].apply(pd.to_numeric, errors='coerce').sum(axis=1, min_count=1)\n",
        "            if basal_div_cols else np.nan\n",
        "        )\n",
        "\n",
        "        dataset['derived_strom_prop'] = np.where(\n",
        "            dataset['strom_total_occ'] > 0,\n",
        "            dataset['derived_strom_occ'] / dataset['strom_total_occ'],\n",
        "            np.nan\n",
        "        )\n",
        "        dataset['basal_strom_prop'] = np.where(\n",
        "            dataset['strom_total_occ'] > 0,\n",
        "            dataset['basal_strom_occ'] / dataset['strom_total_occ'],\n",
        "            np.nan\n",
        "        )\n",
        "\n",
        "        print(f\"  [OK] [{label}] Calculated strom proportions and groupings\")\n",
        "    else:\n",
        "        print(f\"  - [{label}] No strom occurrence columns found.\")\n",
        "\n",
        "    return dataset\n",
        "\n",
        "df = calculate_derived_metrics(df, \"Stage\")\n",
        "df_5myr = calculate_derived_metrics(df_5myr, \"5-Myr\")\n",
        "\n",
        "# -----------------------------------------------------------------------------#\n",
        "# 1A. STANDARDIZE ATMOSPHERIC O2/CO2 COLUMN NAMES (Stage + 5-Myr)\n",
        "# -----------------------------------------------------------------------------#\n",
        "def standardize_atm_cols(dataset, label):\n",
        "    if dataset is None or dataset.empty:\n",
        "        return dataset\n",
        "    dataset = dataset.copy()\n",
        "\n",
        "    def _find_col(candidates, regex_pat=None):\n",
        "        for c in candidates:\n",
        "            if c in dataset.columns:\n",
        "                return c\n",
        "        if regex_pat is not None:\n",
        "            hits = [c for c in dataset.columns if re.search(regex_pat, c, flags=re.IGNORECASE)]\n",
        "            return hits[0] if hits else None\n",
        "        return None\n",
        "\n",
        "    # Atmospheric O2\n",
        "    if 'atmospheric_O2' not in dataset.columns:\n",
        "        o2_src = _find_col(\n",
        "            candidates=['atm_O2','atmospheric_o2','oxygen','pO2','PO2','O2_atm','oxygen_atm'],\n",
        "            regex_pat=r'(atm|atmos).*o2|po2'\n",
        "        )\n",
        "        if o2_src is not None:\n",
        "            dataset['atmospheric_O2'] = pd.to_numeric(dataset[o2_src], errors='coerce')\n",
        "            print(f\"  [OK] [{label}] atmospheric_O2 <- {o2_src}\")\n",
        "        else:\n",
        "            print(f\"  [WARN] [{label}] No atmospheric O2 column found (atmospheric_O2 missing).\")\n",
        "\n",
        "    # Atmospheric CO2\n",
        "    if 'atmospheric_CO2' not in dataset.columns:\n",
        "        co2_src = _find_col(\n",
        "            candidates=['atm_CO2','atmospheric_co2','co2','pCO2','PCO2','CO2_atm','co2_atm'],\n",
        "            regex_pat=r'(atm|atmos).*co2|pco2'\n",
        "        )\n",
        "        if co2_src is not None:\n",
        "            dataset['atmospheric_CO2'] = pd.to_numeric(dataset[co2_src], errors='coerce')\n",
        "            print(f\"  [OK] [{label}] atmospheric_CO2 <- {co2_src}\")\n",
        "        else:\n",
        "            print(f\"  [WARN] [{label}] No atmospheric CO2 column found (atmospheric_CO2 missing).\")\n",
        "\n",
        "    return dataset\n",
        "\n",
        "df = standardize_atm_cols(df, \"Stage\")\n",
        "df_5myr = standardize_atm_cols(df_5myr, \"5-Myr\")\n",
        "\n",
        "# -----------------------------------------------------------------------------#\n",
        "# 1B. CORAL TOTALS (for optional coral zero-handling)\n",
        "# -----------------------------------------------------------------------------#\n",
        "def add_coral_totals(dataset, label):\n",
        "    if dataset is None or dataset.empty:\n",
        "        return dataset\n",
        "    dataset = dataset.copy()\n",
        "\n",
        "    for c in ['rugose_occ','tabulate_occ','rugose_div','tabulate_div']:\n",
        "        if c in dataset.columns:\n",
        "            dataset[c] = pd.to_numeric(dataset[c], errors='coerce')\n",
        "\n",
        "    occ_cols = [c for c in ['rugose_occ','tabulate_occ'] if c in dataset.columns]\n",
        "    div_cols = [c for c in ['rugose_div','tabulate_div'] if c in dataset.columns]\n",
        "\n",
        "    if occ_cols:\n",
        "        dataset['coral_total_occ'] = dataset[occ_cols].sum(axis=1, min_count=1)\n",
        "    if div_cols:\n",
        "        dataset['coral_total_div'] = dataset[div_cols].sum(axis=1, min_count=1)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "df = add_coral_totals(df, \"Stage\")\n",
        "df_5myr = add_coral_totals(df_5myr, \"5-Myr\")\n",
        "\n",
        "# -----------------------------------------------------------------------------#\n",
        "# 1C. BUILD DATASET VIEWS (UPDATED: NO PRESENCE FILTERS)\n",
        "#     Option 1 policy: keep ALL rows; missingness handled pairwise in calc_stats_pairwise().\n",
        "# -----------------------------------------------------------------------------#\n",
        "df_all = df\n",
        "df_5myr_all = df_5myr\n",
        "\n",
        "# For compatibility with choose_view() and group logic, strom/coral views are identical.\n",
        "df_strom = df_all\n",
        "df_5myr_strom = df_5myr_all\n",
        "\n",
        "df_coral = df_all\n",
        "df_5myr_coral = df_5myr_all\n",
        "\n",
        "# -----------------------------------------------------------------------------#\n",
        "# 2. DEFINE VARIABLE GROUPS\n",
        "# -----------------------------------------------------------------------------#\n",
        "reef_targets = [\n",
        "    ('thickness_mean', 'Thickness (Log)'),\n",
        "    ('width_mean', 'Width (Log)')\n",
        "]\n",
        "\n",
        "strom_prop_vars = [('derived_strom_prop', 'Derived Proportion'), ('basal_strom_prop', 'Basal Proportion')] + \\\n",
        "                  [(f'{order}_prop', f'{order} Prop') for order in STROM_ORDERS]\n",
        "\n",
        "strom_occ_vars = [('strom_total_occ', 'Total Occurrence'), ('derived_strom_occ', 'Derived Occurrence'), ('basal_strom_occ', 'Basal Occurrence')] + \\\n",
        "                 [(f'{order}_occ', f'{order} Occ') for order in STROM_ORDERS]\n",
        "\n",
        "strom_div_vars = [('strom_total_gen', 'Total Diversity'), ('derived_strom_div', 'Derived Diversity'), ('basal_strom_div', 'Basal Diversity')] + \\\n",
        "                 [(f'{order}_genus', f'{order} Div') for order in STROM_ORDERS]\n",
        "\n",
        "coral_div_vars = [('rugose_div', 'Rugose Diversity'), ('tabulate_div', 'Tabulate Diversity')]\n",
        "coral_occ_vars = [('rugose_occ', 'Rugose Occurrence'), ('tabulate_occ', 'Tabulate Occurrence')]\n",
        "\n",
        "env_vars_macrostrat = [\n",
        "    ('total_area_km2', 'Total Area'),\n",
        "    ('carbonate_area_km2', 'Carb Area'),\n",
        "    ('carbonate_percentage', 'Carb %')\n",
        "]\n",
        "\n",
        "env_vars_proxies = [\n",
        "    ('temperature', 'SST'),\n",
        "    ('sea_level', 'Sea Level'),\n",
        "    ('atmospheric_O2', 'Atm O2'),\n",
        "    ('atmospheric_CO2', 'Atm CO2'),\n",
        "    ('dissolved_O2', 'Dissolved O2'),\n",
        "    ('d13C', 'δ¹³C')\n",
        "]\n",
        "\n",
        "var_groups = [\n",
        "    ('Strom Props', strom_prop_vars),\n",
        "    ('Strom Occ', strom_occ_vars),\n",
        "    ('Strom Div', strom_div_vars),\n",
        "    ('Coral Div', coral_div_vars),\n",
        "    ('Coral Occ', coral_occ_vars),\n",
        "    ('Macrostrat', env_vars_macrostrat),\n",
        "    ('Proxies', env_vars_proxies),\n",
        "]\n",
        "\n",
        "STROM_GROUPS = {'Strom Props', 'Strom Occ', 'Strom Div'}\n",
        "CORAL_GROUPS = {'Coral Div', 'Coral Occ'}\n",
        "\n",
        "# -----------------------------------------------------------------------------#\n",
        "# 3. ANALYSIS FUNCTIONS\n",
        "# -----------------------------------------------------------------------------#\n",
        "def get_significance_stars(p):\n",
        "    if p is None or np.isnan(p):\n",
        "        return \"\"\n",
        "    if p < 0.001: return \"***\"\n",
        "    if p < 0.01:  return \"**\"\n",
        "    if p < 0.05:  return \"*\"\n",
        "    return \"\"\n",
        "\n",
        "def calc_stats_pairwise(x, y, min_n=5):\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    y = np.asarray(y, dtype=float)\n",
        "\n",
        "    mask = np.isfinite(x) & np.isfinite(y)\n",
        "    x = x[mask]\n",
        "    y = y[mask]\n",
        "    n = int(len(x))\n",
        "\n",
        "    out = dict(\n",
        "        n=n,\n",
        "        spearman_rho=np.nan, spearman_p=np.nan,\n",
        "        pearson_r=np.nan,  pearson_p=np.nan,\n",
        "        status=\"too_few\"\n",
        "    )\n",
        "\n",
        "    if n < min_n:\n",
        "        return out\n",
        "\n",
        "    x_const = (np.unique(x).size <= 1)\n",
        "    y_const = (np.unique(y).size <= 1)\n",
        "\n",
        "    if x_const and y_const:\n",
        "        out[\"status\"] = \"constant_both\"; return out\n",
        "    if x_const:\n",
        "        out[\"status\"] = \"constant_x\"; return out\n",
        "    if y_const:\n",
        "        out[\"status\"] = \"constant_y\"; return out\n",
        "\n",
        "    sr = stats.spearmanr(x, y)\n",
        "    pr = stats.pearsonr(x, y)\n",
        "\n",
        "    out.update(\n",
        "        spearman_rho=float(sr.correlation),\n",
        "        spearman_p=float(sr.pvalue),\n",
        "        pearson_r=float(pr.statistic),\n",
        "        pearson_p=float(pr.pvalue),\n",
        "        status=\"ok\"\n",
        "    )\n",
        "    return out\n",
        "\n",
        "def choose_view(group_name, df_all_in, df_strom_in, df_coral_in):\n",
        "    if group_name in STROM_GROUPS:\n",
        "        return df_strom_in\n",
        "    if group_name in CORAL_GROUPS:\n",
        "        return df_coral_in\n",
        "    return df_all_in\n",
        "\n",
        "def run_correlation_suite(scope_label, df_all_in, df_strom_in, df_coral_in, target_col, target_name, min_n=5):\n",
        "    if df_all_in is None or df_all_in.empty or target_col not in df_all_in.columns:\n",
        "        print(f\"[WARN] ({scope_label}) Missing target {target_col} or dataset empty; skipping {target_name}.\")\n",
        "        return []\n",
        "\n",
        "    print(\"\\n\" + \"-\"*90)\n",
        "    print(f\"{scope_label} | TARGET: {target_name.upper()}\")\n",
        "    print(\"-\"*90)\n",
        "    print(\"{:<12} {:<35} {:>8} {:>10} {:>8} {:>10} {:>5}\".format(\"Group\", \"Variable\", \"rho\", \"p(rho)\", \"r\", \"p(r)\", \"n\"))\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for group_name, group_vars in var_groups:\n",
        "        use_df = choose_view(group_name, df_all_in, df_strom_in, df_coral_in)\n",
        "        if use_df is None or use_df.empty or target_col not in use_df.columns:\n",
        "            continue\n",
        "\n",
        "        y = pd.to_numeric(use_df[target_col], errors='coerce').to_numpy(dtype=float)\n",
        "\n",
        "        for var, label in group_vars:\n",
        "            if var not in use_df.columns:\n",
        "                continue\n",
        "\n",
        "            x = pd.to_numeric(use_df[var], errors='coerce').to_numpy(dtype=float)\n",
        "\n",
        "            # OPTIONAL: treat coral zeros as missing (ONLY if zeros mean \"no data\")\n",
        "            if TREAT_CORAL_ZEROS_AS_MISSING and (group_name in CORAL_GROUPS):\n",
        "                x = x.copy()\n",
        "                x[x <= 0] = np.nan\n",
        "\n",
        "            s = calc_stats_pairwise(x, y, min_n=min_n)\n",
        "\n",
        "            if s[\"status\"] == \"ok\":\n",
        "                s_sig = get_significance_stars(s['spearman_p'])\n",
        "                p_sig = get_significance_stars(s['pearson_p'])\n",
        "                print(f\"{group_name[:11]:<12} {label:35s} {s['spearman_rho']:8.2f}{s_sig:3s} {s['spearman_p']:10.3g} \"\n",
        "                      f\"{s['pearson_r']:8.2f}{p_sig:3s} {s['pearson_p']:10.3g} {s['n']:5d}\")\n",
        "            else:\n",
        "                if VERBOSE_SKIPS and s[\"n\"] > 0:\n",
        "                    print(f\"{group_name[:11]:<12} {label:35s} {'':>8} {'':>10} {'':>8} {'':>10} {s['n']:5d}  [{s['status']}]\")\n",
        "\n",
        "            results.append({\n",
        "                'Scope': scope_label,\n",
        "                'Target': target_col,\n",
        "                'Predictor': var,\n",
        "                'Label': label,\n",
        "                'Group': group_name,\n",
        "                'Spearman_Rho': s['spearman_rho'],\n",
        "                'Spearman_P': s['spearman_p'],\n",
        "                'Pearson_R': s['pearson_r'],\n",
        "                'Pearson_P': s['pearson_p'],\n",
        "                'N': int(s['n']),\n",
        "                'Status': s['status']\n",
        "            })\n",
        "\n",
        "    return results\n",
        "\n",
        "# -----------------------------------------------------------------------------#\n",
        "# 4. RUN: Stage + 5-Myr\n",
        "# -----------------------------------------------------------------------------#\n",
        "all_results_stage = []\n",
        "for target_col, target_name in reef_targets:\n",
        "    all_results_stage.extend(\n",
        "        run_correlation_suite(\"Stage\", df_all, df_strom, df_coral, target_col, target_name, min_n=MIN_N)\n",
        "    )\n",
        "\n",
        "all_results_5myr = []\n",
        "for target_col, target_name in reef_targets:\n",
        "    all_results_5myr.extend(\n",
        "        run_correlation_suite(\"5-Myr\", df_5myr_all, df_5myr_strom, df_5myr_coral, target_col, target_name, min_n=MIN_N)\n",
        "    )\n",
        "\n",
        "stage_results_df = pd.DataFrame(all_results_stage)\n",
        "myr_results_df = pd.DataFrame(all_results_5myr)\n",
        "\n",
        "# Keep only successful correlations for main outputs\n",
        "stage_ok = stage_results_df[stage_results_df['Status'] == 'ok'].copy() if not stage_results_df.empty else stage_results_df\n",
        "myr_ok   = myr_results_df[myr_results_df['Status'] == 'ok'].copy() if not myr_results_df.empty else myr_results_df\n",
        "\n",
        "# -----------------------------------------------------------------------------#\n",
        "# 5. SAVE + DISPLAY\n",
        "# -----------------------------------------------------------------------------#\n",
        "if 'OUTPUT_DIR' in globals():\n",
        "    if not stage_ok.empty:\n",
        "        stage_ok.to_csv(f\"{OUTPUT_DIR}/results_correlations_stage.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "        print(f\"\\nSaved: {OUTPUT_DIR}/results_correlations_stage.csv\")\n",
        "    else:\n",
        "        print(\"\\n[WARN] Stage correlations empty (nothing met criteria).\")\n",
        "\n",
        "    if not myr_ok.empty:\n",
        "        myr_ok.to_csv(f\"{OUTPUT_DIR}/results_correlations_5myr.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "        print(f\"Saved: {OUTPUT_DIR}/results_correlations_5myr.csv\")\n",
        "    else:\n",
        "        print(\"[WARN] 5-Myr correlations empty (nothing met criteria).\")\n",
        "\n",
        "    # Full tables with skip reasons\n",
        "    if not stage_results_df.empty:\n",
        "        stage_results_df.to_csv(f\"{OUTPUT_DIR}/results_correlations_stage_FULL_with_status.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "        print(f\"Saved: {OUTPUT_DIR}/results_correlations_stage_FULL_with_status.csv\")\n",
        "    if not myr_results_df.empty:\n",
        "        myr_results_df.to_csv(f\"{OUTPUT_DIR}/results_correlations_5myr_FULL_with_status.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "        print(f\"Saved: {OUTPUT_DIR}/results_correlations_5myr_FULL_with_status.csv\")\n",
        "\n",
        "display(stage_ok if not stage_ok.empty else pd.DataFrame())\n",
        "display(myr_ok if not myr_ok.empty else pd.DataFrame())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4oRd7FSq_Rab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "483552f1-df81-443f-e5b6-25acc6d8f8dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "PERFORMING ADVANCED STATISTICAL ANALYSES (CENTRALIZED) — PART A (REWRITE v3 + LOWESS)\n",
            "Iterations: Bootstrap=10000, Permutation=10000\n",
            "LOWESS: True (frac=0.4, it=0)\n",
            "Output dir: output\n",
            "================================================================================\n",
            "Loaded: MASTER_dataset_stage.csv (22 rows)\n",
            "[INFO] Predictors included: ['derived_strom_prop', 'basal_strom_prop', 'derived_strom_occ', 'basal_strom_occ', 'derived_strom_div', 'basal_strom_div', 'rugose_occ', 'tabulate_occ', 'rugose_div', 'tabulate_div', 'carbonate_area_km2', 'temperature', 'dissolved_O2', 'd13C', 'atm_O2', 'atm_CO2', 'total_area_km2', 'carbonate_percentage', 'sea_level', 'Labechiida_prop', 'Clathrodictyida_prop', 'Actinostromatida_prop', 'Stromatoporida_prop', 'Stromatoporellida_prop', 'Syringostromatida_prop', 'Amphiporida_prop']\n",
            "\n",
            "[LOWESS] Computing LOWESS smooths vs time (midpoint_ma)...\n",
            "  LOWESS predictors: ['basal_strom_prop', 'derived_strom_prop', 'basal_strom_occ', 'derived_strom_occ', 'basal_strom_div', 'derived_strom_div']\n",
            "  -> Saved results_lowess_predictors_vs_time_long.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           Predictor  midpoint_ma  lowess_y  N_used  frac  it\n",
              "0   basal_strom_prop       365.55  0.279930      21   0.4   0\n",
              "1   basal_strom_prop       377.45  0.202240      21   0.4   0\n",
              "2   basal_strom_prop       385.20  0.154829      21   0.4   0\n",
              "3   basal_strom_prop       390.50  0.122368      21   0.4   0\n",
              "4   basal_strom_prop       400.45  0.113658      21   0.4   0\n",
              "5   basal_strom_prop       409.20  0.136065      21   0.4   0\n",
              "6   basal_strom_prop       415.00  0.160710      21   0.4   0\n",
              "7   basal_strom_prop       421.10  0.321537      21   0.4   0\n",
              "8   basal_strom_prop       424.30  0.416435      21   0.4   0\n",
              "9   basal_strom_prop       426.50  0.482884      21   0.4   0\n",
              "10  basal_strom_prop       428.95  0.562331      21   0.4   0\n",
              "11  basal_strom_prop       431.95  0.663422      21   0.4   0\n",
              "12  basal_strom_prop       435.95  0.790010      21   0.4   0\n",
              "13  basal_strom_prop       439.65  0.888043      21   0.4   0\n",
              "14  basal_strom_prop       442.30  0.945029      21   0.4   0\n",
              "15  basal_strom_prop       444.50  0.961616      21   0.4   0\n",
              "16  basal_strom_prop       449.10  0.980202      21   0.4   0\n",
              "17  basal_strom_prop       455.70  0.989315      21   0.4   0\n",
              "18  basal_strom_prop       462.85  0.993887      21   0.4   0\n",
              "19  basal_strom_prop       473.85  0.998970      21   0.4   0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-347273a9-838e-4d4e-bcef-ab60c60629d3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predictor</th>\n",
              "      <th>midpoint_ma</th>\n",
              "      <th>lowess_y</th>\n",
              "      <th>N_used</th>\n",
              "      <th>frac</th>\n",
              "      <th>it</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>365.55</td>\n",
              "      <td>0.279930</td>\n",
              "      <td>21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>377.45</td>\n",
              "      <td>0.202240</td>\n",
              "      <td>21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>385.20</td>\n",
              "      <td>0.154829</td>\n",
              "      <td>21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>390.50</td>\n",
              "      <td>0.122368</td>\n",
              "      <td>21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>400.45</td>\n",
              "      <td>0.113658</td>\n",
              "      <td>21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>409.20</td>\n",
              "      <td>0.136065</td>\n",
              "      <td>21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>415.00</td>\n",
              "      <td>0.160710</td>\n",
              "      <td>21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>421.10</td>\n",
              "      <td>0.321537</td>\n",
              "      <td>21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>424.30</td>\n",
              "      <td>0.416435</td>\n",
              "      <td>21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>426.50</td>\n",
              "      <td>0.482884</td>\n",
              "      <td>21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>428.95</td>\n",
              "      <td>0.562331</td>\n",
              "      <td>21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>431.95</td>\n",
              "      <td>0.663422</td>\n",
              "      <td>21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>435.95</td>\n",
              "      <td>0.790010</td>\n",
              "      <td>21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>439.65</td>\n",
              "      <td>0.888043</td>\n",
              "      <td>21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>442.30</td>\n",
              "      <td>0.945029</td>\n",
              "      <td>21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>444.50</td>\n",
              "      <td>0.961616</td>\n",
              "      <td>21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>449.10</td>\n",
              "      <td>0.980202</td>\n",
              "      <td>21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>455.70</td>\n",
              "      <td>0.989315</td>\n",
              "      <td>21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>462.85</td>\n",
              "      <td>0.993887</td>\n",
              "      <td>21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>473.85</td>\n",
              "      <td>0.998970</td>\n",
              "      <td>21</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-347273a9-838e-4d4e-bcef-ab60c60629d3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-347273a9-838e-4d4e-bcef-ab60c60629d3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-347273a9-838e-4d4e-bcef-ab60c60629d3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\n\\u2713 CELL 13 PART A COMPLETE (v3 + LOWESS; strom+coral summary occ/div allow zeros once present)\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Predictor\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"basal_strom_prop\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"midpoint_ma\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28.964772047037457,\n        \"min\": 365.55,\n        \"max\": 473.85,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          365.55\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lowess_y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3558860815593483,\n        \"min\": 0.11365781689419005,\n        \"max\": 0.9989699439302782,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.27993019337452724\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N_used\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 21,\n        \"max\": 21,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frac\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.695323946259567e-17,\n        \"min\": 0.4,\n        \"max\": 0.4,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"it\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[INFO] Predictors used for correlation/bootstrap/permutation/LOO/detrend/partial/univariate: ['derived_strom_prop', 'derived_strom_occ', 'basal_strom_occ', 'derived_strom_div', 'basal_strom_div', 'rugose_occ', 'tabulate_occ', 'rugose_div', 'tabulate_div', 'carbonate_area_km2', 'temperature', 'dissolved_O2', 'd13C', 'atm_O2', 'atm_CO2', 'total_area_km2', 'carbonate_percentage', 'sea_level', 'Labechiida_prop', 'Clathrodictyida_prop', 'Actinostromatida_prop', 'Stromatoporida_prop', 'Stromatoporellida_prop', 'Syringostromatida_prop', 'Amphiporida_prop']\n",
            "\n",
            "0. Computing original Spearman correlations...\n",
            "  -> Saved results_spearman_original_all_predictors.csv\n",
            "[INFO] Spearman status counts: {'too_few': 0, 'prop_low_signal': 0, 'ok': 25}\n",
            "\n",
            "1. Running Bootstrap (10000 iter)...\n",
            "  -> Saved results_bootstrap.csv\n",
            "  -> Saved results_bootstrap_dist_all_predictors_long.csv\n",
            "2. Running Permutation (10000 iter)...\n",
            "  -> Saved results_permutation.csv\n",
            "  -> Saved results_permutation_dist_all_predictors_long.csv\n",
            "3. Running Leave-One-Out...\n",
            "  -> Saved results_loo_detailed_all_predictors_long.csv\n",
            "  -> Saved results_loo_summary.csv\n",
            "4. Running Detrending (status logged)...\n",
            "  -> Saved results_detrending_improved.csv\n",
            "\n",
            "5. Running Partial Correlations (predictor-type aware)...\n",
            "  -> Saved results_partial_correlations.csv\n",
            "\n",
            "[DISPLAY] Partial correlations (OK rows):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "             Dataset          Target               Predictor  \\\n",
              "0   Stage-Level Data  thickness_mean      derived_strom_prop   \n",
              "24  Stage-Level Data  thickness_mean        Amphiporida_prop   \n",
              "1   Stage-Level Data  thickness_mean       derived_strom_occ   \n",
              "22  Stage-Level Data  thickness_mean  Stromatoporellida_prop   \n",
              "2   Stage-Level Data  thickness_mean         basal_strom_occ   \n",
              "18  Stage-Level Data  thickness_mean         Labechiida_prop   \n",
              "23  Stage-Level Data  thickness_mean  Syringostromatida_prop   \n",
              "20  Stage-Level Data  thickness_mean   Actinostromatida_prop   \n",
              "3   Stage-Level Data  thickness_mean       derived_strom_div   \n",
              "4   Stage-Level Data  thickness_mean         basal_strom_div   \n",
              "19  Stage-Level Data  thickness_mean    Clathrodictyida_prop   \n",
              "21  Stage-Level Data  thickness_mean     Stromatoporida_prop   \n",
              "10  Stage-Level Data  thickness_mean             temperature   \n",
              "11  Stage-Level Data  thickness_mean            dissolved_O2   \n",
              "5   Stage-Level Data  thickness_mean              rugose_occ   \n",
              "7   Stage-Level Data  thickness_mean              rugose_div   \n",
              "13  Stage-Level Data  thickness_mean                  atm_O2   \n",
              "12  Stage-Level Data  thickness_mean                    d13C   \n",
              "17  Stage-Level Data  thickness_mean               sea_level   \n",
              "14  Stage-Level Data  thickness_mean                 atm_CO2   \n",
              "16  Stage-Level Data  thickness_mean    carbonate_percentage   \n",
              "6   Stage-Level Data  thickness_mean            tabulate_occ   \n",
              "9   Stage-Level Data  thickness_mean      carbonate_area_km2   \n",
              "8   Stage-Level Data  thickness_mean            tabulate_div   \n",
              "15  Stage-Level Data  thickness_mean          total_area_km2   \n",
              "\n",
              "                          Test_Type  \\\n",
              "0     Biotic/Taxon (Env Controlled)   \n",
              "24    Biotic/Taxon (Env Controlled)   \n",
              "1     Biotic/Taxon (Env Controlled)   \n",
              "22    Biotic/Taxon (Env Controlled)   \n",
              "2     Biotic/Taxon (Env Controlled)   \n",
              "18    Biotic/Taxon (Env Controlled)   \n",
              "23    Biotic/Taxon (Env Controlled)   \n",
              "20    Biotic/Taxon (Env Controlled)   \n",
              "3     Biotic/Taxon (Env Controlled)   \n",
              "4     Biotic/Taxon (Env Controlled)   \n",
              "19    Biotic/Taxon (Env Controlled)   \n",
              "21    Biotic/Taxon (Env Controlled)   \n",
              "10  Environment (Biotic Controlled)   \n",
              "11  Environment (Biotic Controlled)   \n",
              "5     Biotic/Taxon (Env Controlled)   \n",
              "7     Biotic/Taxon (Env Controlled)   \n",
              "13  Environment (Biotic Controlled)   \n",
              "12  Environment (Biotic Controlled)   \n",
              "17  Environment (Biotic Controlled)   \n",
              "14  Environment (Biotic Controlled)   \n",
              "16  Environment (Biotic Controlled)   \n",
              "6     Biotic/Taxon (Env Controlled)   \n",
              "9   Environment (Biotic Controlled)   \n",
              "8     Biotic/Taxon (Env Controlled)   \n",
              "15  Environment (Biotic Controlled)   \n",
              "\n",
              "                                       Controls   N  spearman_partial  \\\n",
              "0   carbonate_area_km2,temperature,dissolved_O2  21          0.816883   \n",
              "24  carbonate_area_km2,temperature,dissolved_O2  21          0.723377   \n",
              "1   carbonate_area_km2,temperature,dissolved_O2  21          0.685714   \n",
              "22  carbonate_area_km2,temperature,dissolved_O2  21          0.637662   \n",
              "2   carbonate_area_km2,temperature,dissolved_O2  21         -0.631169   \n",
              "18  carbonate_area_km2,temperature,dissolved_O2  21         -0.628571   \n",
              "23  carbonate_area_km2,temperature,dissolved_O2  21          0.618182   \n",
              "20  carbonate_area_km2,temperature,dissolved_O2  21          0.563636   \n",
              "3   carbonate_area_km2,temperature,dissolved_O2  21          0.487013   \n",
              "4   carbonate_area_km2,temperature,dissolved_O2  21         -0.481818   \n",
              "19  carbonate_area_km2,temperature,dissolved_O2  21         -0.475325   \n",
              "21  carbonate_area_km2,temperature,dissolved_O2  21          0.441558   \n",
              "10                           derived_strom_prop  22         -0.360813   \n",
              "11                           derived_strom_prop  22          0.294184   \n",
              "5   carbonate_area_km2,temperature,dissolved_O2  21          0.276623   \n",
              "7   carbonate_area_km2,temperature,dissolved_O2  21          0.268831   \n",
              "13                           derived_strom_prop  22          0.210615   \n",
              "12                           derived_strom_prop  22         -0.159797   \n",
              "17                           derived_strom_prop  22          0.104461   \n",
              "14                           derived_strom_prop  22          0.088650   \n",
              "16                           derived_strom_prop  22          0.084133   \n",
              "6   carbonate_area_km2,temperature,dissolved_O2  21          0.084416   \n",
              "9                            derived_strom_prop  22          0.062676   \n",
              "8   carbonate_area_km2,temperature,dissolved_O2  21          0.054545   \n",
              "15                           derived_strom_prop  22          0.026539   \n",
              "\n",
              "    spearman_p_partial Status  \n",
              "0             0.000006     OK  \n",
              "24            0.000211     OK  \n",
              "1             0.000601     OK  \n",
              "22            0.001873     OK  \n",
              "2             0.002153     OK  \n",
              "18            0.002274     OK  \n",
              "23            0.002819     OK  \n",
              "20            0.007793     OK  \n",
              "3             0.025151     OK  \n",
              "4             0.026987     OK  \n",
              "19            0.029430     OK  \n",
              "21            0.045078     OK  \n",
              "10            0.099006     OK  \n",
              "11            0.183870     OK  \n",
              "5             0.224791     OK  \n",
              "7             0.238656     OK  \n",
              "13            0.346796     OK  \n",
              "12            0.477489     OK  \n",
              "17            0.643627     OK  \n",
              "14            0.694829     OK  \n",
              "16            0.709709     OK  \n",
              "6             0.716005     OK  \n",
              "9             0.781710     OK  \n",
              "8             0.814343     OK  \n",
              "15            0.906677     OK  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd1224fc-5720-4a34-9f3e-8d7415c64d06\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Target</th>\n",
              "      <th>Predictor</th>\n",
              "      <th>Test_Type</th>\n",
              "      <th>Controls</th>\n",
              "      <th>N</th>\n",
              "      <th>spearman_partial</th>\n",
              "      <th>spearman_p_partial</th>\n",
              "      <th>Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.816883</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>Amphiporida_prop</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.723377</td>\n",
              "      <td>0.000211</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>derived_strom_occ</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.685714</td>\n",
              "      <td>0.000601</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>Stromatoporellida_prop</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.637662</td>\n",
              "      <td>0.001873</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>basal_strom_occ</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>-0.631169</td>\n",
              "      <td>0.002153</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>Labechiida_prop</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>-0.628571</td>\n",
              "      <td>0.002274</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>Syringostromatida_prop</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.618182</td>\n",
              "      <td>0.002819</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>Actinostromatida_prop</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.563636</td>\n",
              "      <td>0.007793</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>derived_strom_div</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.487013</td>\n",
              "      <td>0.025151</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>basal_strom_div</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>-0.481818</td>\n",
              "      <td>0.026987</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>Clathrodictyida_prop</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>-0.475325</td>\n",
              "      <td>0.029430</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>Stromatoporida_prop</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.441558</td>\n",
              "      <td>0.045078</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>temperature</td>\n",
              "      <td>Environment (Biotic Controlled)</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>22</td>\n",
              "      <td>-0.360813</td>\n",
              "      <td>0.099006</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>dissolved_O2</td>\n",
              "      <td>Environment (Biotic Controlled)</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>22</td>\n",
              "      <td>0.294184</td>\n",
              "      <td>0.183870</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>rugose_occ</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.276623</td>\n",
              "      <td>0.224791</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>rugose_div</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.268831</td>\n",
              "      <td>0.238656</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>atm_O2</td>\n",
              "      <td>Environment (Biotic Controlled)</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>22</td>\n",
              "      <td>0.210615</td>\n",
              "      <td>0.346796</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>d13C</td>\n",
              "      <td>Environment (Biotic Controlled)</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>22</td>\n",
              "      <td>-0.159797</td>\n",
              "      <td>0.477489</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>sea_level</td>\n",
              "      <td>Environment (Biotic Controlled)</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>22</td>\n",
              "      <td>0.104461</td>\n",
              "      <td>0.643627</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>atm_CO2</td>\n",
              "      <td>Environment (Biotic Controlled)</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>22</td>\n",
              "      <td>0.088650</td>\n",
              "      <td>0.694829</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>carbonate_percentage</td>\n",
              "      <td>Environment (Biotic Controlled)</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>22</td>\n",
              "      <td>0.084133</td>\n",
              "      <td>0.709709</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>tabulate_occ</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.084416</td>\n",
              "      <td>0.716005</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>carbonate_area_km2</td>\n",
              "      <td>Environment (Biotic Controlled)</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>22</td>\n",
              "      <td>0.062676</td>\n",
              "      <td>0.781710</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>tabulate_div</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.054545</td>\n",
              "      <td>0.814343</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>total_area_km2</td>\n",
              "      <td>Environment (Biotic Controlled)</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>22</td>\n",
              "      <td>0.026539</td>\n",
              "      <td>0.906677</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd1224fc-5720-4a34-9f3e-8d7415c64d06')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fd1224fc-5720-4a34-9f3e-8d7415c64d06 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fd1224fc-5720-4a34-9f3e-8d7415c64d06');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\n\\u2713 CELL 13 PART A COMPLETE (v3 + LOWESS; strom+coral summary occ/div allow zeros once present)\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"Dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Stage-Level Data\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"thickness_mean\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predictor\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"derived_strom_div\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test_Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Environment (Biotic Controlled)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Controls\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"derived_strom_prop\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 21,\n        \"max\": 22,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"spearman_partial\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4258179525588832,\n        \"min\": -0.6311688311688312,\n        \"max\": 0.8168831168831169,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          0.487012987012987\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"spearman_p_partial\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3268227984294132,\n        \"min\": 6.228850108065048e-06,\n        \"max\": 0.9066765277008431,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          0.025150758255917977\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"OK\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[DISPLAY] Partial correlations (all rows incl. skips/fails):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "             Dataset          Target               Predictor  \\\n",
              "0   Stage-Level Data  thickness_mean      derived_strom_prop   \n",
              "24  Stage-Level Data  thickness_mean        Amphiporida_prop   \n",
              "1   Stage-Level Data  thickness_mean       derived_strom_occ   \n",
              "22  Stage-Level Data  thickness_mean  Stromatoporellida_prop   \n",
              "2   Stage-Level Data  thickness_mean         basal_strom_occ   \n",
              "18  Stage-Level Data  thickness_mean         Labechiida_prop   \n",
              "23  Stage-Level Data  thickness_mean  Syringostromatida_prop   \n",
              "20  Stage-Level Data  thickness_mean   Actinostromatida_prop   \n",
              "3   Stage-Level Data  thickness_mean       derived_strom_div   \n",
              "4   Stage-Level Data  thickness_mean         basal_strom_div   \n",
              "19  Stage-Level Data  thickness_mean    Clathrodictyida_prop   \n",
              "21  Stage-Level Data  thickness_mean     Stromatoporida_prop   \n",
              "10  Stage-Level Data  thickness_mean             temperature   \n",
              "11  Stage-Level Data  thickness_mean            dissolved_O2   \n",
              "5   Stage-Level Data  thickness_mean              rugose_occ   \n",
              "7   Stage-Level Data  thickness_mean              rugose_div   \n",
              "13  Stage-Level Data  thickness_mean                  atm_O2   \n",
              "12  Stage-Level Data  thickness_mean                    d13C   \n",
              "17  Stage-Level Data  thickness_mean               sea_level   \n",
              "14  Stage-Level Data  thickness_mean                 atm_CO2   \n",
              "16  Stage-Level Data  thickness_mean    carbonate_percentage   \n",
              "6   Stage-Level Data  thickness_mean            tabulate_occ   \n",
              "9   Stage-Level Data  thickness_mean      carbonate_area_km2   \n",
              "8   Stage-Level Data  thickness_mean            tabulate_div   \n",
              "15  Stage-Level Data  thickness_mean          total_area_km2   \n",
              "\n",
              "                          Test_Type  \\\n",
              "0     Biotic/Taxon (Env Controlled)   \n",
              "24    Biotic/Taxon (Env Controlled)   \n",
              "1     Biotic/Taxon (Env Controlled)   \n",
              "22    Biotic/Taxon (Env Controlled)   \n",
              "2     Biotic/Taxon (Env Controlled)   \n",
              "18    Biotic/Taxon (Env Controlled)   \n",
              "23    Biotic/Taxon (Env Controlled)   \n",
              "20    Biotic/Taxon (Env Controlled)   \n",
              "3     Biotic/Taxon (Env Controlled)   \n",
              "4     Biotic/Taxon (Env Controlled)   \n",
              "19    Biotic/Taxon (Env Controlled)   \n",
              "21    Biotic/Taxon (Env Controlled)   \n",
              "10  Environment (Biotic Controlled)   \n",
              "11  Environment (Biotic Controlled)   \n",
              "5     Biotic/Taxon (Env Controlled)   \n",
              "7     Biotic/Taxon (Env Controlled)   \n",
              "13  Environment (Biotic Controlled)   \n",
              "12  Environment (Biotic Controlled)   \n",
              "17  Environment (Biotic Controlled)   \n",
              "14  Environment (Biotic Controlled)   \n",
              "16  Environment (Biotic Controlled)   \n",
              "6     Biotic/Taxon (Env Controlled)   \n",
              "9   Environment (Biotic Controlled)   \n",
              "8     Biotic/Taxon (Env Controlled)   \n",
              "15  Environment (Biotic Controlled)   \n",
              "\n",
              "                                       Controls   N  spearman_partial  \\\n",
              "0   carbonate_area_km2,temperature,dissolved_O2  21          0.816883   \n",
              "24  carbonate_area_km2,temperature,dissolved_O2  21          0.723377   \n",
              "1   carbonate_area_km2,temperature,dissolved_O2  21          0.685714   \n",
              "22  carbonate_area_km2,temperature,dissolved_O2  21          0.637662   \n",
              "2   carbonate_area_km2,temperature,dissolved_O2  21         -0.631169   \n",
              "18  carbonate_area_km2,temperature,dissolved_O2  21         -0.628571   \n",
              "23  carbonate_area_km2,temperature,dissolved_O2  21          0.618182   \n",
              "20  carbonate_area_km2,temperature,dissolved_O2  21          0.563636   \n",
              "3   carbonate_area_km2,temperature,dissolved_O2  21          0.487013   \n",
              "4   carbonate_area_km2,temperature,dissolved_O2  21         -0.481818   \n",
              "19  carbonate_area_km2,temperature,dissolved_O2  21         -0.475325   \n",
              "21  carbonate_area_km2,temperature,dissolved_O2  21          0.441558   \n",
              "10                           derived_strom_prop  22         -0.360813   \n",
              "11                           derived_strom_prop  22          0.294184   \n",
              "5   carbonate_area_km2,temperature,dissolved_O2  21          0.276623   \n",
              "7   carbonate_area_km2,temperature,dissolved_O2  21          0.268831   \n",
              "13                           derived_strom_prop  22          0.210615   \n",
              "12                           derived_strom_prop  22         -0.159797   \n",
              "17                           derived_strom_prop  22          0.104461   \n",
              "14                           derived_strom_prop  22          0.088650   \n",
              "16                           derived_strom_prop  22          0.084133   \n",
              "6   carbonate_area_km2,temperature,dissolved_O2  21          0.084416   \n",
              "9                            derived_strom_prop  22          0.062676   \n",
              "8   carbonate_area_km2,temperature,dissolved_O2  21          0.054545   \n",
              "15                           derived_strom_prop  22          0.026539   \n",
              "\n",
              "    spearman_p_partial Status  \n",
              "0             0.000006     OK  \n",
              "24            0.000211     OK  \n",
              "1             0.000601     OK  \n",
              "22            0.001873     OK  \n",
              "2             0.002153     OK  \n",
              "18            0.002274     OK  \n",
              "23            0.002819     OK  \n",
              "20            0.007793     OK  \n",
              "3             0.025151     OK  \n",
              "4             0.026987     OK  \n",
              "19            0.029430     OK  \n",
              "21            0.045078     OK  \n",
              "10            0.099006     OK  \n",
              "11            0.183870     OK  \n",
              "5             0.224791     OK  \n",
              "7             0.238656     OK  \n",
              "13            0.346796     OK  \n",
              "12            0.477489     OK  \n",
              "17            0.643627     OK  \n",
              "14            0.694829     OK  \n",
              "16            0.709709     OK  \n",
              "6             0.716005     OK  \n",
              "9             0.781710     OK  \n",
              "8             0.814343     OK  \n",
              "15            0.906677     OK  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e6f9726-4f35-4b22-9cec-f24d65081e44\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Target</th>\n",
              "      <th>Predictor</th>\n",
              "      <th>Test_Type</th>\n",
              "      <th>Controls</th>\n",
              "      <th>N</th>\n",
              "      <th>spearman_partial</th>\n",
              "      <th>spearman_p_partial</th>\n",
              "      <th>Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.816883</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>Amphiporida_prop</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.723377</td>\n",
              "      <td>0.000211</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>derived_strom_occ</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.685714</td>\n",
              "      <td>0.000601</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>Stromatoporellida_prop</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.637662</td>\n",
              "      <td>0.001873</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>basal_strom_occ</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>-0.631169</td>\n",
              "      <td>0.002153</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>Labechiida_prop</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>-0.628571</td>\n",
              "      <td>0.002274</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>Syringostromatida_prop</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.618182</td>\n",
              "      <td>0.002819</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>Actinostromatida_prop</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.563636</td>\n",
              "      <td>0.007793</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>derived_strom_div</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.487013</td>\n",
              "      <td>0.025151</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>basal_strom_div</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>-0.481818</td>\n",
              "      <td>0.026987</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>Clathrodictyida_prop</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>-0.475325</td>\n",
              "      <td>0.029430</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>Stromatoporida_prop</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.441558</td>\n",
              "      <td>0.045078</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>temperature</td>\n",
              "      <td>Environment (Biotic Controlled)</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>22</td>\n",
              "      <td>-0.360813</td>\n",
              "      <td>0.099006</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>dissolved_O2</td>\n",
              "      <td>Environment (Biotic Controlled)</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>22</td>\n",
              "      <td>0.294184</td>\n",
              "      <td>0.183870</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>rugose_occ</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.276623</td>\n",
              "      <td>0.224791</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>rugose_div</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.268831</td>\n",
              "      <td>0.238656</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>atm_O2</td>\n",
              "      <td>Environment (Biotic Controlled)</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>22</td>\n",
              "      <td>0.210615</td>\n",
              "      <td>0.346796</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>d13C</td>\n",
              "      <td>Environment (Biotic Controlled)</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>22</td>\n",
              "      <td>-0.159797</td>\n",
              "      <td>0.477489</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>sea_level</td>\n",
              "      <td>Environment (Biotic Controlled)</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>22</td>\n",
              "      <td>0.104461</td>\n",
              "      <td>0.643627</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>atm_CO2</td>\n",
              "      <td>Environment (Biotic Controlled)</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>22</td>\n",
              "      <td>0.088650</td>\n",
              "      <td>0.694829</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>carbonate_percentage</td>\n",
              "      <td>Environment (Biotic Controlled)</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>22</td>\n",
              "      <td>0.084133</td>\n",
              "      <td>0.709709</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>tabulate_occ</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.084416</td>\n",
              "      <td>0.716005</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>carbonate_area_km2</td>\n",
              "      <td>Environment (Biotic Controlled)</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>22</td>\n",
              "      <td>0.062676</td>\n",
              "      <td>0.781710</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>tabulate_div</td>\n",
              "      <td>Biotic/Taxon (Env Controlled)</td>\n",
              "      <td>carbonate_area_km2,temperature,dissolved_O2</td>\n",
              "      <td>21</td>\n",
              "      <td>0.054545</td>\n",
              "      <td>0.814343</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Stage-Level Data</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>total_area_km2</td>\n",
              "      <td>Environment (Biotic Controlled)</td>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>22</td>\n",
              "      <td>0.026539</td>\n",
              "      <td>0.906677</td>\n",
              "      <td>OK</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e6f9726-4f35-4b22-9cec-f24d65081e44')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8e6f9726-4f35-4b22-9cec-f24d65081e44 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8e6f9726-4f35-4b22-9cec-f24d65081e44');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_ab806c39-3311-420d-b651-109a8a38fe90\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('part_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ab806c39-3311-420d-b651-109a8a38fe90 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('part_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "part_df",
              "summary": "{\n  \"name\": \"part_df\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"Dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Stage-Level Data\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"thickness_mean\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predictor\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"derived_strom_div\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test_Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Environment (Biotic Controlled)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Controls\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"derived_strom_prop\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 21,\n        \"max\": 22,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"spearman_partial\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4258179525588832,\n        \"min\": -0.6311688311688312,\n        \"max\": 0.8168831168831169,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          0.487012987012987\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"spearman_p_partial\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3268227984294132,\n        \"min\": 6.228850108065048e-06,\n        \"max\": 0.9066765277008431,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          0.025150758255917977\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"OK\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6. Running Variance Partitioning (groups; strict subset)...\n",
            "  -> Saved results_variance_partition_improved.csv\n",
            "6b. Running Univariate adj-R2 (robust)...\n",
            "  -> Saved results_adjR2_univariate_all_predictors.csv\n",
            "\n",
            "✓ CELL 13 PART A COMPLETE (v3 + LOWESS; strom+coral summary occ/div allow zeros once present).\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# @title CELL 13: PERFORM ADVANCED STATISTICAL ANALYSES (Centralized) — PART A (REWRITE v3 + LOWESS)\n",
        "#   Updated to enforce the SAME missingness/presence logic for stromatoporoids and corals:\n",
        "#   - KEEP NaNs in MASTER; each analysis uses pairwise complete-case only for its variables\n",
        "#   - Apply strom_total_occ > 0 for ALL strom/coral predictors (your existing rule)\n",
        "#   - Apply coral_total_occ > 0 (or rugose+tabulate fallback) for coral predictors\n",
        "#   - occ/div rule:\n",
        "#       * For group-summary occ/div (derived/basal + rugose/tabulate), DO NOT require pred>0\n",
        "#         (zeros are allowed once the group is present)\n",
        "#       * For other occ/div (taxon-specific occ/div), require pred>0\n",
        "#   - prop rule: allow zeros but require enough non-zero overall (signal gate)\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "import re\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# -------------------------\n",
        "# Config\n",
        "# -------------------------\n",
        "DATA_DIR = Path(\"./output\")\n",
        "\n",
        "if \"OUTPUT_DIR\" in globals():\n",
        "    try:\n",
        "        OUTPUT_DIR = Path(OUTPUT_DIR)\n",
        "    except Exception:\n",
        "        OUTPUT_DIR = DATA_DIR\n",
        "else:\n",
        "    OUTPUT_DIR = DATA_DIR\n",
        "\n",
        "N_BOOT = 10000\n",
        "N_PERM = 10000\n",
        "RNG_SEED = 0\n",
        "\n",
        "MIN_N = 5\n",
        "MIN_POSITIVE = 5          # only used for presence-only occ/div variables\n",
        "MIN_NONZERO_PROP = 5\n",
        "VERBOSE_SKIP_COUNTS = True\n",
        "\n",
        "# LOWESS config\n",
        "DO_LOWESS = True\n",
        "LOWESS_FRAC = 0.4\n",
        "LOWESS_IT = 0\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"PERFORMING ADVANCED STATISTICAL ANALYSES (CENTRALIZED) — PART A (REWRITE v3 + LOWESS)\")\n",
        "print(f\"Iterations: Bootstrap={N_BOOT}, Permutation={N_PERM}\")\n",
        "print(f\"LOWESS: {DO_LOWESS} (frac={LOWESS_FRAC}, it={LOWESS_IT})\")\n",
        "print(f\"Output dir: {OUTPUT_DIR}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# -------------------------\n",
        "# Load dataset\n",
        "# -------------------------\n",
        "master_path = DATA_DIR / \"MASTER_dataset_stage.csv\"\n",
        "df = pd.read_csv(master_path, encoding=\"utf-8-sig\")\n",
        "print(f\"Loaded: {master_path.name} ({len(df)} rows)\")\n",
        "\n",
        "if df.empty:\n",
        "    raise SystemExit(\"ERROR: Dataset is empty.\")\n",
        "\n",
        "target = \"thickness_mean\"\n",
        "if target not in df.columns:\n",
        "    raise SystemExit(f\"ERROR: target column '{target}' not found.\")\n",
        "\n",
        "# numeric core\n",
        "for c in [\"midpoint_ma\", target]:\n",
        "    if c in df.columns:\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "# -------------------------\n",
        "# Standardize atmospheric columns -> atm_O2 / atm_CO2\n",
        "# -------------------------\n",
        "def _find_col(frame, candidates, regex_pat=None):\n",
        "    for c in candidates:\n",
        "        if c in frame.columns:\n",
        "            return c\n",
        "    if regex_pat:\n",
        "        hits = [c for c in frame.columns if re.search(regex_pat, c, flags=re.IGNORECASE)]\n",
        "        return hits[0] if hits else None\n",
        "    return None\n",
        "\n",
        "if \"atm_O2\" not in df.columns:\n",
        "    o2_src = _find_col(\n",
        "        df,\n",
        "        [\"atmospheric_O2\",\"atmospheric_o2\",\"atm_o2\",\"pO2\",\"PO2\",\"oxygen\",\"O2_atm\",\"oxygen_atm\"],\n",
        "        r\"(atm|atmos).*o2|po2\"\n",
        "    )\n",
        "    if o2_src is not None:\n",
        "        df[\"atm_O2\"] = pd.to_numeric(df[o2_src], errors=\"coerce\")\n",
        "        print(f\"[INFO] atm_O2 <- {o2_src}\")\n",
        "\n",
        "if \"atm_CO2\" not in df.columns:\n",
        "    co2_src = _find_col(\n",
        "        df,\n",
        "        [\"atmospheric_CO2\",\"atmospheric_co2\",\"atm_co2\",\"pCO2\",\"PCO2\",\"co2\",\"CO2_atm\",\"co2_atm\"],\n",
        "        r\"(atm|atmos).*co2|pco2\"\n",
        "    )\n",
        "    if co2_src is not None:\n",
        "        df[\"atm_CO2\"] = pd.to_numeric(df[co2_src], errors=\"coerce\")\n",
        "        print(f\"[INFO] atm_CO2 <- {co2_src}\")\n",
        "\n",
        "# -------------------------\n",
        "# Global strom filter (kept)\n",
        "# -------------------------\n",
        "def _filter_no_strom(sub: pd.DataFrame) -> pd.DataFrame:\n",
        "    if sub is None or sub.empty:\n",
        "        return sub\n",
        "    if \"strom_total_occ\" in sub.columns:\n",
        "        v = pd.to_numeric(sub[\"strom_total_occ\"], errors=\"coerce\").fillna(0)\n",
        "        sub = sub.loc[v > 0].copy()\n",
        "    return sub\n",
        "\n",
        "# -------------------------\n",
        "# Global coral filter (added)\n",
        "# -------------------------\n",
        "def _filter_no_coral(sub: pd.DataFrame) -> pd.DataFrame:\n",
        "    if sub is None or sub.empty:\n",
        "        return sub\n",
        "    if \"coral_total_occ\" in sub.columns:\n",
        "        c = pd.to_numeric(sub[\"coral_total_occ\"], errors=\"coerce\").fillna(0)\n",
        "        return sub.loc[c > 0].copy()\n",
        "    # fallback if totals missing\n",
        "    cols = [cc for cc in [\"rugose_occ\", \"tabulate_occ\"] if cc in sub.columns]\n",
        "    if cols:\n",
        "        tmp = sub[cols].apply(pd.to_numeric, errors=\"coerce\").sum(axis=1, min_count=1).fillna(0)\n",
        "        return sub.loc[tmp > 0].copy()\n",
        "    return sub\n",
        "\n",
        "# -------------------------\n",
        "# Predictor typing + presence rules\n",
        "# -------------------------\n",
        "ENV_VARS = set([v for v in [\n",
        "    \"carbonate_area_km2\",\"temperature\",\"dissolved_O2\",\n",
        "    \"d13C\",\"atm_O2\",\"atm_CO2\",\n",
        "    \"total_area_km2\",\"carbonate_percentage\",\"sea_level\"\n",
        "] if v in df.columns])\n",
        "\n",
        "COUNTLIKE_EXTRA = set([v for v in [\"reef_count\",\"strom_total_occ\"] if v in df.columns])\n",
        "\n",
        "STROM_GROUPS = set([\n",
        "    \"derived_strom_prop\",\"basal_strom_prop\",\n",
        "    \"derived_strom_occ\",\"basal_strom_occ\",\n",
        "    \"derived_strom_div\",\"basal_strom_div\",\n",
        "    \"strom_total_occ\",\"strom_total_gen\",\n",
        "    \"Labechiida_prop\",\"Clathrodictyida_prop\",\"Actinostromatida_prop\",\"Stromatoporida_prop\",\n",
        "    \"Stromatoporellida_prop\",\"Syringostromatida_prop\",\"Amphiporida_prop\",\n",
        "    \"Labechiida_occ\",\"Clathrodictyida_occ\",\"Actinostromatida_occ\",\"Stromatoporida_occ\",\n",
        "    \"Stromatoporellida_occ\",\"Syringostromatida_occ\",\"Amphiporida_occ\",\n",
        "    \"Labechiida_genus\",\"Clathrodictyida_genus\",\"Actinostromatida_genus\",\"Stromatoporida_genus\",\n",
        "    \"Stromatoporellida_genus\",\"Syringostromatida_genus\",\"Amphiporida_genus\",\n",
        "])\n",
        "\n",
        "CORAL_GROUPS = set([\"rugose_occ\",\"tabulate_occ\",\"rugose_div\",\"tabulate_div\"])\n",
        "\n",
        "# IMPORTANT: these occ/div variables are \"group summaries\" where zeros are valid within a present group\n",
        "KEEP_ZERO_OCCDIV = set([\n",
        "    \"derived_strom_occ\",\"basal_strom_occ\",\n",
        "    \"derived_strom_div\",\"basal_strom_div\",\n",
        "    \"rugose_occ\",\"tabulate_occ\",\n",
        "    \"rugose_div\",\"tabulate_div\",\n",
        "    \"strom_total_gen\",\n",
        "])\n",
        "\n",
        "def _pred_kind(pred: str) -> str:\n",
        "    if pred in ENV_VARS:\n",
        "        return \"env\"\n",
        "    if pred.endswith(\"_prop\"):\n",
        "        return \"prop\"\n",
        "    if pred.endswith(\"_occ\") or pred.endswith(\"_div\") or pred in COUNTLIKE_EXTRA:\n",
        "        return \"occdiv\"\n",
        "    return \"other\"\n",
        "\n",
        "def _passes_prop_signal(sub: pd.DataFrame, pred: str) -> bool:\n",
        "    if sub is None or sub.empty or len(sub) < MIN_N:\n",
        "        return False\n",
        "    vals = pd.to_numeric(sub[pred], errors=\"coerce\").values\n",
        "    nonzero = int(np.sum(np.isfinite(vals) & (vals != 0)))\n",
        "    return nonzero >= MIN_NONZERO_PROP\n",
        "\n",
        "def _apply_occdiv_presence_rule(sub: pd.DataFrame, pred: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    occ/div rule:\n",
        "      - if pred in KEEP_ZERO_OCCDIV: do NOT require pred>0\n",
        "      - else: require pred>0\n",
        "    \"\"\"\n",
        "    if sub is None or sub.empty:\n",
        "        return sub\n",
        "    if pred in KEEP_ZERO_OCCDIV:\n",
        "        return sub\n",
        "    return sub.loc[pd.to_numeric(sub[pred], errors=\"coerce\") > 0].copy()\n",
        "\n",
        "def get_analysis_data(d: pd.DataFrame, pred: str, targ: str) -> pd.DataFrame:\n",
        "    cols = [pred, targ]\n",
        "    if \"stage\" in d.columns: cols.append(\"stage\")\n",
        "    if \"midpoint_ma\" in d.columns: cols.append(\"midpoint_ma\")\n",
        "    if \"strom_total_occ\" in d.columns: cols.append(\"strom_total_occ\")\n",
        "    if \"coral_total_occ\" in d.columns: cols.append(\"coral_total_occ\")\n",
        "    for cc in [\"rugose_occ\",\"tabulate_occ\"]:\n",
        "        if cc in d.columns and cc not in cols:\n",
        "            cols.append(cc)\n",
        "\n",
        "    sub = d[cols].copy()\n",
        "    sub[pred] = pd.to_numeric(sub[pred], errors=\"coerce\")\n",
        "    sub[targ] = pd.to_numeric(sub[targ], errors=\"coerce\")\n",
        "\n",
        "    # Pairwise complete-case\n",
        "    sub = sub[np.isfinite(sub[pred].values) & np.isfinite(sub[targ].values)].copy()\n",
        "\n",
        "    # Apply group presence filters\n",
        "    if pred in STROM_GROUPS or pred in CORAL_GROUPS:\n",
        "        sub = _filter_no_strom(sub)\n",
        "    if pred in CORAL_GROUPS:\n",
        "        sub = _filter_no_coral(sub)\n",
        "\n",
        "    # Apply predictor-type presence\n",
        "    kind = _pred_kind(pred)\n",
        "    if kind == \"occdiv\":\n",
        "        sub = _apply_occdiv_presence_rule(sub, pred)\n",
        "\n",
        "    return sub\n",
        "\n",
        "def get_lowess_data(d: pd.DataFrame, pred: str) -> pd.DataFrame:\n",
        "    if \"midpoint_ma\" not in d.columns:\n",
        "        return d.iloc[0:0].copy()\n",
        "\n",
        "    cols = [\"midpoint_ma\", pred]\n",
        "    if \"stage\" in d.columns: cols.append(\"stage\")\n",
        "    if \"strom_total_occ\" in d.columns: cols.append(\"strom_total_occ\")\n",
        "    if \"coral_total_occ\" in d.columns: cols.append(\"coral_total_occ\")\n",
        "    for cc in [\"rugose_occ\",\"tabulate_occ\"]:\n",
        "        if cc in d.columns and cc not in cols:\n",
        "            cols.append(cc)\n",
        "\n",
        "    sub = d[cols].copy()\n",
        "    sub[\"midpoint_ma\"] = pd.to_numeric(sub[\"midpoint_ma\"], errors=\"coerce\")\n",
        "    sub[pred] = pd.to_numeric(sub[pred], errors=\"coerce\")\n",
        "\n",
        "    sub = sub[np.isfinite(sub[\"midpoint_ma\"].values) & np.isfinite(sub[pred].values)].copy()\n",
        "\n",
        "    if pred in STROM_GROUPS or pred in CORAL_GROUPS:\n",
        "        sub = _filter_no_strom(sub)\n",
        "    if pred in CORAL_GROUPS:\n",
        "        sub = _filter_no_coral(sub)\n",
        "\n",
        "    kind = _pred_kind(pred)\n",
        "    if kind == \"occdiv\":\n",
        "        sub = _apply_occdiv_presence_rule(sub, pred)\n",
        "\n",
        "    return sub\n",
        "\n",
        "def _safe_spearman(x, y):\n",
        "    x = pd.to_numeric(pd.Series(x), errors=\"coerce\")\n",
        "    y = pd.to_numeric(pd.Series(y), errors=\"coerce\")\n",
        "    m = np.isfinite(x.values) & np.isfinite(y.values)\n",
        "    if m.sum() < MIN_N:\n",
        "        return np.nan, np.nan\n",
        "    res = stats.spearmanr(x.values[m], y.values[m])\n",
        "    return float(res.correlation), float(res.pvalue)\n",
        "\n",
        "def _min_n_for_partial(k_controls: int) -> int:\n",
        "    return max(6, k_controls + 3)\n",
        "\n",
        "rng = np.random.default_rng(RNG_SEED)\n",
        "\n",
        "# -------------------------\n",
        "# Predictor list\n",
        "# -------------------------\n",
        "all_predictors = []\n",
        "\n",
        "for v in [\"derived_strom_prop\", \"basal_strom_prop\", \"derived_strom_occ\", \"basal_strom_occ\", \"derived_strom_div\", \"basal_strom_div\"]:\n",
        "    if v in df.columns:\n",
        "        all_predictors.append(v)\n",
        "\n",
        "for v in [\"rugose_occ\",\"tabulate_occ\",\"rugose_div\",\"tabulate_div\"]:\n",
        "    if v in df.columns:\n",
        "        all_predictors.append(v)\n",
        "\n",
        "for v in [\"carbonate_area_km2\",\"temperature\",\"dissolved_O2\",\n",
        "          \"d13C\",\"atm_O2\",\"atm_CO2\",\"total_area_km2\",\"carbonate_percentage\",\"sea_level\"]:\n",
        "    if v in df.columns and v not in all_predictors:\n",
        "        all_predictors.append(v)\n",
        "\n",
        "for v in [\n",
        "    \"Labechiida_prop\",\"Clathrodictyida_prop\",\"Actinostromatida_prop\",\n",
        "    \"Stromatoporida_prop\",\"Stromatoporellida_prop\",\"Syringostromatida_prop\",\"Amphiporida_prop\"\n",
        "]:\n",
        "    if v in df.columns:\n",
        "        all_predictors.append(v)\n",
        "\n",
        "all_predictors = list(dict.fromkeys(all_predictors))\n",
        "print(\"[INFO] Predictors included:\", all_predictors)\n",
        "\n",
        "# ==============================================================================\n",
        "# LOWESS (pred vs time)\n",
        "# ==============================================================================\n",
        "if DO_LOWESS:\n",
        "    print(\"\\n[LOWESS] Computing LOWESS smooths vs time (midpoint_ma)...\")\n",
        "\n",
        "    if \"midpoint_ma\" not in df.columns:\n",
        "        print(\"  [WARN] midpoint_ma missing; LOWESS skipped.\")\n",
        "    else:\n",
        "        lowess_predictors = []\n",
        "        for v in [\n",
        "            \"basal_strom_prop\",\"derived_strom_prop\",\n",
        "            \"basal_strom_occ\",\"derived_strom_occ\",\n",
        "            \"basal_strom_div\",\"derived_strom_div\"\n",
        "        ]:\n",
        "            if v in df.columns:\n",
        "                lowess_predictors.append(v)\n",
        "\n",
        "        lowess_predictors = list(dict.fromkeys(lowess_predictors))\n",
        "        print(\"  LOWESS predictors:\", lowess_predictors)\n",
        "\n",
        "        lowess_rows = []\n",
        "        for pred in lowess_predictors:\n",
        "            sub = get_lowess_data(df, pred)\n",
        "            kind = _pred_kind(pred)\n",
        "\n",
        "            if kind == \"prop\" and len(sub) >= MIN_N and (not _passes_prop_signal(sub, pred)):\n",
        "                continue\n",
        "            if len(sub) < MIN_N:\n",
        "                continue\n",
        "\n",
        "            sub2 = sub.sort_values(\"midpoint_ma\").reset_index(drop=True)\n",
        "            x = sub2[\"midpoint_ma\"].values.astype(float)\n",
        "            y = sub2[pred].values.astype(float)\n",
        "\n",
        "            try:\n",
        "                fit = lowess(endog=y, exog=x, frac=LOWESS_FRAC, it=LOWESS_IT, return_sorted=True)\n",
        "                for xi, yhat in fit:\n",
        "                    lowess_rows.append({\n",
        "                        \"Predictor\": pred,\n",
        "                        \"midpoint_ma\": float(xi),\n",
        "                        \"lowess_y\": float(yhat),\n",
        "                        \"N_used\": int(len(sub2)),\n",
        "                        \"frac\": float(LOWESS_FRAC),\n",
        "                        \"it\": int(LOWESS_IT)\n",
        "                    })\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        lowess_df = pd.DataFrame(lowess_rows)\n",
        "        lowess_df.to_csv(OUTPUT_DIR / \"results_lowess_predictors_vs_time_long.csv\",\n",
        "                         index=False, encoding=\"utf-8-sig\")\n",
        "        print(\"  -> Saved results_lowess_predictors_vs_time_long.csv\")\n",
        "        display(lowess_df.head(20))\n",
        "\n",
        "# ==============================================================================\n",
        "# From here down: advanced stats blocks.\n",
        "# basal_strom_prop excluded for multivariate blocks to avoid singularity.\n",
        "# ==============================================================================\n",
        "stats_predictors = [p for p in all_predictors if p != \"basal_strom_prop\"]\n",
        "\n",
        "print(\"\\n[INFO] Predictors used for correlation/bootstrap/permutation/LOO/detrend/partial/univariate:\",\n",
        "      stats_predictors)\n",
        "\n",
        "# ==============================================================================\n",
        "# 0. ORIGINAL SPEARMAN CORRELATIONS\n",
        "# ==============================================================================\n",
        "print(\"\\n0. Computing original Spearman correlations...\")\n",
        "corr_rows = []\n",
        "skip_counts = {\"too_few\":0, \"prop_low_signal\":0, \"ok\":0}\n",
        "\n",
        "for pred in stats_predictors:\n",
        "    sub = get_analysis_data(df, pred, target)\n",
        "    kind = _pred_kind(pred)\n",
        "\n",
        "    if kind == \"prop\" and len(sub) >= MIN_N and (not _passes_prop_signal(sub, pred)):\n",
        "        corr_rows.append({\"Dataset\":\"Stage-Level Data\",\"Target\":target,\"Predictor\":pred,\"N\":int(len(sub)),\n",
        "                          \"spearman_rho\":np.nan,\"spearman_p\":np.nan,\"Status\":\"SKIP_prop_low_signal\"})\n",
        "        skip_counts[\"prop_low_signal\"] += 1\n",
        "        continue\n",
        "\n",
        "    r, p = _safe_spearman(sub[pred], sub[target]) if len(sub) else (np.nan, np.nan)\n",
        "    status = \"OK\" if (len(sub) >= MIN_N and np.isfinite(r)) else \"SKIP_too_few_rows\"\n",
        "    corr_rows.append({\"Dataset\":\"Stage-Level Data\",\"Target\":target,\"Predictor\":pred,\"N\":int(len(sub)),\n",
        "                      \"spearman_rho\":r,\"spearman_p\":p,\"Status\":status})\n",
        "    skip_counts[\"ok\" if status==\"OK\" else \"too_few\"] += 1\n",
        "\n",
        "corr_df = pd.DataFrame(corr_rows)\n",
        "corr_df.to_csv(OUTPUT_DIR / \"results_spearman_original_all_predictors.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(\"  -> Saved results_spearman_original_all_predictors.csv\")\n",
        "if VERBOSE_SKIP_COUNTS:\n",
        "    print(\"[INFO] Spearman status counts:\", skip_counts)\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. BOOTSTRAP\n",
        "# ==============================================================================\n",
        "print(f\"\\n1. Running Bootstrap ({N_BOOT} iter)...\")\n",
        "boot_summary = []\n",
        "boot_dist_long = []\n",
        "\n",
        "for pred in stats_predictors:\n",
        "    sub = get_analysis_data(df, pred, target)\n",
        "    kind = _pred_kind(pred)\n",
        "    n = len(sub)\n",
        "\n",
        "    if kind == \"prop\" and n >= MIN_N and (not _passes_prop_signal(sub, pred)):\n",
        "        boot_summary.append({\"Dataset\":\"Stage-Level Data\",\"Target\":target,\"Predictor\":pred,\"N\":int(n),\n",
        "                             \"spearman_observed\":np.nan,\"spearman_ci_low\":np.nan,\"spearman_ci_high\":np.nan,\n",
        "                             \"Status\":\"SKIP_prop_low_signal\"})\n",
        "        continue\n",
        "\n",
        "    if n < MIN_N:\n",
        "        boot_summary.append({\"Dataset\":\"Stage-Level Data\",\"Target\":target,\"Predictor\":pred,\"N\":int(n),\n",
        "                             \"spearman_observed\":np.nan,\"spearman_ci_low\":np.nan,\"spearman_ci_high\":np.nan,\n",
        "                             \"Status\":\"SKIP_too_few_rows\"})\n",
        "        continue\n",
        "\n",
        "    rho_obs, _ = stats.spearmanr(sub[pred], sub[target])\n",
        "\n",
        "    idx = np.arange(n)\n",
        "    rhos = np.empty(N_BOOT, dtype=float)\n",
        "    for b in range(N_BOOT):\n",
        "        s = rng.choice(idx, size=n, replace=True)\n",
        "        r, _ = stats.spearmanr(sub[pred].iloc[s], sub[target].iloc[s])\n",
        "        rhos[b] = r\n",
        "\n",
        "    ci_low = np.nanpercentile(rhos, 2.5)\n",
        "    ci_high = np.nanpercentile(rhos, 97.5)\n",
        "\n",
        "    boot_summary.append({\"Dataset\":\"Stage-Level Data\",\"Target\":target,\"Predictor\":pred,\"N\":int(n),\n",
        "                         \"spearman_observed\":float(rho_obs) if np.isfinite(rho_obs) else np.nan,\n",
        "                         \"spearman_ci_low\":float(ci_low),\"spearman_ci_high\":float(ci_high),\"Status\":\"OK\"})\n",
        "    boot_dist_long.extend([{\"Predictor\":pred,\"iter\":i+1,\"rho\":float(rhos[i])} for i in range(N_BOOT)])\n",
        "\n",
        "pd.DataFrame(boot_summary).to_csv(OUTPUT_DIR / \"results_bootstrap.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "pd.DataFrame(boot_dist_long).to_csv(OUTPUT_DIR / \"results_bootstrap_dist_all_predictors_long.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(\"  -> Saved results_bootstrap.csv\")\n",
        "print(\"  -> Saved results_bootstrap_dist_all_predictors_long.csv\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. PERMUTATION\n",
        "# ==============================================================================\n",
        "print(f\"2. Running Permutation ({N_PERM} iter)...\")\n",
        "perm_summary = []\n",
        "perm_dist_long = []\n",
        "\n",
        "for pred in stats_predictors:\n",
        "    sub = get_analysis_data(df, pred, target)\n",
        "    kind = _pred_kind(pred)\n",
        "    n = len(sub)\n",
        "\n",
        "    if kind == \"prop\" and n >= MIN_N and (not _passes_prop_signal(sub, pred)):\n",
        "        perm_summary.append({\"Dataset\":\"Stage-Level Data\",\"Target\":target,\"Predictor\":pred,\"N\":int(n),\n",
        "                             \"spearman_observed\":np.nan,\"spearman_p_permutation\":np.nan,\n",
        "                             \"Status\":\"SKIP_prop_low_signal\"})\n",
        "        continue\n",
        "\n",
        "    if n < MIN_N:\n",
        "        perm_summary.append({\"Dataset\":\"Stage-Level Data\",\"Target\":target,\"Predictor\":pred,\"N\":int(n),\n",
        "                             \"spearman_observed\":np.nan,\"spearman_p_permutation\":np.nan,\n",
        "                             \"Status\":\"SKIP_too_few_rows\"})\n",
        "        continue\n",
        "\n",
        "    rho_obs, _ = stats.spearmanr(sub[pred], sub[target])\n",
        "    y = sub[target].values\n",
        "\n",
        "    perm_rhos = np.empty(N_PERM, dtype=float)\n",
        "    extreme = 0\n",
        "    for i in range(N_PERM):\n",
        "        y_perm = rng.permutation(y)\n",
        "        r_perm, _ = stats.spearmanr(sub[pred].values, y_perm)\n",
        "        perm_rhos[i] = r_perm\n",
        "        if np.isfinite(r_perm) and np.isfinite(rho_obs) and (abs(r_perm) >= abs(rho_obs)):\n",
        "            extreme += 1\n",
        "\n",
        "    p_val = (extreme + 1) / (N_PERM + 1)\n",
        "    perm_summary.append({\"Dataset\":\"Stage-Level Data\",\"Target\":target,\"Predictor\":pred,\"N\":int(n),\n",
        "                         \"spearman_observed\":float(rho_obs) if np.isfinite(rho_obs) else np.nan,\n",
        "                         \"spearman_p_permutation\":float(p_val),\"Status\":\"OK\"})\n",
        "    perm_dist_long.extend([{\"Predictor\":pred,\"iter\":i+1,\"rho\":float(perm_rhos[i])} for i in range(N_PERM)])\n",
        "\n",
        "pd.DataFrame(perm_summary).to_csv(OUTPUT_DIR / \"results_permutation.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "pd.DataFrame(perm_dist_long).to_csv(OUTPUT_DIR / \"results_permutation_dist_all_predictors_long.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(\"  -> Saved results_permutation.csv\")\n",
        "print(\"  -> Saved results_permutation_dist_all_predictors_long.csv\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. LEAVE-ONE-OUT\n",
        "# ==============================================================================\n",
        "print(\"3. Running Leave-One-Out...\")\n",
        "loo_detailed_long = []\n",
        "loo_summary = []\n",
        "\n",
        "for pred in stats_predictors:\n",
        "    cols = [\"stage\", pred, target]\n",
        "    if \"strom_total_occ\" in df.columns: cols.append(\"strom_total_occ\")\n",
        "    if \"coral_total_occ\" in df.columns: cols.append(\"coral_total_occ\")\n",
        "    for cc in [\"rugose_occ\",\"tabulate_occ\"]:\n",
        "        if cc in df.columns and cc not in cols:\n",
        "            cols.append(cc)\n",
        "    if \"midpoint_ma\" in df.columns: cols.append(\"midpoint_ma\")\n",
        "\n",
        "    v = df[cols].copy()\n",
        "    for c in [pred, target]:\n",
        "        v[c] = pd.to_numeric(v[c], errors=\"coerce\")\n",
        "    v = v.dropna(subset=[\"stage\", pred, target])\n",
        "\n",
        "    if pred in STROM_GROUPS or pred in CORAL_GROUPS:\n",
        "        v = _filter_no_strom(v)\n",
        "    if pred in CORAL_GROUPS:\n",
        "        v = _filter_no_coral(v)\n",
        "\n",
        "    kind = _pred_kind(pred)\n",
        "    if kind == \"occdiv\":\n",
        "        v = _apply_occdiv_presence_rule(v, pred)\n",
        "\n",
        "    if kind == \"prop\" and len(v) >= MIN_N and (not _passes_prop_signal(v, pred)):\n",
        "        loo_summary.append({\"Dataset\":\"Stage-Level Data\",\"Target\":target,\"Predictor\":pred,\"N\":int(len(v)),\n",
        "                            \"LOO_Mean_Rho\":np.nan,\"LOO_Max_P\":np.nan,\"LOO_Min_Rho\":np.nan,\"LOO_Max_Rho\":np.nan,\n",
        "                            \"Status\":\"SKIP_prop_low_signal\"})\n",
        "        continue\n",
        "\n",
        "    v = v.reset_index(drop=True)\n",
        "    n = len(v)\n",
        "    if n < MIN_N:\n",
        "        loo_summary.append({\"Dataset\":\"Stage-Level Data\",\"Target\":target,\"Predictor\":pred,\"N\":int(n),\n",
        "                            \"LOO_Mean_Rho\":np.nan,\"LOO_Max_P\":np.nan,\"LOO_Min_Rho\":np.nan,\"LOO_Max_Rho\":np.nan,\n",
        "                            \"Status\":\"SKIP_too_few_rows\"})\n",
        "        continue\n",
        "\n",
        "    rho_full, _ = stats.spearmanr(v[pred], v[target])\n",
        "\n",
        "    rhos, ps = [], []\n",
        "    for i in range(n):\n",
        "        vv = v.drop(index=i)\n",
        "        r, p = _safe_spearman(vv[pred], vv[target])\n",
        "        rhos.append(r); ps.append(p)\n",
        "        loo_detailed_long.append({\n",
        "            \"Predictor\": pred,\n",
        "            \"Stage_Dropped\": v.loc[i, \"stage\"],\n",
        "            \"LOO_Rho\": r,\n",
        "            \"Diff_from_Full\": (r - rho_full) if (np.isfinite(r) and np.isfinite(rho_full)) else np.nan\n",
        "        })\n",
        "\n",
        "    loo_summary.append({\n",
        "        \"Dataset\":\"Stage-Level Data\",\"Target\":target,\"Predictor\":pred,\"N\":int(n),\n",
        "        \"LOO_Mean_Rho\":float(np.nanmean(rhos)),\n",
        "        \"LOO_Max_P\":float(np.nanmax(ps)),\n",
        "        \"LOO_Min_Rho\":float(np.nanmin(rhos)),\n",
        "        \"LOO_Max_Rho\":float(np.nanmax(rhos)),\n",
        "        \"Status\":\"OK\"\n",
        "    })\n",
        "\n",
        "pd.DataFrame(loo_detailed_long).to_csv(OUTPUT_DIR / \"results_loo_detailed_all_predictors_long.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "pd.DataFrame(loo_summary).to_csv(OUTPUT_DIR / \"results_loo_summary.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(\"  -> Saved results_loo_detailed_all_predictors_long.csv\")\n",
        "print(\"  -> Saved results_loo_summary.csv\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. DETRENDING\n",
        "# ==============================================================================\n",
        "print(\"4. Running Detrending (status logged)...\")\n",
        "det_results = []\n",
        "\n",
        "if \"midpoint_ma\" not in df.columns:\n",
        "    print(\"  [ERROR] midpoint_ma missing -> detrending cannot run.\")\n",
        "else:\n",
        "    for pred in stats_predictors:\n",
        "        row = {\"Dataset\":\"Stage-Level Data\",\"Target\":target,\"Predictor\":pred,\"N\":0,\n",
        "               \"Detrend_Rho\":np.nan,\"Detrend_P\":np.nan,\"Status\":\"INIT\"}\n",
        "\n",
        "        cols = [\"midpoint_ma\", pred, target]\n",
        "        if \"strom_total_occ\" in df.columns: cols.append(\"strom_total_occ\")\n",
        "        if \"coral_total_occ\" in df.columns: cols.append(\"coral_total_occ\")\n",
        "        for cc in [\"rugose_occ\",\"tabulate_occ\"]:\n",
        "            if cc in df.columns and cc not in cols:\n",
        "                cols.append(cc)\n",
        "\n",
        "        v = df[cols].copy()\n",
        "        v[\"midpoint_ma\"] = pd.to_numeric(v[\"midpoint_ma\"], errors=\"coerce\")\n",
        "        v[pred] = pd.to_numeric(v[pred], errors=\"coerce\")\n",
        "        v[target] = pd.to_numeric(v[target], errors=\"coerce\")\n",
        "\n",
        "        v = v.dropna(subset=[\"midpoint_ma\", pred, target])\n",
        "\n",
        "        if pred in STROM_GROUPS or pred in CORAL_GROUPS:\n",
        "            v = _filter_no_strom(v)\n",
        "        if pred in CORAL_GROUPS:\n",
        "            v = _filter_no_coral(v)\n",
        "\n",
        "        kind = _pred_kind(pred)\n",
        "        if kind == \"occdiv\":\n",
        "            v = _apply_occdiv_presence_rule(v, pred)\n",
        "        elif kind == \"prop\":\n",
        "            if len(v) >= MIN_N and (not _passes_prop_signal(v, pred)):\n",
        "                row[\"N\"] = int(len(v))\n",
        "                row[\"Status\"] = \"SKIP_prop_low_signal\"\n",
        "                det_results.append(row)\n",
        "                continue\n",
        "\n",
        "        n = len(v)\n",
        "        row[\"N\"] = int(n)\n",
        "        if n < MIN_N:\n",
        "            row[\"Status\"] = \"SKIP_too_few_rows\"\n",
        "            det_results.append(row)\n",
        "            continue\n",
        "        if v[pred].nunique(dropna=True) < 2 or float(np.nanstd(v[pred].values)) == 0.0:\n",
        "            row[\"Status\"] = \"SKIP_constant_predictor\"\n",
        "            det_results.append(row)\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            sx, ix, *_ = stats.linregress(v[\"midpoint_ma\"], v[pred])\n",
        "            sy, iy, *_ = stats.linregress(v[\"midpoint_ma\"], v[target])\n",
        "            resid_x = v[pred] - (sx * v[\"midpoint_ma\"] + ix)\n",
        "            resid_y = v[target] - (sy * v[\"midpoint_ma\"] + iy)\n",
        "            r, p = stats.spearmanr(resid_x, resid_y, nan_policy=\"omit\")\n",
        "            row[\"Detrend_Rho\"] = float(r) if np.isfinite(r) else np.nan\n",
        "            row[\"Detrend_P\"] = float(p) if np.isfinite(p) else np.nan\n",
        "            row[\"Status\"] = \"OK\"\n",
        "        except Exception as e:\n",
        "            row[\"Status\"] = f\"FAIL_{type(e).__name__}\"\n",
        "\n",
        "        det_results.append(row)\n",
        "\n",
        "pd.DataFrame(det_results).to_csv(OUTPUT_DIR / \"results_detrending_improved.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(\"  -> Saved results_detrending_improved.csv\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. PARTIAL CORRELATIONS\n",
        "# ==============================================================================\n",
        "print(\"\\n5. Running Partial Correlations (predictor-type aware)...\")\n",
        "\n",
        "env_controls = [v for v in [\"carbonate_area_km2\",\"temperature\",\"dissolved_O2\"] if v in df.columns]\n",
        "biotic_controls_for_env = [v for v in [\"derived_strom_prop\"] if v in df.columns]\n",
        "\n",
        "def _partial_spearman(sub: pd.DataFrame, pred: str, targ: str, controls: list):\n",
        "    Xc = sm.add_constant(sub[controls], has_constant=\"add\")\n",
        "    res_pred = sm.OLS(sub[pred].values.astype(float), Xc.values.astype(float)).fit().resid\n",
        "    res_targ = sm.OLS(sub[targ].values.astype(float), Xc.values.astype(float)).fit().resid\n",
        "    r, p = stats.spearmanr(res_pred, res_targ, nan_policy=\"omit\")\n",
        "    return float(r) if np.isfinite(r) else np.nan, float(p) if np.isfinite(p) else np.nan\n",
        "\n",
        "part_rows = []\n",
        "\n",
        "for pred in stats_predictors:\n",
        "    kind = _pred_kind(pred)\n",
        "    if kind == \"env\":\n",
        "        controls = biotic_controls_for_env[:]\n",
        "        test_type = \"Environment (Biotic Controlled)\"\n",
        "    else:\n",
        "        controls = env_controls[:]\n",
        "        test_type = \"Biotic/Taxon (Env Controlled)\"\n",
        "\n",
        "    controls = [c for c in controls if c in df.columns]\n",
        "    if len(controls) < 1:\n",
        "        part_rows.append({\"Dataset\":\"Stage-Level Data\",\"Target\":target,\"Predictor\":pred,\"Test_Type\":test_type,\n",
        "                          \"Controls\":\",\".join(controls),\"N\":0,\"spearman_partial\":np.nan,\"spearman_p_partial\":np.nan,\n",
        "                          \"Status\":\"SKIP_insufficient_controls\"})\n",
        "        continue\n",
        "\n",
        "    cols = [pred, target] + controls\n",
        "    if \"strom_total_occ\" in df.columns: cols.append(\"strom_total_occ\")\n",
        "    if \"coral_total_occ\" in df.columns: cols.append(\"coral_total_occ\")\n",
        "    for cc in [\"rugose_occ\",\"tabulate_occ\"]:\n",
        "        if cc in df.columns and cc not in cols:\n",
        "            cols.append(cc)\n",
        "\n",
        "    sub = df[cols].copy()\n",
        "    for c in [pred, target] + controls:\n",
        "        sub[c] = pd.to_numeric(sub[c], errors=\"coerce\")\n",
        "\n",
        "    sub = sub.dropna(subset=[pred, target] + controls)\n",
        "\n",
        "    if pred in STROM_GROUPS or pred in CORAL_GROUPS:\n",
        "        sub = _filter_no_strom(sub)\n",
        "    if pred in CORAL_GROUPS:\n",
        "        sub = _filter_no_coral(sub)\n",
        "\n",
        "    if kind == \"occdiv\":\n",
        "        sub = _apply_occdiv_presence_rule(sub, pred)\n",
        "        # Only enforce MIN_POSITIVE for presence-only occ/div variables\n",
        "        if pred not in KEEP_ZERO_OCCDIV and len(sub) < MIN_POSITIVE:\n",
        "            part_rows.append({\"Dataset\":\"Stage-Level Data\",\"Target\":target,\"Predictor\":pred,\"Test_Type\":test_type,\n",
        "                              \"Controls\":\",\".join(controls),\"N\":int(len(sub)),\n",
        "                              \"spearman_partial\":np.nan,\"spearman_p_partial\":np.nan,\n",
        "                              \"Status\":\"SKIP_too_few_positive\"})\n",
        "            continue\n",
        "    elif kind == \"prop\":\n",
        "        if len(sub) >= MIN_N and (not _passes_prop_signal(sub, pred)):\n",
        "            part_rows.append({\"Dataset\":\"Stage-Level Data\",\"Target\":target,\"Predictor\":pred,\"Test_Type\":test_type,\n",
        "                              \"Controls\":\",\".join(controls),\"N\":int(len(sub)),\n",
        "                              \"spearman_partial\":np.nan,\"spearman_p_partial\":np.nan,\n",
        "                              \"Status\":\"SKIP_prop_low_signal\"})\n",
        "            continue\n",
        "\n",
        "    n = len(sub)\n",
        "    min_n = _min_n_for_partial(len(controls))\n",
        "    if n < min_n:\n",
        "        part_rows.append({\"Dataset\":\"Stage-Level Data\",\"Target\":target,\"Predictor\":pred,\"Test_Type\":test_type,\n",
        "                          \"Controls\":\",\".join(controls),\"N\":int(n),\n",
        "                          \"spearman_partial\":np.nan,\"spearman_p_partial\":np.nan,\n",
        "                          \"Status\":f\"SKIP_too_few_rows(n<{min_n})\"})\n",
        "        continue\n",
        "\n",
        "    if sub[pred].nunique(dropna=True) < 2 or float(np.nanstd(sub[pred].values)) == 0.0:\n",
        "        part_rows.append({\"Dataset\":\"Stage-Level Data\",\"Target\":target,\"Predictor\":pred,\"Test_Type\":test_type,\n",
        "                          \"Controls\":\",\".join(controls),\"N\":int(n),\n",
        "                          \"spearman_partial\":np.nan,\"spearman_p_partial\":np.nan,\n",
        "                          \"Status\":\"SKIP_constant_predictor\"})\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        r, p = _partial_spearman(sub, pred, target, controls)\n",
        "        part_rows.append({\"Dataset\":\"Stage-Level Data\",\"Target\":target,\"Predictor\":pred,\"Test_Type\":test_type,\n",
        "                          \"Controls\":\",\".join(controls),\"N\":int(n),\n",
        "                          \"spearman_partial\":r,\"spearman_p_partial\":p,\"Status\":\"OK\"})\n",
        "    except Exception as e:\n",
        "        part_rows.append({\"Dataset\":\"Stage-Level Data\",\"Target\":target,\"Predictor\":pred,\"Test_Type\":test_type,\n",
        "                          \"Controls\":\",\".join(controls),\"N\":int(n),\n",
        "                          \"spearman_partial\":np.nan,\"spearman_p_partial\":np.nan,\n",
        "                          \"Status\":f\"FAIL_{type(e).__name__}\"})\n",
        "\n",
        "part_df = pd.DataFrame(part_rows).sort_values([\"Status\",\"spearman_p_partial\"], na_position=\"last\")\n",
        "part_df.to_csv(OUTPUT_DIR / \"results_partial_correlations.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(\"  -> Saved results_partial_correlations.csv\")\n",
        "\n",
        "print(\"\\n[DISPLAY] Partial correlations (OK rows):\")\n",
        "display(part_df[part_df[\"Status\"] == \"OK\"].sort_values(\"spearman_p_partial\", na_position=\"last\"))\n",
        "\n",
        "print(\"\\n[DISPLAY] Partial correlations (all rows incl. skips/fails):\")\n",
        "display(part_df)\n",
        "\n",
        "# ==============================================================================\n",
        "# 6. VARIANCE PARTITIONING (strict)\n",
        "# ==============================================================================\n",
        "print(\"6. Running Variance Partitioning (groups; strict subset)...\")\n",
        "\n",
        "def get_adj_r2_group(data: pd.DataFrame, y_col: str, x_cols: list) -> float:\n",
        "    if len(x_cols) == 0:\n",
        "        return np.nan\n",
        "    vv = data[[y_col] + x_cols].copy()\n",
        "    for c in [y_col] + x_cols:\n",
        "        vv[c] = pd.to_numeric(vv[c], errors=\"coerce\")\n",
        "    vv = vv.dropna()\n",
        "    if len(vv) < len(x_cols) + 2:\n",
        "        return np.nan\n",
        "    # drop constant predictors to avoid singular designs\n",
        "    keep = []\n",
        "    for xc in x_cols:\n",
        "        if vv[xc].nunique(dropna=True) >= 2 and float(np.nanstd(vv[xc].values)) > 0.0:\n",
        "            keep.append(xc)\n",
        "    if len(keep) == 0:\n",
        "        return np.nan\n",
        "    X = sm.add_constant(vv[keep], has_constant=\"add\")\n",
        "    y = vv[y_col].values.astype(float)\n",
        "    try:\n",
        "        return float(sm.OLS(y, X.values.astype(float)).fit(method=\"qr\").rsquared_adj)\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "A = [v for v in [\"derived_strom_prop\"] if v in df.columns]  # derived only\n",
        "B = [v for v in [\"rugose_occ\",\"tabulate_occ\"] if v in df.columns]\n",
        "C = env_controls[:]\n",
        "ABC = A + B + C\n",
        "\n",
        "vp_cols = [target] + ABC\n",
        "if \"strom_total_occ\" in df.columns: vp_cols.append(\"strom_total_occ\")\n",
        "if \"coral_total_occ\" in df.columns: vp_cols.append(\"coral_total_occ\")\n",
        "for cc in [\"rugose_occ\",\"tabulate_occ\"]:\n",
        "    if cc in df.columns and cc not in vp_cols:\n",
        "        vp_cols.append(cc)\n",
        "\n",
        "sub_vp = df[vp_cols].copy()\n",
        "for c in [target] + ABC:\n",
        "    sub_vp[c] = pd.to_numeric(sub_vp[c], errors=\"coerce\")\n",
        "sub_vp = sub_vp.dropna(subset=[target] + ABC)\n",
        "\n",
        "# Apply group presence (do NOT force rugose/tabulate >0; zeros allowed once corals present)\n",
        "sub_vp = _filter_no_strom(sub_vp)\n",
        "sub_vp = _filter_no_coral(sub_vp)\n",
        "\n",
        "# Prop signal gate for A\n",
        "for pred in A:\n",
        "    if not _passes_prop_signal(sub_vp, pred):\n",
        "        sub_vp = sub_vp.iloc[0:0].copy()\n",
        "        break\n",
        "\n",
        "r2_abc = get_adj_r2_group(sub_vp, target, ABC)\n",
        "r2_bc  = get_adj_r2_group(sub_vp, target, B + C)\n",
        "r2_ac  = get_adj_r2_group(sub_vp, target, A + C)\n",
        "r2_ab  = get_adj_r2_group(sub_vp, target, A + B)\n",
        "\n",
        "unique_a = r2_abc - r2_bc if np.isfinite(r2_abc) and np.isfinite(r2_bc) else np.nan\n",
        "unique_b = r2_abc - r2_ac if np.isfinite(r2_abc) and np.isfinite(r2_ac) else np.nan\n",
        "unique_c = r2_abc - r2_ab if np.isfinite(r2_abc) and np.isfinite(r2_ab) else np.nan\n",
        "shared   = r2_abc - (unique_a + unique_b + unique_c) if np.isfinite(r2_abc) else np.nan\n",
        "\n",
        "var_out = pd.DataFrame([{\n",
        "    \"Dataset\":\"Stage-Level Data\",\n",
        "    \"Target\":target,\n",
        "    \"Strom_Group\":\",\".join(A),\n",
        "    \"Coral_Group\":\",\".join(B),\n",
        "    \"Env_Group\":\",\".join(C),\n",
        "    \"Unique_Strom\":unique_a,\n",
        "    \"Unique_Coral\":unique_b,\n",
        "    \"Unique_Env\":unique_c,\n",
        "    \"Shared\":shared,\n",
        "    \"Residual\":(1 - r2_abc) if np.isfinite(r2_abc) else np.nan,\n",
        "    \"Total_R2_adj\":r2_abc,\n",
        "    \"N\":int(len(sub_vp))\n",
        "}])\n",
        "var_out.to_csv(OUTPUT_DIR / \"results_variance_partition_improved.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(\"  -> Saved results_variance_partition_improved.csv\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 6b. Univariate adj-R2\n",
        "# ==============================================================================\n",
        "print(\"6b. Running Univariate adj-R2 (robust)...\")\n",
        "uni_rows = []\n",
        "\n",
        "for pred in stats_predictors:\n",
        "    sub = get_analysis_data(df, pred, target)\n",
        "    kind = _pred_kind(pred)\n",
        "\n",
        "    if kind == \"prop\" and len(sub) >= MIN_N and (not _passes_prop_signal(sub, pred)):\n",
        "        uni_rows.append({\"Predictor\":pred,\"N\":int(len(sub)),\"Adj_R2_univariate\":np.nan,\"Status\":\"SKIP_prop_low_signal\"})\n",
        "        continue\n",
        "\n",
        "    n = len(sub)\n",
        "    if n < 6:\n",
        "        uni_rows.append({\"Predictor\":pred,\"N\":int(n),\"Adj_R2_univariate\":np.nan,\"Status\":\"SKIP_too_few_rows\"})\n",
        "        continue\n",
        "\n",
        "    x = pd.to_numeric(sub[pred], errors=\"coerce\")\n",
        "    y = pd.to_numeric(sub[target], errors=\"coerce\")\n",
        "    m = np.isfinite(x.values) & np.isfinite(y.values)\n",
        "    x = x[m]; y = y[m]\n",
        "\n",
        "    if len(x) < 6:\n",
        "        uni_rows.append({\"Predictor\":pred,\"N\":int(len(x)),\"Adj_R2_univariate\":np.nan,\"Status\":\"SKIP_too_few_rows\"})\n",
        "        continue\n",
        "    if x.nunique(dropna=True) < 2 or float(np.nanstd(x.values)) == 0.0:\n",
        "        uni_rows.append({\"Predictor\":pred,\"N\":int(len(x)),\"Adj_R2_univariate\":np.nan,\"Status\":\"SKIP_constant_predictor\"})\n",
        "        continue\n",
        "\n",
        "    X = sm.add_constant(pd.DataFrame({pred: x.values}), has_constant=\"add\").values.astype(float)\n",
        "    yy = y.values.astype(float)\n",
        "\n",
        "    try:\n",
        "        fit = sm.OLS(yy, X).fit(method=\"qr\")\n",
        "        uni_rows.append({\"Predictor\":pred,\"N\":int(len(x)),\"Adj_R2_univariate\":float(fit.rsquared_adj),\"Status\":\"OK\"})\n",
        "    except Exception as e:\n",
        "        uni_rows.append({\"Predictor\":pred,\"N\":int(len(x)),\"Adj_R2_univariate\":np.nan,\"Status\":f\"FAIL_{type(e).__name__}\"})\n",
        "\n",
        "pd.DataFrame(uni_rows).to_csv(OUTPUT_DIR / \"results_adjR2_univariate_all_predictors.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(\"  -> Saved results_adjR2_univariate_all_predictors.csv\")\n",
        "\n",
        "CELL13_PART_A_DONE = True\n",
        "print(\"\\n✓ CELL 13 PART A COMPLETE (v3 + LOWESS; strom+coral summary occ/div allow zeros once present).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# @title CELL 14: MODEL SELECTION + LOWESS + LAG (Robust guards) — NO BASAL\n",
        "# =============================================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"CELL 14: AICc + LOWESS + LAG (NO BASAL)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def _filter_no_strom(sub):\n",
        "    if 'strom_total_occ' in sub.columns:\n",
        "        sub = sub[sub['strom_total_occ'].notna() & (pd.to_numeric(sub['strom_total_occ'], errors='coerce') > 0)]\n",
        "    return sub\n",
        "\n",
        "# ---------------------------\n",
        "# 7. AICc MODEL SELECTION (COMMON SUBSET; Method 1) — strom/coral/env only\n",
        "# ---------------------------\n",
        "print(\"7. Running AICc Model Selection (COMMON SUBSET; strom/coral/env only)...\")\n",
        "\n",
        "target = 'thickness_mean'\n",
        "\n",
        "# requested groups (NO BASAL)\n",
        "strom_vars = [v for v in ['derived_strom_prop'] if v in df.columns]\n",
        "coral_vars = [v for v in ['rugose_div', 'tabulate_div'] if v in df.columns]\n",
        "env_vars   = [v for v in ['carbonate_area_km2', 'temperature', 'dissolved_O2'] if v in df.columns]\n",
        "\n",
        "needed = [target] + strom_vars + coral_vars + env_vars\n",
        "if 'strom_total_occ' in df.columns:\n",
        "    needed += ['strom_total_occ']\n",
        "\n",
        "sub_aic = df[needed].copy()\n",
        "sub_aic[target] = pd.to_numeric(sub_aic[target], errors='coerce')\n",
        "for c in strom_vars + coral_vars + env_vars:\n",
        "    sub_aic[c] = pd.to_numeric(sub_aic[c], errors='coerce')\n",
        "\n",
        "# COMMON SUBSET (complete for full set)\n",
        "sub_aic = sub_aic.dropna(subset=[target] + strom_vars + coral_vars + env_vars)\n",
        "sub_aic = _filter_no_strom(sub_aic)\n",
        "\n",
        "print(f\"  Common-subset N = {len(sub_aic)} rows\")\n",
        "\n",
        "models = {\n",
        "    'Strom+Coral': strom_vars + coral_vars,\n",
        "    'Strom-only':  strom_vars,\n",
        "    'Strom+Env':   strom_vars + env_vars,\n",
        "    'Full':        strom_vars + coral_vars + env_vars,\n",
        "    'Null':        [],\n",
        "    'Coral-only':  coral_vars,\n",
        "    'Env-only':    env_vars,\n",
        "    'Coral+Env':   coral_vars + env_vars,\n",
        "}\n",
        "\n",
        "aic_rows = []\n",
        "n = len(sub_aic)\n",
        "\n",
        "if n == 0:\n",
        "    print(\"  [SKIP] AICc: common-subset is empty.\")\n",
        "else:\n",
        "    y = sub_aic[target].values.astype(float)\n",
        "\n",
        "    for name, preds in models.items():\n",
        "        if len(preds) == 0:\n",
        "            X = np.ones((n, 1))\n",
        "        else:\n",
        "            X = sm.add_constant(sub_aic[preds], has_constant='add')\n",
        "            X = np.asarray(X, dtype=float)\n",
        "\n",
        "        k = X.shape[1]\n",
        "        if n <= k + 1:\n",
        "            print(f\"  [SKIP] {name}: too few rows for AICc (n={n}, k={k})\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            fit = sm.OLS(y, X).fit(method='qr')\n",
        "            aic = float(fit.aic)\n",
        "            aicc = aic + (2 * k * (k + 1)) / (n - k - 1)\n",
        "            aic_rows.append({\n",
        "                'Model': name,\n",
        "                'Predictors': str(preds),\n",
        "                'R2': float(fit.rsquared),\n",
        "                'Adj_R2': float(fit.rsquared_adj),\n",
        "                'AIC': aic,\n",
        "                'AICc': float(aicc),\n",
        "                'N': int(n),\n",
        "                'K': int(k)\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"  [FAIL] {name}: fit failed -> {e}\")\n",
        "\n",
        "aic_df = pd.DataFrame(aic_rows)\n",
        "if aic_df.empty:\n",
        "    print(\"  [SKIP] AICc: no models could be fit.\")\n",
        "else:\n",
        "    aic_df = aic_df.sort_values('AICc')\n",
        "    min_aicc = aic_df['AICc'].min()\n",
        "    aic_df['Delta_AICc'] = aic_df['AICc'] - min_aicc\n",
        "    aic_df['Weight'] = np.exp(-0.5 * aic_df['Delta_AICc'])\n",
        "    aic_df['Weight'] = aic_df['Weight'] / aic_df['Weight'].sum()\n",
        "    aic_df.to_csv(OUTPUT_DIR / 'results_aic_improved.csv', index=False)\n",
        "    print(\"  -> Saved results_aic_improved.csv\")\n",
        "    display(aic_df)\n",
        "\n",
        "# ---------------------------\n",
        "# 8. LOWESS (keep: derived only now that basal is removed)\n",
        "# ---------------------------\n",
        "print(\"8. LOWESS fits (derived only; 1000 boot for plotting stability/speed)...\")\n",
        "\n",
        "rng = np.random.default_rng(0)\n",
        "\n",
        "def get_lowess_ci(x, y, frac=0.6, n_boot=1000):\n",
        "    sort_idx = np.argsort(x)\n",
        "    x_sorted = x.iloc[sort_idx].values\n",
        "    y_sorted = y.iloc[sort_idx].values\n",
        "\n",
        "    z = lowess(y_sorted, x_sorted, frac=frac)\n",
        "    x_grid = z[:, 0]\n",
        "    y_fit = z[:, 1]\n",
        "\n",
        "    boot_curves = []\n",
        "    idx_all = np.arange(len(x))\n",
        "    for _ in range(n_boot):\n",
        "        idx = rng.choice(idx_all, size=len(idx_all), replace=True)\n",
        "        x_s = x.iloc[idx].values\n",
        "        y_s = y.iloc[idx].values\n",
        "        s_idx = np.argsort(x_s)\n",
        "        try:\n",
        "            z_b = lowess(y_s[s_idx], x_s[s_idx], frac=frac)\n",
        "            y_interp = np.interp(x_grid, z_b[:, 0], z_b[:, 1])\n",
        "            boot_curves.append(y_interp)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    boot_curves = np.array(boot_curves)\n",
        "    ci_low = np.nanpercentile(boot_curves, 2.5, axis=0)\n",
        "    ci_high = np.nanpercentile(boot_curves, 97.5, axis=0)\n",
        "    return pd.DataFrame({'x': x_grid, 'y_fit': y_fit, 'ci_low': ci_low, 'ci_high': ci_high})\n",
        "\n",
        "if 'derived_strom_prop' in df.columns:\n",
        "    v = df.dropna(subset=['derived_strom_prop', target]).copy()\n",
        "    v = _filter_no_strom(v)\n",
        "    low = get_lowess_ci(v['derived_strom_prop'], v[target])\n",
        "    low.to_csv(OUTPUT_DIR / 'results_lowess_derived.csv', index=False)\n",
        "    print(\"  -> Saved results_lowess_derived.csv\")\n",
        "\n",
        "# =============================================================================\n",
        "# LAG ANALYSIS (Max-|t| & |Cohen’s d|) — robust + saves outputs\n",
        "#   Outputs:\n",
        "#     - output/results_lag_summary_all_predictors.csv\n",
        "#     - output/results_lag_profile_all_predictors_long.csv\n",
        "#     - output/results_lag_profile_thickness.csv\n",
        "#   Also defines: peak_thick, peak_deriv (for segmented regression cell)\n",
        "# =============================================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_DIR = Path(\"./output\")\n",
        "OUTPUT_DIR = DATA_DIR\n",
        "\n",
        "# -------------------------\n",
        "# Ensure df exists\n",
        "# -------------------------\n",
        "if \"df\" not in globals() or df is None or not isinstance(df, pd.DataFrame) or df.empty:\n",
        "    df = pd.read_csv(DATA_DIR / \"MASTER_dataset_stage.csv\", encoding=\"utf-8-sig\")\n",
        "    print(f\"[INFO] Loaded df from MASTER_dataset_stage.csv: {len(df)} rows\")\n",
        "\n",
        "# -------------------------\n",
        "# Config\n",
        "# -------------------------\n",
        "target = \"thickness_mean\"\n",
        "AGE_MIN, AGE_MAX = 358.9, 485.4   # Ord–Dev window used previously\n",
        "MIN_BEFORE, MIN_AFTER = 3, 3\n",
        "\n",
        "# -------------------------\n",
        "# Build predictor list (use all_predictors if available; else reconstruct)\n",
        "# -------------------------\n",
        "if \"all_predictors\" in globals() and isinstance(all_predictors, (list, tuple)) and len(all_predictors) > 0:\n",
        "    predictors = [p for p in all_predictors if p in df.columns]\n",
        "else:\n",
        "    predictors = []\n",
        "    for p in [\n",
        "        \"derived_strom_prop\", \"basal_strom_prop\",\n",
        "        \"rugose_div\", \"tabulate_div\",\n",
        "        \"carbonate_area_km2\", \"temperature\", \"dissolved_O2\",\n",
        "        \"log_derived_basal_ratio\",\n",
        "        \"d13C\", \"atm_O2\", \"atm_CO2\", \"pO2\", \"pCO2\",\n",
        "        \"Labechiida_prop\", \"Clathrodictyida_prop\", \"Actinostromatida_prop\",\n",
        "        \"Stromatoporida_prop\", \"Stromatoporellida_prop\", \"Syringostromatida_prop\",\n",
        "        \"Amphiporida_prop\",\n",
        "    ]:\n",
        "        if p in df.columns:\n",
        "            predictors.append(p)\n",
        "\n",
        "# Ensure required columns exist\n",
        "needed_cols = [\"stage\", \"midpoint_ma\", \"strom_total_occ\", target]\n",
        "missing = [c for c in needed_cols if c not in df.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"Missing required columns for lag analysis: {missing}\")\n",
        "\n",
        "# -------------------------\n",
        "# Filter Ord–Dev + strom presence + required numeric\n",
        "# -------------------------\n",
        "work = df.copy()\n",
        "work[\"midpoint_ma\"] = pd.to_numeric(work[\"midpoint_ma\"], errors=\"coerce\")\n",
        "work[\"strom_total_occ\"] = pd.to_numeric(work[\"strom_total_occ\"], errors=\"coerce\")\n",
        "work[target] = pd.to_numeric(work[target], errors=\"coerce\")\n",
        "\n",
        "work = work.dropna(subset=[\"stage\", \"midpoint_ma\", \"strom_total_occ\", target]).copy()\n",
        "work = work[(work[\"midpoint_ma\"] >= AGE_MIN) & (work[\"midpoint_ma\"] <= AGE_MAX)].copy()\n",
        "work = work[work[\"strom_total_occ\"] > 0].copy()\n",
        "\n",
        "# Sort oldest->youngest (descending Ma)\n",
        "work = work.sort_values(\"midpoint_ma\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(f\"[INFO] Lag dataset after filters: n={len(work)} (Ord–Dev, strom_total_occ>0)\")\n",
        "\n",
        "def _cohen_d(before, after):\n",
        "    before = before[np.isfinite(before)]\n",
        "    after  = after[np.isfinite(after)]\n",
        "    if len(before) < 2 or len(after) < 2:\n",
        "        return np.nan\n",
        "    pooled_std = np.sqrt(((len(before)-1)*np.var(before, ddof=1) + (len(after)-1)*np.var(after, ddof=1)) /\n",
        "                         (len(before) + len(after) - 2))\n",
        "    if not np.isfinite(pooled_std) or pooled_std <= 0:\n",
        "        return np.nan\n",
        "    return (np.mean(after) - np.mean(before)) / pooled_std\n",
        "\n",
        "def lag_profile_for_var(df_sorted, var, min_before=3, min_after=3):\n",
        "    \"\"\"Return break profile rows for a single variable.\"\"\"\n",
        "    y = pd.to_numeric(df_sorted[var], errors=\"coerce\").values.astype(float)\n",
        "    ages = pd.to_numeric(df_sorted[\"midpoint_ma\"], errors=\"coerce\").values.astype(float)\n",
        "    stages = df_sorted[\"stage\"].astype(str).values\n",
        "\n",
        "    rows = []\n",
        "    n_all = len(df_sorted)\n",
        "    for i in range(min_before, n_all - min_after):\n",
        "        before = y[:i]\n",
        "        after  = y[i:]\n",
        "\n",
        "        before = before[np.isfinite(before)]\n",
        "        after  = after[np.isfinite(after)]\n",
        "\n",
        "        if len(before) >= 2 and len(after) >= 2:\n",
        "            t, p = stats.ttest_ind(before, after, equal_var=True, nan_policy=\"omit\")\n",
        "            d = _cohen_d(before, after)\n",
        "        else:\n",
        "            t, p, d = np.nan, np.nan, np.nan\n",
        "\n",
        "        rows.append({\n",
        "            \"Variable\": var,\n",
        "            \"stage\": stages[i],\n",
        "            \"age\": float(ages[i]) if np.isfinite(ages[i]) else np.nan,\n",
        "            \"n_before\": int(i),\n",
        "            \"n_after\": int(n_all - i),\n",
        "            \"t_abs\": float(np.abs(t)) if np.isfinite(t) else 0.0,\n",
        "            \"p\": float(p) if np.isfinite(p) else np.nan,\n",
        "            \"d_abs\": float(np.abs(d)) if np.isfinite(d) else 0.0\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# -------------------------\n",
        "# Compute thickness profile + peak\n",
        "# -------------------------\n",
        "prof_thick = lag_profile_for_var(work, target, MIN_BEFORE, MIN_AFTER)\n",
        "if prof_thick.empty:\n",
        "    raise RuntimeError(\"[ERROR] Thickness lag profile is empty (too few rows?)\")\n",
        "\n",
        "peak_thick = prof_thick.loc[prof_thick[\"t_abs\"].idxmax()].to_dict()\n",
        "\n",
        "# -------------------------\n",
        "# Compute predictor profiles + peaks\n",
        "# -------------------------\n",
        "profiles = [prof_thick]\n",
        "summary_rows = []\n",
        "\n",
        "peak_deriv = None  # composition changepoint\n",
        "\n",
        "for pred in predictors:\n",
        "    # skip if fully missing in this filtered dataset\n",
        "    if pred not in work.columns:\n",
        "        continue\n",
        "\n",
        "    prof = lag_profile_for_var(work, pred, MIN_BEFORE, MIN_AFTER)\n",
        "    if prof.empty:\n",
        "        continue\n",
        "\n",
        "    profiles.append(prof)\n",
        "\n",
        "    peak = prof.loc[prof[\"t_abs\"].idxmax()].to_dict()\n",
        "    lag_vs_thick = peak[\"age\"] - peak_thick[\"age\"] if np.isfinite(peak.get(\"age\", np.nan)) else np.nan\n",
        "\n",
        "    summary_rows.append({\n",
        "        \"Predictor\": pred,\n",
        "        \"Peak_Age\": peak[\"age\"],\n",
        "        \"Peak_Stage\": peak[\"stage\"],\n",
        "        \"Max_t_abs\": peak[\"t_abs\"],\n",
        "        \"Max_d_abs\": peak[\"d_abs\"],\n",
        "        \"p_at_peak\": peak[\"p\"],\n",
        "        \"Lag_vs_Thickness_Myr\": lag_vs_thick,\n",
        "        \"Thickness_Peak_Age\": peak_thick[\"age\"],\n",
        "        \"Thickness_Peak_Stage\": peak_thick[\"stage\"],\n",
        "    })\n",
        "\n",
        "    if pred == \"derived_strom_prop\":\n",
        "        peak_deriv = peak\n",
        "\n",
        "# fallback for peak_deriv (so downstream cells won't break)\n",
        "if peak_deriv is None:\n",
        "    peak_deriv = {\"age\": np.nan, \"stage\": None, \"t_abs\": np.nan, \"d_abs\": np.nan}\n",
        "\n",
        "lag_summary_df = pd.DataFrame(summary_rows).sort_values(\"Max_t_abs\", ascending=False)\n",
        "lag_profiles_long = pd.concat(profiles, ignore_index=True)\n",
        "\n",
        "# -------------------------\n",
        "# Save\n",
        "# -------------------------\n",
        "(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "lag_summary_df.to_csv(OUTPUT_DIR / \"results_lag_summary_all_predictors.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "lag_profiles_long.to_csv(OUTPUT_DIR / \"results_lag_profile_all_predictors_long.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "prof_thick.to_csv(OUTPUT_DIR / \"results_lag_profile_thickness.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"\\n[OK] Saved lag outputs:\")\n",
        "print(\"  - output/results_lag_summary_all_predictors.csv\")\n",
        "print(\"  - output/results_lag_profile_all_predictors_long.csv\")\n",
        "print(\"  - output/results_lag_profile_thickness.csv\")\n",
        "\n",
        "print(f\"\\nChangepoint (thickness):   {peak_thick['age']:.2f} Ma ({peak_thick['stage']})\")\n",
        "if np.isfinite(peak_deriv.get(\"age\", np.nan)):\n",
        "    print(f\"Changepoint (composition): {peak_deriv['age']:.2f} Ma ({peak_deriv['stage']})\")\n",
        "else:\n",
        "    print(\"Changepoint (composition): NA (derived_strom_prop not available/insufficient)\")\n",
        "\n",
        "display(lag_summary_df.head(25))\n",
        "\n",
        "\n",
        "print(\"\\n✓ CELL 14 COMPLETE (NO BASAL).\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZpjcVv1GLq1V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b8ff95f-7354-4b36-b7b0-31501c8b01a7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "CELL 14: AICc + LOWESS + LAG (NO BASAL)\n",
            "================================================================================\n",
            "7. Running AICc Model Selection (COMMON SUBSET; strom/coral/env only)...\n",
            "  Common-subset N = 21 rows\n",
            "  -> Saved results_aic_improved.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         Model                                         Predictors  \\\n",
              "0  Strom+Coral  ['derived_strom_prop', 'rugose_div', 'tabulate...   \n",
              "1   Strom-only                             ['derived_strom_prop']   \n",
              "2    Strom+Env  ['derived_strom_prop', 'carbonate_area_km2', '...   \n",
              "3         Full  ['derived_strom_prop', 'rugose_div', 'tabulate...   \n",
              "4         Null                                                 []   \n",
              "5   Coral-only                     ['rugose_div', 'tabulate_div']   \n",
              "6     Env-only  ['carbonate_area_km2', 'temperature', 'dissolv...   \n",
              "7    Coral+Env  ['rugose_div', 'tabulate_div', 'carbonate_area...   \n",
              "\n",
              "             R2        Adj_R2        AIC       AICc   N  K  Delta_AICc  \\\n",
              "0  8.039800e-01  7.693882e-01 -16.139037 -13.639037  21  4    0.000000   \n",
              "1  7.282392e-01  7.139360e-01 -13.278221 -12.611555  21  2    1.027482   \n",
              "2  7.582710e-01  6.978387e-01  -9.737422  -5.737422  21  5    7.901615   \n",
              "3  8.297055e-01  7.567222e-01 -13.093479  -4.478095  21  7    9.160942   \n",
              "4  1.110223e-16  1.110223e-16  12.081272  12.291798  21  1   25.930835   \n",
              "5  1.657233e-01  7.302591e-02  12.276278  13.688043  21  3   27.327080   \n",
              "6  1.971273e-01  5.544383e-02  13.470532  15.970532  21  4   29.609569   \n",
              "7  3.493958e-01  1.325277e-01  13.054342  19.054342  21  6   32.693379   \n",
              "\n",
              "         Weight  \n",
              "0  6.143463e-01  \n",
              "1  3.675347e-01  \n",
              "2  1.181951e-02  \n",
              "3  6.297090e-03  \n",
              "4  1.437487e-06  \n",
              "5  7.151765e-07  \n",
              "6  2.284426e-07  \n",
              "7  4.888057e-08  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec04c11b-59fd-4672-bbc2-a149dce9a85a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Predictors</th>\n",
              "      <th>R2</th>\n",
              "      <th>Adj_R2</th>\n",
              "      <th>AIC</th>\n",
              "      <th>AICc</th>\n",
              "      <th>N</th>\n",
              "      <th>K</th>\n",
              "      <th>Delta_AICc</th>\n",
              "      <th>Weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Strom+Coral</td>\n",
              "      <td>['derived_strom_prop', 'rugose_div', 'tabulate...</td>\n",
              "      <td>8.039800e-01</td>\n",
              "      <td>7.693882e-01</td>\n",
              "      <td>-16.139037</td>\n",
              "      <td>-13.639037</td>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.143463e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Strom-only</td>\n",
              "      <td>['derived_strom_prop']</td>\n",
              "      <td>7.282392e-01</td>\n",
              "      <td>7.139360e-01</td>\n",
              "      <td>-13.278221</td>\n",
              "      <td>-12.611555</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>1.027482</td>\n",
              "      <td>3.675347e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Strom+Env</td>\n",
              "      <td>['derived_strom_prop', 'carbonate_area_km2', '...</td>\n",
              "      <td>7.582710e-01</td>\n",
              "      <td>6.978387e-01</td>\n",
              "      <td>-9.737422</td>\n",
              "      <td>-5.737422</td>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>7.901615</td>\n",
              "      <td>1.181951e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Full</td>\n",
              "      <td>['derived_strom_prop', 'rugose_div', 'tabulate...</td>\n",
              "      <td>8.297055e-01</td>\n",
              "      <td>7.567222e-01</td>\n",
              "      <td>-13.093479</td>\n",
              "      <td>-4.478095</td>\n",
              "      <td>21</td>\n",
              "      <td>7</td>\n",
              "      <td>9.160942</td>\n",
              "      <td>6.297090e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Null</td>\n",
              "      <td>[]</td>\n",
              "      <td>1.110223e-16</td>\n",
              "      <td>1.110223e-16</td>\n",
              "      <td>12.081272</td>\n",
              "      <td>12.291798</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>25.930835</td>\n",
              "      <td>1.437487e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Coral-only</td>\n",
              "      <td>['rugose_div', 'tabulate_div']</td>\n",
              "      <td>1.657233e-01</td>\n",
              "      <td>7.302591e-02</td>\n",
              "      <td>12.276278</td>\n",
              "      <td>13.688043</td>\n",
              "      <td>21</td>\n",
              "      <td>3</td>\n",
              "      <td>27.327080</td>\n",
              "      <td>7.151765e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Env-only</td>\n",
              "      <td>['carbonate_area_km2', 'temperature', 'dissolv...</td>\n",
              "      <td>1.971273e-01</td>\n",
              "      <td>5.544383e-02</td>\n",
              "      <td>13.470532</td>\n",
              "      <td>15.970532</td>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>29.609569</td>\n",
              "      <td>2.284426e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Coral+Env</td>\n",
              "      <td>['rugose_div', 'tabulate_div', 'carbonate_area...</td>\n",
              "      <td>3.493958e-01</td>\n",
              "      <td>1.325277e-01</td>\n",
              "      <td>13.054342</td>\n",
              "      <td>19.054342</td>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "      <td>32.693379</td>\n",
              "      <td>4.888057e-08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec04c11b-59fd-4672-bbc2-a149dce9a85a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ec04c11b-59fd-4672-bbc2-a149dce9a85a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ec04c11b-59fd-4672-bbc2-a149dce9a85a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_1eb9ed36-f019-481e-90df-42bcc313bdf0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('aic_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1eb9ed36-f019-481e-90df-42bcc313bdf0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('aic_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "aic_df",
              "summary": "{\n  \"name\": \"aic_df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Strom-only\",\n          \"Coral-only\",\n          \"Strom+Coral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predictors\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"['derived_strom_prop']\",\n          \"['rugose_div', 'tabulate_div']\",\n          \"['derived_strom_prop', 'rugose_div', 'tabulate_div']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3364842519505228,\n        \"min\": 1.1102230246251565e-16,\n        \"max\": 0.8297055457121829,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.7282392017551722,\n          0.16572331968732867,\n          0.8039799891102314\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adj_R2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.36018533985258944,\n        \"min\": 1.1102230246251565e-16,\n        \"max\": 0.7693882224826252,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.7139360018475497,\n          0.07302591076369847,\n          0.7693882224826252\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AIC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.89418341927732,\n        \"min\": -16.139037068427996,\n        \"max\": 13.4705318841186,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -13.278221342300242,\n          12.276278237904165,\n          -16.139037068427996\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AICc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.519059286824383,\n        \"min\": -13.639037068427996,\n        \"max\": 19.054341816996825,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -12.611554675633576,\n          13.688042943786519,\n          -13.639037068427996\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 21,\n        \"max\": 21,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"K\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 7,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Delta_AICc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.519059286824383,\n        \"min\": 0.0,\n        \"max\": 32.69337888542482,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.02748239279442\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23533637757200826,\n        \"min\": 4.888056729271784e-08,\n        \"max\": 0.6143463182455061,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.36753465332589225\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8. LOWESS fits (derived only; 1000 boot for plotting stability/speed)...\n",
            "  -> Saved results_lowess_derived.csv\n",
            "[INFO] Lag dataset after filters: n=21 (Ord–Dev, strom_total_occ>0)\n",
            "\n",
            "[OK] Saved lag outputs:\n",
            "  - output/results_lag_summary_all_predictors.csv\n",
            "  - output/results_lag_profile_all_predictors_long.csv\n",
            "  - output/results_lag_profile_thickness.csv\n",
            "\n",
            "Changepoint (thickness):   426.50 Ma (Gorstian)\n",
            "Changepoint (composition): 431.95 Ma (Sheinwoodian)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                 Predictor  Peak_Age    Peak_Stage  Max_t_abs  Max_d_abs  \\\n",
              "19         Labechiida_prop    444.50    Hirnantian  17.523005   8.977868   \n",
              "1         basal_strom_prop    431.95  Sheinwoodian   9.514933   4.195691   \n",
              "0       derived_strom_prop    431.95  Sheinwoodian   9.514933   4.195691   \n",
              "23  Stromatoporellida_prop    400.45        Emsian   7.150752   3.663670   \n",
              "15                 atm_CO2    390.50      Eifelian   6.970991   3.873912   \n",
              "11             temperature    455.70      Sandbian   5.758257   3.590904   \n",
              "21   Actinostromatida_prop    435.95     Telychian   5.623248   2.526855   \n",
              "22     Stromatoporida_prop    431.95  Sheinwoodian   5.200166   2.293058   \n",
              "25        Amphiporida_prop    424.30    Ludfordian   5.149704   2.270806   \n",
              "4        derived_strom_div    428.95      Homerian   4.677870   2.043909   \n",
              "2        derived_strom_occ    400.45        Emsian   4.558234   2.335400   \n",
              "12            dissolved_O2    449.10        Katian   4.059576   2.255983   \n",
              "17    carbonate_percentage    421.10       Pridoli   3.994995   1.795185   \n",
              "6               rugose_occ    400.45        Emsian   3.919634   2.008215   \n",
              "18               sea_level    415.00    Lochkovian   3.848877   1.781684   \n",
              "8               rugose_div    400.45        Emsian   3.843866   1.969395   \n",
              "13                    d13C    444.50    Hirnantian   3.314334   1.698091   \n",
              "9             tabulate_div    455.70      Sandbian   3.189720   1.989140   \n",
              "24  Syringostromatida_prop    415.00    Lochkovian   3.082546   1.426942   \n",
              "14                  atm_O2    444.50    Hirnantian   3.080434   1.578253   \n",
              "20    Clathrodictyida_prop    449.10        Katian   2.610065   1.450463   \n",
              "7             tabulate_occ    400.45        Emsian   2.504948   1.283404   \n",
              "10      carbonate_area_km2    444.50    Hirnantian   2.313268   1.185197   \n",
              "5          basal_strom_div    455.70      Sandbian   2.274144   1.418178   \n",
              "3          basal_strom_occ    426.50      Gorstian   2.115929   0.924516   \n",
              "\n",
              "       p_at_peak  Lag_vs_Thickness_Myr  Thickness_Peak_Age  \\\n",
              "19  3.471399e-13                 18.00               426.5   \n",
              "1   1.165251e-08                  5.45               426.5   \n",
              "0   1.165251e-08                  5.45               426.5   \n",
              "23  8.510268e-07                -26.05               426.5   \n",
              "15  1.215429e-06                -36.00               426.5   \n",
              "11  1.505465e-05                 29.20               426.5   \n",
              "21  2.015312e-05                  9.45               426.5   \n",
              "22  5.094031e-05                  5.45               426.5   \n",
              "25  5.696891e-05                 -2.20               426.5   \n",
              "4   1.639099e-04                  2.45               426.5   \n",
              "2   2.148542e-04                -26.05               426.5   \n",
              "12  6.687131e-04                 22.60               426.5   \n",
              "17  7.750015e-04                 -5.40               426.5   \n",
              "6   9.205867e-04                -26.05               426.5   \n",
              "18  1.082043e-03                -11.50               426.5   \n",
              "8   1.094495e-03                -26.05               426.5   \n",
              "13  3.645673e-03                 18.00               426.5   \n",
              "9   4.824055e-03                 29.20               426.5   \n",
              "24  6.128849e-03                -11.50               426.5   \n",
              "14  6.157735e-03                 18.00               426.5   \n",
              "20  1.721135e-02                 22.60               426.5   \n",
              "7   2.151475e-02                -26.05               426.5   \n",
              "10  3.206781e-02                 18.00               426.5   \n",
              "5   3.474195e-02                 29.20               426.5   \n",
              "3   4.778074e-02                  0.00               426.5   \n",
              "\n",
              "   Thickness_Peak_Stage  \n",
              "19             Gorstian  \n",
              "1              Gorstian  \n",
              "0              Gorstian  \n",
              "23             Gorstian  \n",
              "15             Gorstian  \n",
              "11             Gorstian  \n",
              "21             Gorstian  \n",
              "22             Gorstian  \n",
              "25             Gorstian  \n",
              "4              Gorstian  \n",
              "2              Gorstian  \n",
              "12             Gorstian  \n",
              "17             Gorstian  \n",
              "6              Gorstian  \n",
              "18             Gorstian  \n",
              "8              Gorstian  \n",
              "13             Gorstian  \n",
              "9              Gorstian  \n",
              "24             Gorstian  \n",
              "14             Gorstian  \n",
              "20             Gorstian  \n",
              "7              Gorstian  \n",
              "10             Gorstian  \n",
              "5              Gorstian  \n",
              "3              Gorstian  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28c6e456-6d57-4298-aa01-db7b3f79a11e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predictor</th>\n",
              "      <th>Peak_Age</th>\n",
              "      <th>Peak_Stage</th>\n",
              "      <th>Max_t_abs</th>\n",
              "      <th>Max_d_abs</th>\n",
              "      <th>p_at_peak</th>\n",
              "      <th>Lag_vs_Thickness_Myr</th>\n",
              "      <th>Thickness_Peak_Age</th>\n",
              "      <th>Thickness_Peak_Stage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Labechiida_prop</td>\n",
              "      <td>444.50</td>\n",
              "      <td>Hirnantian</td>\n",
              "      <td>17.523005</td>\n",
              "      <td>8.977868</td>\n",
              "      <td>3.471399e-13</td>\n",
              "      <td>18.00</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>basal_strom_prop</td>\n",
              "      <td>431.95</td>\n",
              "      <td>Sheinwoodian</td>\n",
              "      <td>9.514933</td>\n",
              "      <td>4.195691</td>\n",
              "      <td>1.165251e-08</td>\n",
              "      <td>5.45</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>derived_strom_prop</td>\n",
              "      <td>431.95</td>\n",
              "      <td>Sheinwoodian</td>\n",
              "      <td>9.514933</td>\n",
              "      <td>4.195691</td>\n",
              "      <td>1.165251e-08</td>\n",
              "      <td>5.45</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Stromatoporellida_prop</td>\n",
              "      <td>400.45</td>\n",
              "      <td>Emsian</td>\n",
              "      <td>7.150752</td>\n",
              "      <td>3.663670</td>\n",
              "      <td>8.510268e-07</td>\n",
              "      <td>-26.05</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>atm_CO2</td>\n",
              "      <td>390.50</td>\n",
              "      <td>Eifelian</td>\n",
              "      <td>6.970991</td>\n",
              "      <td>3.873912</td>\n",
              "      <td>1.215429e-06</td>\n",
              "      <td>-36.00</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>temperature</td>\n",
              "      <td>455.70</td>\n",
              "      <td>Sandbian</td>\n",
              "      <td>5.758257</td>\n",
              "      <td>3.590904</td>\n",
              "      <td>1.505465e-05</td>\n",
              "      <td>29.20</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Actinostromatida_prop</td>\n",
              "      <td>435.95</td>\n",
              "      <td>Telychian</td>\n",
              "      <td>5.623248</td>\n",
              "      <td>2.526855</td>\n",
              "      <td>2.015312e-05</td>\n",
              "      <td>9.45</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Stromatoporida_prop</td>\n",
              "      <td>431.95</td>\n",
              "      <td>Sheinwoodian</td>\n",
              "      <td>5.200166</td>\n",
              "      <td>2.293058</td>\n",
              "      <td>5.094031e-05</td>\n",
              "      <td>5.45</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Amphiporida_prop</td>\n",
              "      <td>424.30</td>\n",
              "      <td>Ludfordian</td>\n",
              "      <td>5.149704</td>\n",
              "      <td>2.270806</td>\n",
              "      <td>5.696891e-05</td>\n",
              "      <td>-2.20</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>derived_strom_div</td>\n",
              "      <td>428.95</td>\n",
              "      <td>Homerian</td>\n",
              "      <td>4.677870</td>\n",
              "      <td>2.043909</td>\n",
              "      <td>1.639099e-04</td>\n",
              "      <td>2.45</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>derived_strom_occ</td>\n",
              "      <td>400.45</td>\n",
              "      <td>Emsian</td>\n",
              "      <td>4.558234</td>\n",
              "      <td>2.335400</td>\n",
              "      <td>2.148542e-04</td>\n",
              "      <td>-26.05</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>dissolved_O2</td>\n",
              "      <td>449.10</td>\n",
              "      <td>Katian</td>\n",
              "      <td>4.059576</td>\n",
              "      <td>2.255983</td>\n",
              "      <td>6.687131e-04</td>\n",
              "      <td>22.60</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>carbonate_percentage</td>\n",
              "      <td>421.10</td>\n",
              "      <td>Pridoli</td>\n",
              "      <td>3.994995</td>\n",
              "      <td>1.795185</td>\n",
              "      <td>7.750015e-04</td>\n",
              "      <td>-5.40</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>rugose_occ</td>\n",
              "      <td>400.45</td>\n",
              "      <td>Emsian</td>\n",
              "      <td>3.919634</td>\n",
              "      <td>2.008215</td>\n",
              "      <td>9.205867e-04</td>\n",
              "      <td>-26.05</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>sea_level</td>\n",
              "      <td>415.00</td>\n",
              "      <td>Lochkovian</td>\n",
              "      <td>3.848877</td>\n",
              "      <td>1.781684</td>\n",
              "      <td>1.082043e-03</td>\n",
              "      <td>-11.50</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>rugose_div</td>\n",
              "      <td>400.45</td>\n",
              "      <td>Emsian</td>\n",
              "      <td>3.843866</td>\n",
              "      <td>1.969395</td>\n",
              "      <td>1.094495e-03</td>\n",
              "      <td>-26.05</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>d13C</td>\n",
              "      <td>444.50</td>\n",
              "      <td>Hirnantian</td>\n",
              "      <td>3.314334</td>\n",
              "      <td>1.698091</td>\n",
              "      <td>3.645673e-03</td>\n",
              "      <td>18.00</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>tabulate_div</td>\n",
              "      <td>455.70</td>\n",
              "      <td>Sandbian</td>\n",
              "      <td>3.189720</td>\n",
              "      <td>1.989140</td>\n",
              "      <td>4.824055e-03</td>\n",
              "      <td>29.20</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Syringostromatida_prop</td>\n",
              "      <td>415.00</td>\n",
              "      <td>Lochkovian</td>\n",
              "      <td>3.082546</td>\n",
              "      <td>1.426942</td>\n",
              "      <td>6.128849e-03</td>\n",
              "      <td>-11.50</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>atm_O2</td>\n",
              "      <td>444.50</td>\n",
              "      <td>Hirnantian</td>\n",
              "      <td>3.080434</td>\n",
              "      <td>1.578253</td>\n",
              "      <td>6.157735e-03</td>\n",
              "      <td>18.00</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Clathrodictyida_prop</td>\n",
              "      <td>449.10</td>\n",
              "      <td>Katian</td>\n",
              "      <td>2.610065</td>\n",
              "      <td>1.450463</td>\n",
              "      <td>1.721135e-02</td>\n",
              "      <td>22.60</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>tabulate_occ</td>\n",
              "      <td>400.45</td>\n",
              "      <td>Emsian</td>\n",
              "      <td>2.504948</td>\n",
              "      <td>1.283404</td>\n",
              "      <td>2.151475e-02</td>\n",
              "      <td>-26.05</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>carbonate_area_km2</td>\n",
              "      <td>444.50</td>\n",
              "      <td>Hirnantian</td>\n",
              "      <td>2.313268</td>\n",
              "      <td>1.185197</td>\n",
              "      <td>3.206781e-02</td>\n",
              "      <td>18.00</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>basal_strom_div</td>\n",
              "      <td>455.70</td>\n",
              "      <td>Sandbian</td>\n",
              "      <td>2.274144</td>\n",
              "      <td>1.418178</td>\n",
              "      <td>3.474195e-02</td>\n",
              "      <td>29.20</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basal_strom_occ</td>\n",
              "      <td>426.50</td>\n",
              "      <td>Gorstian</td>\n",
              "      <td>2.115929</td>\n",
              "      <td>0.924516</td>\n",
              "      <td>4.778074e-02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>426.5</td>\n",
              "      <td>Gorstian</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28c6e456-6d57-4298-aa01-db7b3f79a11e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28c6e456-6d57-4298-aa01-db7b3f79a11e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28c6e456-6d57-4298-aa01-db7b3f79a11e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\n\\u2713 CELL 14 COMPLETE (NO BASAL)\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"Predictor\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"Amphiporida_prop\",\n          \"d13C\",\n          \"Labechiida_prop\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Peak_Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.40725708336784,\n        \"min\": 390.5,\n        \"max\": 455.7,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          415.0,\n          421.1,\n          444.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Peak_Stage\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"Lochkovian\",\n          \"Pridoli\",\n          \"Hirnantian\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Max_t_abs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.3009596747967853,\n        \"min\": 2.1159286495004896,\n        \"max\": 17.52300496023834,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          5.149703592729095,\n          3.3143339497883666,\n          17.52300496023834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Max_d_abs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6449163586614477,\n        \"min\": 0.9245157702834903,\n        \"max\": 8.977868454961405,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          2.043908555308027,\n          1.9891401112137252,\n          8.977868454961405\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p_at_peak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013086625935997635,\n        \"min\": 3.471399309194109e-13,\n        \"max\": 0.047780739797230985,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          5.696890743630203e-05,\n          0.003645673070927021,\n          3.471399309194109e-13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lag_vs_Thickness_Myr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.40725708336784,\n        \"min\": -36.0,\n        \"max\": 29.19999999999999,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          -11.5,\n          -5.399999999999977,\n          18.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Thickness_Peak_Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 426.5,\n        \"max\": 426.5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          426.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Thickness_Peak_Stage\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Gorstian\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ CELL 14 COMPLETE (NO BASAL).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "cellView": "form",
        "id": "289ac04c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8739596-cfb4-485c-a859-b19aab0478ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running segmented regression at thickness CP = 426.5 Ma...\n",
            "Running segmented regression at composition CP = 431.9 Ma...\n",
            "Saved: output/results_segmented_regression.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      Model          Target  Changepoint_Ma          Term      Coef        SE  \\\n",
              "0   OLS+HAC  thickness_mean          426.50         const  4.437553  1.963271   \n",
              "1   OLS+HAC  thickness_mean          426.50          time -0.006305  0.004040   \n",
              "2   OLS+HAC  thickness_mean          426.50          step  0.267077  0.103465   \n",
              "3   OLS+HAC  thickness_mean          426.50    post_slope -0.007805  0.003683   \n",
              "4   OLS+HAC  thickness_mean          426.50  derived_prop  0.226117  0.238352   \n",
              "5   OLS+HAC  thickness_mean          426.50      sampling -0.011693  0.032358   \n",
              "6   WLS+HAC  thickness_mean          426.50         const  4.438575  1.605677   \n",
              "7   WLS+HAC  thickness_mean          426.50          time -0.006293  0.003329   \n",
              "8   WLS+HAC  thickness_mean          426.50          step  0.252720  0.111388   \n",
              "9   WLS+HAC  thickness_mean          426.50    post_slope -0.008940  0.003298   \n",
              "10  WLS+HAC  thickness_mean          426.50  derived_prop  0.320467  0.227413   \n",
              "11  WLS+HAC  thickness_mean          426.50      sampling -0.017337  0.021239   \n",
              "12    GLSAR  thickness_mean          426.50         const  4.678245  1.814229   \n",
              "13    GLSAR  thickness_mean          426.50          time -0.006918  0.003828   \n",
              "14    GLSAR  thickness_mean          426.50          step  0.332067  0.134623   \n",
              "15    GLSAR  thickness_mean          426.50    post_slope -0.007702  0.003311   \n",
              "16    GLSAR  thickness_mean          426.50  derived_prop  0.097316  0.234248   \n",
              "17    GLSAR  thickness_mean          426.50      sampling -0.002235  0.027610   \n",
              "18  OLS+HAC  thickness_mean          431.95         const  4.913854  1.486159   \n",
              "19  OLS+HAC  thickness_mean          431.95          time -0.007291  0.003096   \n",
              "20  OLS+HAC  thickness_mean          431.95          step -0.119427  0.114253   \n",
              "21  OLS+HAC  thickness_mean          431.95    post_slope -0.007885  0.003746   \n",
              "22  OLS+HAC  thickness_mean          431.95  derived_prop  0.693046  0.200957   \n",
              "23  OLS+HAC  thickness_mean          431.95      sampling -0.019315  0.022118   \n",
              "24  WLS+HAC  thickness_mean          431.95         const  4.579993  1.147702   \n",
              "25  WLS+HAC  thickness_mean          431.95          time -0.006606  0.002397   \n",
              "26  WLS+HAC  thickness_mean          431.95          step -0.090380  0.138155   \n",
              "27  WLS+HAC  thickness_mean          431.95    post_slope -0.008128  0.003005   \n",
              "28  WLS+HAC  thickness_mean          431.95  derived_prop  0.716334  0.184522   \n",
              "29  WLS+HAC  thickness_mean          431.95      sampling -0.015122  0.014159   \n",
              "30    GLSAR  thickness_mean          431.95         const  5.251776  2.566636   \n",
              "31    GLSAR  thickness_mean          431.95          time -0.008089  0.005491   \n",
              "32    GLSAR  thickness_mean          431.95          step -0.120271  0.192591   \n",
              "33    GLSAR  thickness_mean          431.95    post_slope -0.008506  0.005344   \n",
              "34    GLSAR  thickness_mean          431.95  derived_prop  0.674613  0.293239   \n",
              "35    GLSAR  thickness_mean          431.95      sampling -0.015599  0.032073   \n",
              "\n",
              "           P   N        R2      CP_type  \n",
              "0   0.039107  21  0.800573    Thickness  \n",
              "1   0.139493  21  0.800573    Thickness  \n",
              "2   0.020860  21  0.800573    Thickness  \n",
              "3   0.051189  21  0.800573    Thickness  \n",
              "4   0.357823  21  0.800573    Thickness  \n",
              "5   0.722855  21  0.800573    Thickness  \n",
              "6   0.014464  21  0.891673    Thickness  \n",
              "7   0.078221  21  0.891673    Thickness  \n",
              "8   0.038469  21  0.891673    Thickness  \n",
              "9   0.016109  21  0.891673    Thickness  \n",
              "10  0.179173  21  0.891673    Thickness  \n",
              "11  0.427112  21  0.891673    Thickness  \n",
              "12  0.021867  21  0.903397    Thickness  \n",
              "13  0.092236  21  0.903397    Thickness  \n",
              "14  0.027159  21  0.903397    Thickness  \n",
              "15  0.035514  21  0.903397    Thickness  \n",
              "16  0.684118  21  0.903397    Thickness  \n",
              "17  0.936616  21  0.903397    Thickness  \n",
              "18  0.004795  21  0.767484  Composition  \n",
              "19  0.032554  21  0.767484  Composition  \n",
              "20  0.312445  21  0.767484  Composition  \n",
              "21  0.052570  21  0.767484  Composition  \n",
              "22  0.003581  21  0.767484  Composition  \n",
              "23  0.396284  21  0.767484  Composition  \n",
              "24  0.001182  21  0.870922  Composition  \n",
              "25  0.014725  21  0.870922  Composition  \n",
              "26  0.522894  21  0.870922  Composition  \n",
              "27  0.016310  21  0.870922  Composition  \n",
              "28  0.001474  21  0.870922  Composition  \n",
              "29  0.302411  21  0.870922  Composition  \n",
              "30  0.060000  21  0.807467  Composition  \n",
              "31  0.162856  21  0.807467  Composition  \n",
              "32  0.542352  21  0.807467  Composition  \n",
              "33  0.133792  21  0.807467  Composition  \n",
              "34  0.037311  21  0.807467  Composition  \n",
              "35  0.634232  21  0.807467  Composition  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-423e6db8-1cd9-481f-af54-f021ee46badf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Target</th>\n",
              "      <th>Changepoint_Ma</th>\n",
              "      <th>Term</th>\n",
              "      <th>Coef</th>\n",
              "      <th>SE</th>\n",
              "      <th>P</th>\n",
              "      <th>N</th>\n",
              "      <th>R2</th>\n",
              "      <th>CP_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>426.50</td>\n",
              "      <td>const</td>\n",
              "      <td>4.437553</td>\n",
              "      <td>1.963271</td>\n",
              "      <td>0.039107</td>\n",
              "      <td>21</td>\n",
              "      <td>0.800573</td>\n",
              "      <td>Thickness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>426.50</td>\n",
              "      <td>time</td>\n",
              "      <td>-0.006305</td>\n",
              "      <td>0.004040</td>\n",
              "      <td>0.139493</td>\n",
              "      <td>21</td>\n",
              "      <td>0.800573</td>\n",
              "      <td>Thickness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>OLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>426.50</td>\n",
              "      <td>step</td>\n",
              "      <td>0.267077</td>\n",
              "      <td>0.103465</td>\n",
              "      <td>0.020860</td>\n",
              "      <td>21</td>\n",
              "      <td>0.800573</td>\n",
              "      <td>Thickness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>426.50</td>\n",
              "      <td>post_slope</td>\n",
              "      <td>-0.007805</td>\n",
              "      <td>0.003683</td>\n",
              "      <td>0.051189</td>\n",
              "      <td>21</td>\n",
              "      <td>0.800573</td>\n",
              "      <td>Thickness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>426.50</td>\n",
              "      <td>derived_prop</td>\n",
              "      <td>0.226117</td>\n",
              "      <td>0.238352</td>\n",
              "      <td>0.357823</td>\n",
              "      <td>21</td>\n",
              "      <td>0.800573</td>\n",
              "      <td>Thickness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>OLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>426.50</td>\n",
              "      <td>sampling</td>\n",
              "      <td>-0.011693</td>\n",
              "      <td>0.032358</td>\n",
              "      <td>0.722855</td>\n",
              "      <td>21</td>\n",
              "      <td>0.800573</td>\n",
              "      <td>Thickness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>WLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>426.50</td>\n",
              "      <td>const</td>\n",
              "      <td>4.438575</td>\n",
              "      <td>1.605677</td>\n",
              "      <td>0.014464</td>\n",
              "      <td>21</td>\n",
              "      <td>0.891673</td>\n",
              "      <td>Thickness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>WLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>426.50</td>\n",
              "      <td>time</td>\n",
              "      <td>-0.006293</td>\n",
              "      <td>0.003329</td>\n",
              "      <td>0.078221</td>\n",
              "      <td>21</td>\n",
              "      <td>0.891673</td>\n",
              "      <td>Thickness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>WLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>426.50</td>\n",
              "      <td>step</td>\n",
              "      <td>0.252720</td>\n",
              "      <td>0.111388</td>\n",
              "      <td>0.038469</td>\n",
              "      <td>21</td>\n",
              "      <td>0.891673</td>\n",
              "      <td>Thickness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>WLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>426.50</td>\n",
              "      <td>post_slope</td>\n",
              "      <td>-0.008940</td>\n",
              "      <td>0.003298</td>\n",
              "      <td>0.016109</td>\n",
              "      <td>21</td>\n",
              "      <td>0.891673</td>\n",
              "      <td>Thickness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>WLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>426.50</td>\n",
              "      <td>derived_prop</td>\n",
              "      <td>0.320467</td>\n",
              "      <td>0.227413</td>\n",
              "      <td>0.179173</td>\n",
              "      <td>21</td>\n",
              "      <td>0.891673</td>\n",
              "      <td>Thickness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>WLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>426.50</td>\n",
              "      <td>sampling</td>\n",
              "      <td>-0.017337</td>\n",
              "      <td>0.021239</td>\n",
              "      <td>0.427112</td>\n",
              "      <td>21</td>\n",
              "      <td>0.891673</td>\n",
              "      <td>Thickness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>GLSAR</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>426.50</td>\n",
              "      <td>const</td>\n",
              "      <td>4.678245</td>\n",
              "      <td>1.814229</td>\n",
              "      <td>0.021867</td>\n",
              "      <td>21</td>\n",
              "      <td>0.903397</td>\n",
              "      <td>Thickness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>GLSAR</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>426.50</td>\n",
              "      <td>time</td>\n",
              "      <td>-0.006918</td>\n",
              "      <td>0.003828</td>\n",
              "      <td>0.092236</td>\n",
              "      <td>21</td>\n",
              "      <td>0.903397</td>\n",
              "      <td>Thickness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>GLSAR</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>426.50</td>\n",
              "      <td>step</td>\n",
              "      <td>0.332067</td>\n",
              "      <td>0.134623</td>\n",
              "      <td>0.027159</td>\n",
              "      <td>21</td>\n",
              "      <td>0.903397</td>\n",
              "      <td>Thickness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>GLSAR</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>426.50</td>\n",
              "      <td>post_slope</td>\n",
              "      <td>-0.007702</td>\n",
              "      <td>0.003311</td>\n",
              "      <td>0.035514</td>\n",
              "      <td>21</td>\n",
              "      <td>0.903397</td>\n",
              "      <td>Thickness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>GLSAR</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>426.50</td>\n",
              "      <td>derived_prop</td>\n",
              "      <td>0.097316</td>\n",
              "      <td>0.234248</td>\n",
              "      <td>0.684118</td>\n",
              "      <td>21</td>\n",
              "      <td>0.903397</td>\n",
              "      <td>Thickness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>GLSAR</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>426.50</td>\n",
              "      <td>sampling</td>\n",
              "      <td>-0.002235</td>\n",
              "      <td>0.027610</td>\n",
              "      <td>0.936616</td>\n",
              "      <td>21</td>\n",
              "      <td>0.903397</td>\n",
              "      <td>Thickness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>OLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>431.95</td>\n",
              "      <td>const</td>\n",
              "      <td>4.913854</td>\n",
              "      <td>1.486159</td>\n",
              "      <td>0.004795</td>\n",
              "      <td>21</td>\n",
              "      <td>0.767484</td>\n",
              "      <td>Composition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>OLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>431.95</td>\n",
              "      <td>time</td>\n",
              "      <td>-0.007291</td>\n",
              "      <td>0.003096</td>\n",
              "      <td>0.032554</td>\n",
              "      <td>21</td>\n",
              "      <td>0.767484</td>\n",
              "      <td>Composition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>OLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>431.95</td>\n",
              "      <td>step</td>\n",
              "      <td>-0.119427</td>\n",
              "      <td>0.114253</td>\n",
              "      <td>0.312445</td>\n",
              "      <td>21</td>\n",
              "      <td>0.767484</td>\n",
              "      <td>Composition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>OLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>431.95</td>\n",
              "      <td>post_slope</td>\n",
              "      <td>-0.007885</td>\n",
              "      <td>0.003746</td>\n",
              "      <td>0.052570</td>\n",
              "      <td>21</td>\n",
              "      <td>0.767484</td>\n",
              "      <td>Composition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>OLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>431.95</td>\n",
              "      <td>derived_prop</td>\n",
              "      <td>0.693046</td>\n",
              "      <td>0.200957</td>\n",
              "      <td>0.003581</td>\n",
              "      <td>21</td>\n",
              "      <td>0.767484</td>\n",
              "      <td>Composition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>OLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>431.95</td>\n",
              "      <td>sampling</td>\n",
              "      <td>-0.019315</td>\n",
              "      <td>0.022118</td>\n",
              "      <td>0.396284</td>\n",
              "      <td>21</td>\n",
              "      <td>0.767484</td>\n",
              "      <td>Composition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>WLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>431.95</td>\n",
              "      <td>const</td>\n",
              "      <td>4.579993</td>\n",
              "      <td>1.147702</td>\n",
              "      <td>0.001182</td>\n",
              "      <td>21</td>\n",
              "      <td>0.870922</td>\n",
              "      <td>Composition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>WLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>431.95</td>\n",
              "      <td>time</td>\n",
              "      <td>-0.006606</td>\n",
              "      <td>0.002397</td>\n",
              "      <td>0.014725</td>\n",
              "      <td>21</td>\n",
              "      <td>0.870922</td>\n",
              "      <td>Composition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>WLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>431.95</td>\n",
              "      <td>step</td>\n",
              "      <td>-0.090380</td>\n",
              "      <td>0.138155</td>\n",
              "      <td>0.522894</td>\n",
              "      <td>21</td>\n",
              "      <td>0.870922</td>\n",
              "      <td>Composition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>WLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>431.95</td>\n",
              "      <td>post_slope</td>\n",
              "      <td>-0.008128</td>\n",
              "      <td>0.003005</td>\n",
              "      <td>0.016310</td>\n",
              "      <td>21</td>\n",
              "      <td>0.870922</td>\n",
              "      <td>Composition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>WLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>431.95</td>\n",
              "      <td>derived_prop</td>\n",
              "      <td>0.716334</td>\n",
              "      <td>0.184522</td>\n",
              "      <td>0.001474</td>\n",
              "      <td>21</td>\n",
              "      <td>0.870922</td>\n",
              "      <td>Composition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>WLS+HAC</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>431.95</td>\n",
              "      <td>sampling</td>\n",
              "      <td>-0.015122</td>\n",
              "      <td>0.014159</td>\n",
              "      <td>0.302411</td>\n",
              "      <td>21</td>\n",
              "      <td>0.870922</td>\n",
              "      <td>Composition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>GLSAR</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>431.95</td>\n",
              "      <td>const</td>\n",
              "      <td>5.251776</td>\n",
              "      <td>2.566636</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>21</td>\n",
              "      <td>0.807467</td>\n",
              "      <td>Composition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>GLSAR</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>431.95</td>\n",
              "      <td>time</td>\n",
              "      <td>-0.008089</td>\n",
              "      <td>0.005491</td>\n",
              "      <td>0.162856</td>\n",
              "      <td>21</td>\n",
              "      <td>0.807467</td>\n",
              "      <td>Composition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>GLSAR</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>431.95</td>\n",
              "      <td>step</td>\n",
              "      <td>-0.120271</td>\n",
              "      <td>0.192591</td>\n",
              "      <td>0.542352</td>\n",
              "      <td>21</td>\n",
              "      <td>0.807467</td>\n",
              "      <td>Composition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>GLSAR</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>431.95</td>\n",
              "      <td>post_slope</td>\n",
              "      <td>-0.008506</td>\n",
              "      <td>0.005344</td>\n",
              "      <td>0.133792</td>\n",
              "      <td>21</td>\n",
              "      <td>0.807467</td>\n",
              "      <td>Composition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>GLSAR</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>431.95</td>\n",
              "      <td>derived_prop</td>\n",
              "      <td>0.674613</td>\n",
              "      <td>0.293239</td>\n",
              "      <td>0.037311</td>\n",
              "      <td>21</td>\n",
              "      <td>0.807467</td>\n",
              "      <td>Composition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>GLSAR</td>\n",
              "      <td>thickness_mean</td>\n",
              "      <td>431.95</td>\n",
              "      <td>sampling</td>\n",
              "      <td>-0.015599</td>\n",
              "      <td>0.032073</td>\n",
              "      <td>0.634232</td>\n",
              "      <td>21</td>\n",
              "      <td>0.807467</td>\n",
              "      <td>Composition</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-423e6db8-1cd9-481f-af54-f021ee46badf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-423e6db8-1cd9-481f-af54-f021ee46badf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-423e6db8-1cd9-481f-af54-f021ee46badf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_1f96972e-b628-4ff3-88aa-817daa9e4dad\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('seg_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1f96972e-b628-4ff3-88aa-817daa9e4dad button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('seg_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "seg_df",
              "summary": "{\n  \"name\": \"seg_df\",\n  \"rows\": 36,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"OLS+HAC\",\n          \"WLS+HAC\",\n          \"GLSAR\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"thickness_mean\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Changepoint_Ma\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.7636544129622433,\n        \"min\": 426.5,\n        \"max\": 431.95,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          431.95\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Term\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"const\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coef\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7609184782205283,\n        \"min\": -0.12027071728276276,\n        \"max\": 5.251776018736043,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          -0.01559946570689047\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6679794990416281,\n        \"min\": 0.0023974996751988517,\n        \"max\": 2.5666359505437204,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          0.032073443145854544\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"P\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.251695337586876,\n        \"min\": 0.0011817551031829687,\n        \"max\": 0.9366156915255367,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          0.6342321308819062\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 21,\n        \"max\": 21,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05157484502971011,\n        \"min\": 0.7674839528623132,\n        \"max\": 0.9033968726052056,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.8005727329697789\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CP_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Composition\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# @title CELL 15: TIME-SERIES-ROBUST TESTS (Segmented regression + sampling control)\n",
        "# =============================================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.regression.linear_model import OLS, GLSAR\n",
        "from statsmodels.stats.sandwich_covariance import cov_hac\n",
        "\n",
        "def _as_1d_numeric(v):\n",
        "    \"\"\"Force Series/DataFrame column to 1-D numeric float array.\"\"\"\n",
        "    if isinstance(v, pd.DataFrame):\n",
        "        v = v.iloc[:, 0]\n",
        "    v = pd.to_numeric(v, errors='coerce')\n",
        "    return v.values.astype(float)\n",
        "\n",
        "def run_segmented_regression(df_in, target, changepoint):\n",
        "    \"\"\"Segmented (ITS) regression with OLS+HAC, WLS+HAC, and GLSAR\"\"\"\n",
        "    needed = ['midpoint_ma', target, 'derived_strom_prop', 'reef_count', 'strom_total_occ']\n",
        "    for c in needed:\n",
        "        if c not in df_in.columns:\n",
        "            print(f\"[WARN] Missing column: {c}\")\n",
        "            return []\n",
        "\n",
        "    v = df_in[needed].copy()\n",
        "\n",
        "    # Exclude no-strom rows\n",
        "    v = v[v['strom_total_occ'].notna() & (v['strom_total_occ'] > 0)].copy()\n",
        "\n",
        "    # Force numeric\n",
        "    v['midpoint_ma'] = pd.to_numeric(v['midpoint_ma'], errors='coerce')\n",
        "    v[target] = pd.to_numeric(v[target], errors='coerce')\n",
        "    v['derived_strom_prop'] = pd.to_numeric(v['derived_strom_prop'], errors='coerce')\n",
        "    v['strom_total_occ'] = pd.to_numeric(v['strom_total_occ'], errors='coerce')\n",
        "\n",
        "    v = v.dropna(subset=['midpoint_ma', target, 'derived_strom_prop', 'strom_total_occ'])\n",
        "    v = v.sort_values('midpoint_ma', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    if len(v) < 10:\n",
        "        print(\"[WARN] Too few observations after filtering:\", len(v))\n",
        "        return []\n",
        "\n",
        "    t = _as_1d_numeric(v['midpoint_ma'])\n",
        "    y = _as_1d_numeric(v[target])\n",
        "\n",
        "    I_post = (t <= changepoint).astype(float)\n",
        "    t_post = np.maximum(0, changepoint - t)\n",
        "\n",
        "    x_derived = _as_1d_numeric(v['derived_strom_prop'])\n",
        "    s_intensity = np.log1p(_as_1d_numeric(v['strom_total_occ']))\n",
        "\n",
        "    X = np.column_stack([np.ones(len(t)), t, I_post, t_post, x_derived, s_intensity])\n",
        "    col_names = ['const', 'time', 'step', 'post_slope', 'derived_prop', 'sampling']\n",
        "\n",
        "    results = []\n",
        "    n = len(y)\n",
        "    maxlags = max(1, int(np.floor(4 * (n/100)**(2/9))))  # Newey–West\n",
        "\n",
        "    # OLS + HAC\n",
        "    try:\n",
        "        m = OLS(y, X).fit()\n",
        "        hac_cov = cov_hac(m, nlags=maxlags)\n",
        "        hac_se = np.sqrt(np.diag(hac_cov))\n",
        "        hac_t = m.params / hac_se\n",
        "        hac_p = 2 * (1 - stats.t.cdf(np.abs(hac_t), df=n - X.shape[1]))\n",
        "        for i, name in enumerate(col_names):\n",
        "            results.append({'Model': 'OLS+HAC', 'Target': target, 'Changepoint_Ma': changepoint,\n",
        "                            'Term': name, 'Coef': m.params[i], 'SE': hac_se[i], 'P': hac_p[i],\n",
        "                            'N': n, 'R2': m.rsquared})\n",
        "    except Exception as e:\n",
        "        print(\"OLS+HAC failed:\", e)\n",
        "\n",
        "    # WLS + HAC\n",
        "    try:\n",
        "        weights = 1.0 / np.log1p(_as_1d_numeric(v['strom_total_occ']) + 1.0)\n",
        "        m = sm.WLS(y, X, weights=weights).fit()\n",
        "        hac_cov = cov_hac(m, nlags=maxlags)\n",
        "        hac_se = np.sqrt(np.diag(hac_cov))\n",
        "        hac_t = m.params / hac_se\n",
        "        hac_p = 2 * (1 - stats.t.cdf(np.abs(hac_t), df=n - X.shape[1]))\n",
        "        for i, name in enumerate(col_names):\n",
        "            results.append({'Model': 'WLS+HAC', 'Target': target, 'Changepoint_Ma': changepoint,\n",
        "                            'Term': name, 'Coef': m.params[i], 'SE': hac_se[i], 'P': hac_p[i],\n",
        "                            'N': n, 'R2': m.rsquared})\n",
        "    except Exception as e:\n",
        "        print(\"WLS+HAC failed:\", e)\n",
        "\n",
        "    # GLSAR(AR1)\n",
        "    try:\n",
        "        ar_m = GLSAR(y, X, rho=1)\n",
        "        ar_fit = ar_m.iterative_fit(maxiter=20)\n",
        "        for i, name in enumerate(col_names):\n",
        "            results.append({'Model': 'GLSAR', 'Target': target, 'Changepoint_Ma': changepoint,\n",
        "                            'Term': name, 'Coef': ar_fit.params[i], 'SE': ar_fit.bse[i],\n",
        "                            'P': ar_fit.pvalues[i], 'N': n, 'R2': ar_fit.rsquared})\n",
        "    except Exception as e:\n",
        "        print(\"GLSAR failed:\", e)\n",
        "\n",
        "    return results\n",
        "\n",
        "# -------------------------\n",
        "# RUN (use changepoints from Cell 13)\n",
        "# -------------------------\n",
        "CP_thick = np.nan\n",
        "CP_comp  = np.nan\n",
        "\n",
        "if 'peak_thick' in globals():\n",
        "    if isinstance(peak_thick, dict) and 'age' in peak_thick:\n",
        "        CP_thick = float(peak_thick['age'])\n",
        "    elif hasattr(peak_thick, '__getitem__') and 'age' in peak_thick:\n",
        "        CP_thick = float(peak_thick['age'])\n",
        "\n",
        "if 'peak_deriv' in globals():\n",
        "    if isinstance(peak_deriv, dict) and 'age' in peak_deriv:\n",
        "        CP_comp = float(peak_deriv['age'])\n",
        "    elif hasattr(peak_deriv, '__getitem__') and 'age' in peak_deriv:\n",
        "        CP_comp = float(peak_deriv['age'])\n",
        "\n",
        "# fallbacks if missing\n",
        "if not np.isfinite(CP_thick): CP_thick = 426.5\n",
        "if not np.isfinite(CP_comp):  CP_comp  = 431.9\n",
        "\n",
        "print(f\"Running segmented regression at thickness CP = {CP_thick:.1f} Ma...\")\n",
        "seg_thick = pd.DataFrame(run_segmented_regression(df, 'thickness_mean', changepoint=CP_thick))\n",
        "\n",
        "print(f\"Running segmented regression at composition CP = {CP_comp:.1f} Ma...\")\n",
        "seg_comp  = pd.DataFrame(run_segmented_regression(df, 'thickness_mean', changepoint=CP_comp))\n",
        "\n",
        "seg_df = pd.concat([seg_thick.assign(CP_type='Thickness'),\n",
        "                    seg_comp.assign(CP_type='Composition')], ignore_index=True)\n",
        "\n",
        "if 'OUTPUT_DIR' in globals() and not seg_df.empty:\n",
        "    seg_df.to_csv(f'{OUTPUT_DIR}/results_segmented_regression.csv', index=False, encoding='utf-8-sig')\n",
        "    print(f\"Saved: {OUTPUT_DIR}/results_segmented_regression.csv\")\n",
        "\n",
        "display(seg_df if not seg_df.empty else pd.DataFrame())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#@title CELL 16: ZIP everything in ./output and download the zip (Colab-safe)\n",
        "# ============================================================\n",
        "from pathlib import Path\n",
        "import zipfile, datetime, os\n",
        "\n",
        "OUTPUT_DIR = Path(\"./output\")\n",
        "if not OUTPUT_DIR.exists():\n",
        "    raise FileNotFoundError(f\"OUTPUT_DIR not found: {OUTPUT_DIR.resolve()}\")\n",
        "\n",
        "# Make a timestamped zip name\n",
        "ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "zip_path = Path(f\"output_{ts}.zip\")\n",
        "\n",
        "# Collect files\n",
        "files_to_zip = [p for p in OUTPUT_DIR.rglob(\"*\") if p.is_file()]\n",
        "if len(files_to_zip) == 0:\n",
        "    print(f\"[WARN] No files found under: {OUTPUT_DIR.resolve()}\")\n",
        "else:\n",
        "    # Create zip\n",
        "    with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "        for fp in files_to_zip:\n",
        "            # store relative to OUTPUT_DIR (so zip has a clean structure)\n",
        "            zf.write(fp, arcname=fp.relative_to(OUTPUT_DIR))\n",
        "    print(f\"[OK] Created zip: {zip_path.resolve()}  ({len(files_to_zip)} files)\")\n",
        "\n",
        "    # Download (Colab) or show link (Jupyter)\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(str(zip_path))\n",
        "    except Exception:\n",
        "        try:\n",
        "            from IPython.display import FileLink, display\n",
        "            display(FileLink(str(zip_path)))\n",
        "        except Exception:\n",
        "            print(f\"Download not auto-supported here. Zip is at: {zip_path.resolve()}\")\n"
      ],
      "metadata": {
        "id": "vAOSwErWMeuP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "12620588-aac3-4bf1-d2cd-41b2b20a462c",
        "cellView": "form"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Created zip: /content/output_20260118_071048.zip  (31 files)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f715910d-2f71-4eb2-a520-983f511bcbae\", \"output_20260118_071048.zip\", 4414307)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9bHOenpJCS-_"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}